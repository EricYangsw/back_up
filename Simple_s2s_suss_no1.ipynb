{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# __all__ = [\"AttentionModel\"]\n",
    "print(\"TensorFlow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read data (already reduce dimension)'''\n",
    "x_input = pd.read_csv('plc_x_reduce.csv')\n",
    "y_label = pd.read_csv('plc_y_reduce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_input,\n",
    "                    y_label,\n",
    "                    batch_size=1, \n",
    "                    seq_len=1,\n",
    "                    test_ratio=0.1):\n",
    "    ''' Generating eaach batch data(np.array) into a list'''\n",
    "    \n",
    "    batchs = int(y_label.shape[0] / seq_len / batch_size)\n",
    "    test_batch = int(batchs * test_ratio)\n",
    "    train_batchs = batchs - test_batch\n",
    "    \n",
    "    print('Train Batch: {} ; Test Batch: {}'.format(train_batchs, test_batch))\n",
    "    \n",
    "    train_input = []\n",
    "    train_target = []\n",
    "    test_input = []\n",
    "    test_target = []\n",
    "\n",
    "    up = 0\n",
    "    down = seq_len\n",
    "    for i in range(train_batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            #print(b, x.shape, range(up,down))\n",
    "            x[b, :, :] = x_input[up : down, :]\n",
    "            y[b, :, :] = y_label[up : down, :]\n",
    "            up = down\n",
    "            down = down+seq_len\n",
    "        train_input.append(x)\n",
    "        train_target.append(y)\n",
    "        \n",
    "    for i in range(train_batchs,batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            #print(b, x.shape, range(up,down))\n",
    "            x[b, :, :] = x_input[up : down, :]\n",
    "            y[b, :, :] = y_label[up : down, :]\n",
    "            up = down\n",
    "            down = down+seq_len\n",
    "        test_input.append(x)\n",
    "        test_target.append(y)\n",
    "    return train_input, train_target, test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self,\n",
    "                 seq_max_len=1.,  \n",
    "                 input_len=71.,\n",
    "                 output_len=41.,\n",
    "                 batch_size=1,\n",
    "                 lstm_size=[128., 128., 128.],\n",
    "                 learning_rate=0.005,\n",
    "                 grad_clip=2.,\n",
    "                 keep_prob=0.8,\n",
    "                 forward_only= None):\n",
    "        \n",
    "        self.seq_max_len = seq_max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_len = np.array([])\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_units = self.lstm_size[-1]\n",
    "        self.num_layers = len(self.lstm_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.train_keep_prob = keep_prob\n",
    "        self.go_token = 9.\n",
    "        self.batch_seq_len = np.int32(np.ones(shape=([self.batch_size])) * self.seq_max_len)\n",
    "        \n",
    "        '''Execution method'''\n",
    "        tf.reset_default_graph() #Clears the default graph stack and resets the global default graph\n",
    "        self.build_inputs()\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.saver = tf.train.Saver() #Saves and restores variables.\n",
    " \n",
    "\n",
    "    def build_inputs(self):\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, \n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.input_len),\n",
    "                                         name='inputs')\n",
    "        self.targets = tf.placeholder(tf.float32,\n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.output_len),\n",
    "                                         name='targets')\n",
    "        self.decoder_inputs = tf.placeholder(tf.float32,\n",
    "                                                shape=(self.batch_size, self.seq_max_len, self.output_len),  \n",
    "                                                name='decoder_inputs')        \n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "         \n",
    "        '''if seq is different， sequence input was needed :\n",
    "        self.input_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='input_length')\n",
    "        self.decoder_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='decoder_inputs_length')\n",
    "        self.target_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.float32, name='target_sequence_length')\n",
    "        '''\n",
    "        \n",
    "\n",
    "    # Encoder Model==========================================================================\n",
    "    def build_encoder(self):\n",
    "        ''' Encoder Model'''\n",
    "        def get_a_cell(lstm_size, keep_prop):\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=self.train_keep_prob)\n",
    "            return drop\n",
    "\n",
    "        with tf.variable_scope('encoder', initializer=tf.orthogonal_initializer()):\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                                 [get_a_cell(size, self.keep_prob) for size in self.lstm_size]\n",
    "                                                      )\n",
    "            self.initial_state = encoder_cell.zero_state(self.batch_size, tf.float32)\n",
    "            # 透過dynamic_rnn對cell展開時間維度\n",
    "            self.encoder_outputs, self.encoder_state  = tf.nn.dynamic_rnn(\n",
    "                                                           encoder_cell, \n",
    "                                                           self.encoder_inputs,                                                    \n",
    "                                                           initial_state=self.initial_state\n",
    "                                                                          )\n",
    "\n",
    "            \n",
    "    # Decoder Model==============================================================================\n",
    "    def build_decoder(self):\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(self.lstm_size[-1])\n",
    "        #decoder_cell = tf.contrib.rnn.GRUCell(self.lstm_size[-1])\n",
    "       \n",
    "        '''Project layer (output layer / full connecting layers)'''\n",
    "        project_layer = layers_core.Dense(self.output_len, \n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(mean=0.1,stddev=0.1), \n",
    "                                          name=\"output_projection\") \n",
    "        \n",
    "        ''' Two decoder model:\n",
    "        . training_decoder : for training & target as input\n",
    "        . predict_decoder : for predecting & input by beam search etc...\n",
    "        '''\n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            '''1. Training decoder & output \n",
    "                  Time_major =False(default): [batch_size, max_seq_len, vector_len]\n",
    "                  Time_major =True : [max_seq_len, batch_size, vector_len]\n",
    "            '''\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                                                 self.decoder_inputs, \n",
    "                                                 self.batch_seq_len, \n",
    "                                                 time_major=False)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                                                  cell=decoder_cell,\n",
    "                                                  helper=training_helper,\n",
    "                                                  initial_state=self.encoder_state[-1],#self.encoder_state,\n",
    "                                                  output_layer=project_layer)\n",
    "            train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            self.logits = train_outputs.rnn_output\n",
    "            self.train_prediction = tf.sigmoid(self.logits, name='train_predictions')\n",
    "            t_pred = tf.identity(self.train_prediction, name='t_pred')\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"decode\", reuse=True):\n",
    "            '''2. Predicting decoder & output (same parameter) '''\n",
    "            \n",
    "            '''Three function for CustomHelper'''\n",
    "            def initial_fn():\n",
    "                initial_elements_finished = self.go_token\n",
    "                initial_input = tf.concat(self.go_token, shape=[self.batch_size, self.output_len])\n",
    "                return initial_elements_finished, initial_input\n",
    "\n",
    "            def sample_fn(time, outputs, state):\n",
    "                # 选择logit最大的下标作为sample\n",
    "                prediction = tf.to_int32(outputs)\n",
    "                return prediction\n",
    "\n",
    "            def next_inputs_fn(time, outputs, state, sample_ids):\n",
    "                next_input = tf.concat((outputs, encoder_outputs[time]), 1)\n",
    "                elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n",
    "                next_state = state\n",
    "                return elements_finished, next_inputs, next_state\n",
    "        \n",
    "        \n",
    "            predicting_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)\n",
    "\n",
    "            predicting_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                                                 helper=predicting_helper,\n",
    "                                                                 initial_state=self.encoder_state[-1],\n",
    "                                                                 output_layer=project_layer)\n",
    "            predicting_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            predict_logits = train_outputs.rnn_output\n",
    "            self.final_prediction = tf.sigmoid(predict_logits, name='model_predictions')\n",
    "            model_pred = tf.identity(self.final_prediction, name='model_pred')\n",
    "        \n",
    "        \n",
    "\n",
    "    # Loss & Optimizer ==============================================================================\n",
    "    def build_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            #self.y_reshaped = tf.reshape(self.targets,  self.logits.get_shape())\n",
    "            #self.loss =tf.losses.mean_squared_error(predictions=self.logits, labels=self.targets)\n",
    "            self.loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, labels=self.targets)\n",
    "            self.loss = tf.reduce_mean(self.loss)\n",
    "\n",
    "    def build_optimizer(self):\n",
    "        # Using \"clipping\" gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), self.grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimizer = train_op.apply_gradients(zip(grads, tvars))  \n",
    "        \n",
    "        \n",
    "\n",
    "    # Training===============================================================================    \n",
    "    def train(self, x, y, iters=10,  save_every_n=200, log_every_n=200):\n",
    "        self.train_graph = tf.Graph()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(self.initial_state)           \n",
    "            \n",
    "            for ite in range(iters):\n",
    "                step = 0\n",
    "                print('iters: {}'.format(ite))\n",
    "                for i in range(len(x)):\n",
    "                    step += 1\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    feed = {self.encoder_inputs: x[i], \n",
    "                            self.targets: y[i],\n",
    "                            self.decoder_inputs : y[i],\n",
    "                            self.keep_prob: self.train_keep_prob}\n",
    "                            #self.initial_state: new_state}\n",
    "                    \n",
    "                    batch_loss, new_state, pred, target = sess.run([self.loss,\n",
    "                                                      self.optimizer,\n",
    "                                                      self.train_prediction,\n",
    "                                                      self.targets],\n",
    "                                                      feed_dict=feed)\n",
    "                    end = time.time()\n",
    "                    \n",
    "                    # control the print lines\n",
    "                    if step % log_every_n == 0:\n",
    "                        print(\"=======================================================\\n\")\n",
    "                        print('step: {} in iter: {}/{}... '.format(step, ite+1, iters),\n",
    "                              'loss: {:.15f}... '.format(batch_loss),\n",
    "                              '{:.4f} sec/batch'.format((end - start)))\n",
    "\n",
    "                    if (step % save_every_n == 0):\n",
    "                        self.saver.save(sess, './seq2seq_models/model')\n",
    "    \n",
    "    \n",
    "    def predict(self, x, y, variable_name='model_pred'):\n",
    "        with tf.Session() as sess:\n",
    "            loader = tf.train.import_meta_graph('./seq2seq_models/model.meta')\n",
    "            loader.restore(sess, './seq2seq_models/model')\n",
    "            graph = tf.get_default_graph()\n",
    "            \n",
    "            '''Get the tensor'''\n",
    "            encoder_input = graph.get_tensor_by_name('inputs:0')\n",
    "            decoder_input = graph.get_tensor_by_name('decoder_inputs:0')\n",
    "            target = graph.get_tensor_by_name('targets:0')\n",
    "            keep_prob= graph.get_tensor_by_name('keep_prob:0')\n",
    "            '''Note the same name will be added \"_1\" with default'''\n",
    "            prediction = sess.graph.get_tensor_by_name('decode_1/model_pred:0')\n",
    "            \n",
    "            self.count = 0\n",
    "            self.total = 0\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                feed = {self.encoder_inputs: x[i], \n",
    "                                self.targets: y[0], # just make sure target not influence result\n",
    "                                self.decoder_inputs : y[0], # just make sure target not influence result\n",
    "                                self.keep_prob: 1.}\n",
    "                self.answer = sess.run(prediction, feed_dict=feed)\n",
    "                c, t = self.accuracy(self.answer, y[i])\n",
    "                self.count += c\n",
    "                self.total += t\n",
    "        return self.count/self.total\n",
    "            # print(answer)\n",
    "        \n",
    "    \n",
    "    def accuracy(self, pred, target):\n",
    "        pred = np.array(pred)\n",
    "        pred = np.array(pred >= 0.5).astype(int)\n",
    "        result = np.abs(pred - target)\n",
    "        \n",
    "        count = np.sum(result)\n",
    "        total = result.size\n",
    "\n",
    "        for i in range(result.shape[0]):\n",
    "            np.savetxt(\"result_\" + str(i) + \".csv\", result[i], delimiter=',')\n",
    "        return count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 5\n",
    "lstm_size=[128., 128., 128.]\n",
    "learning_rate=0.005\n",
    "save_path = './seq2seq_models'\n",
    "\n",
    "iters=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch: 1908 ; Test Batch: 211\n",
      "iters: 0\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 1/200...  loss: 0.025029256939888...  0.0170 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 1/200...  loss: 0.015514864586294...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 1/200...  loss: 0.005106868222356...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 1/200...  loss: 0.000756618974265...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 1/200...  loss: 0.006150427274406...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 1/200...  loss: 0.000299317529425...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 1/200...  loss: 0.000150728927110...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 1/200...  loss: 0.000130576809170...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 1/200...  loss: 0.000121198492707...  0.0080 sec/batch\n",
      "iters: 1\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 2/200...  loss: 0.000260296190390...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 2/200...  loss: 0.000391376030166...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 2/200...  loss: 0.000406791106798...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 2/200...  loss: 0.000104340659163...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 2/200...  loss: 0.000418262119638...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 2/200...  loss: 0.000260713277385...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 2/200...  loss: 0.000048714522563...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 2/200...  loss: 0.000073599490861...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 2/200...  loss: 0.000057254615967...  0.0090 sec/batch\n",
      "iters: 2\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 3/200...  loss: 0.000036951361835...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 3/200...  loss: 0.000053162922995...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 3/200...  loss: 0.000099138560472...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 3/200...  loss: 0.000031190469599...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 3/200...  loss: 0.000097211886896...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 3/200...  loss: 0.000014120570995...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 3/200...  loss: 0.000007217164693...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 3/200...  loss: 0.000007844949323...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 3/200...  loss: 0.000021680896680...  0.0080 sec/batch\n",
      "iters: 3\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 4/200...  loss: 0.000020045767087...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 4/200...  loss: 0.000117679599498...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 4/200...  loss: 0.000033486987377...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 4/200...  loss: 0.000012374748621...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 4/200...  loss: 0.000030881456041...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 4/200...  loss: 0.000006308191587...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 4/200...  loss: 0.000003224815828...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 4/200...  loss: 0.000011630028894...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 4/200...  loss: 0.000019922019419...  0.0070 sec/batch\n",
      "iters: 4\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 5/200...  loss: 0.000069819237979...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 5/200...  loss: 0.000034833607060...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 5/200...  loss: 0.000022081174393...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 5/200...  loss: 0.000007631955668...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 5/200...  loss: 0.000013761710761...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 5/200...  loss: 0.000004388516118...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 5/200...  loss: 0.000002612983508...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 5/200...  loss: 0.000009917707757...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 5/200...  loss: 0.000026743493436...  0.0100 sec/batch\n",
      "iters: 5\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 6/200...  loss: 0.000009097916518...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 6/200...  loss: 0.000009899550605...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 6/200...  loss: 0.000010740583093...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 6/200...  loss: 0.000005375702585...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 6/200...  loss: 0.000013376402421...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 6/200...  loss: 0.000002639825425...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 6/200...  loss: 0.000001215367320...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 6/200...  loss: 0.000004365386303...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 6/200...  loss: 0.000006412781659...  0.0090 sec/batch\n",
      "iters: 6\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 7/200...  loss: 0.000008873488696...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 7/200...  loss: 0.000007658944924...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 7/200...  loss: 0.000004649011316...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 7/200...  loss: 0.000001761199769...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 7/200...  loss: 0.000005084142231...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 7/200...  loss: 0.000001352845629...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 7/200...  loss: 0.000000995647042...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 7/200...  loss: 0.000000775470596...  0.0090 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 7/200...  loss: 0.000000562920718...  0.0080 sec/batch\n",
      "iters: 7\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 8/200...  loss: 0.000002442632194...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 8/200...  loss: 0.000015988485757...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 8/200...  loss: 0.000075849413406...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 8/200...  loss: 0.000002452423132...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 8/200...  loss: 0.000004604197784...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 8/200...  loss: 0.000001579914510...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 8/200...  loss: 0.000000942355200...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 8/200...  loss: 0.000000784776091...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 8/200...  loss: 0.000001050260494...  0.0080 sec/batch\n",
      "iters: 8\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 9/200...  loss: 0.000001448243438...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 9/200...  loss: 0.000002757416269...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 9/200...  loss: 0.000003535690212...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 9/200...  loss: 0.000001007482297...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 9/200...  loss: 0.000002618784720...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 9/200...  loss: 0.000000584829252...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 9/200...  loss: 0.000000396103303...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 9/200...  loss: 0.000000281181741...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 9/200...  loss: 0.000000305723177...  0.0090 sec/batch\n",
      "iters: 9\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 10/200...  loss: 0.000001070886356...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 10/200...  loss: 0.000001392156264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 10/200...  loss: 0.000032232965168...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 10/200...  loss: 0.000002964066880...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 10/200...  loss: 0.000002335337285...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 10/200...  loss: 0.000001390381840...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 10/200...  loss: 0.000000709523590...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 10/200...  loss: 0.000000524571362...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 10/200...  loss: 0.000000574633702...  0.0080 sec/batch\n",
      "iters: 10\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 11/200...  loss: 0.000000993917524...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 11/200...  loss: 0.000004282141163...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 11/200...  loss: 0.000009997225789...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 11/200...  loss: 0.000001785270570...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 11/200...  loss: 0.000002354296157...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 11/200...  loss: 0.000003973394087...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 11/200...  loss: 0.000001501080874...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 11/200...  loss: 0.000002629979917...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 11/200...  loss: 0.000004507724043...  0.0080 sec/batch\n",
      "iters: 11\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 12/200...  loss: 0.000001691154580...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 12/200...  loss: 0.000000839408813...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 12/200...  loss: 0.000000409113625...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 12/200...  loss: 0.000000813386180...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 12/200...  loss: 0.000000934971638...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 12/200...  loss: 0.000000451708303...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 12/200...  loss: 0.000000242411744...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 12/200...  loss: 0.000000173232280...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 12/200...  loss: 0.000000134167905...  0.0110 sec/batch\n",
      "iters: 12\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 13/200...  loss: 0.000000099057623...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 13/200...  loss: 0.000000196269511...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 13/200...  loss: 0.000000124556792...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 13/200...  loss: 0.000000199074648...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 13/200...  loss: 0.000003437172154...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 13/200...  loss: 0.000000699895111...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 13/200...  loss: 0.000000367313731...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 13/200...  loss: 0.000000204709721...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 13/200...  loss: 0.000000122765414...  0.0070 sec/batch\n",
      "iters: 13\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 14/200...  loss: 0.000000145766037...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 14/200...  loss: 0.000000051996185...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 14/200...  loss: 0.000000037147437...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 14/200...  loss: 0.000000877738273...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 14/200...  loss: 0.000001520836236...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 14/200...  loss: 0.000000322368578...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 14/200...  loss: 0.000000154713291...  0.0090 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 14/200...  loss: 0.000000091920690...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 14/200...  loss: 0.000000078624538...  0.0080 sec/batch\n",
      "iters: 14\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 15/200...  loss: 0.000000081657781...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 15/200...  loss: 0.000000161678514...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 15/200...  loss: 0.000001481000481...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 15/200...  loss: 0.000006599358130...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 15/200...  loss: 0.000003642663614...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 15/200...  loss: 0.000000725153370...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 15/200...  loss: 0.000000533137154...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 15/200...  loss: 0.000000341508724...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 15/200...  loss: 0.000000295577820...  0.0100 sec/batch\n",
      "iters: 15\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 16/200...  loss: 0.000000260098290...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 16/200...  loss: 0.000000137570765...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 16/200...  loss: 0.000000124780129...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 16/200...  loss: 0.000000105744313...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 16/200...  loss: 0.000000865135007...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 16/200...  loss: 0.000000125887638...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 16/200...  loss: 0.000000095169540...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 16/200...  loss: 0.000000071376178...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 16/200...  loss: 0.000000044629154...  0.0120 sec/batch\n",
      "iters: 16\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 17/200...  loss: 0.000000067688923...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 17/200...  loss: 0.000000111581478...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 17/200...  loss: 0.000000949114508...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 17/200...  loss: 0.000000868898212...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 17/200...  loss: 0.000000677281264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 17/200...  loss: 0.000000447083664...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 17/200...  loss: 0.000000241778565...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 17/200...  loss: 0.000000202137684...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 17/200...  loss: 0.000000509176573...  0.0070 sec/batch\n",
      "iters: 17\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 18/200...  loss: 0.000000284553920...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 18/200...  loss: 0.000000846760088...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 18/200...  loss: 0.000000151625585...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 18/200...  loss: 0.000000141437596...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 18/200...  loss: 0.000000306386283...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 18/200...  loss: 0.000000134513357...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 18/200...  loss: 0.000000095337363...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 18/200...  loss: 0.000000049745772...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 18/200...  loss: 0.000000047085912...  0.0080 sec/batch\n",
      "iters: 18\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 19/200...  loss: 0.000000030078279...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 19/200...  loss: 0.000000061072448...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 19/200...  loss: 0.000000047496407...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 19/200...  loss: 0.000001616817372...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 19/200...  loss: 0.000001141759185...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 19/200...  loss: 0.000000108543006...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 19/200...  loss: 0.000000061648976...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 19/200...  loss: 0.000000048438917...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 19/200...  loss: 0.000000046903320...  0.0080 sec/batch\n",
      "iters: 19\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 20/200...  loss: 0.000000461640781...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 20/200...  loss: 0.000000124051766...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 20/200...  loss: 0.000000061487938...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 20/200...  loss: 0.000000019894561...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 20/200...  loss: 0.000000337062716...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 20/200...  loss: 0.000000062056728...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 20/200...  loss: 0.000000044753634...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 20/200...  loss: 0.000000145753759...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 20/200...  loss: 0.000000057799120...  0.0070 sec/batch\n",
      "iters: 20\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 21/200...  loss: 0.000000056210531...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 21/200...  loss: 0.000000054826401...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 21/200...  loss: 0.000000140886613...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 21/200...  loss: 0.000000493641096...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 21/200...  loss: 0.000001180346658...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 21/200...  loss: 0.000000090040636...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 21/200...  loss: 0.000000039284675...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 21/200...  loss: 0.000000040122494...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 21/200...  loss: 0.000000032958749...  0.0080 sec/batch\n",
      "iters: 21\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 22/200...  loss: 0.000000129246061...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 22/200...  loss: 0.000014696358448...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 22/200...  loss: 0.000002498951289...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 22/200...  loss: 0.000000742942348...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 22/200...  loss: 0.000000705952459...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 22/200...  loss: 0.000000493102732...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 22/200...  loss: 0.000000339376641...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 22/200...  loss: 0.000000261325226...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 22/200...  loss: 0.000000221880626...  0.0080 sec/batch\n",
      "iters: 22\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 23/200...  loss: 0.000000353646016...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 23/200...  loss: 0.000000131234032...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 23/200...  loss: 0.000000125245336...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 23/200...  loss: 0.000000075484927...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 23/200...  loss: 0.000000083632145...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 23/200...  loss: 0.000000050912274...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 23/200...  loss: 0.000000043313509...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 23/200...  loss: 0.000000035227945...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 23/200...  loss: 0.000000028495824...  0.0080 sec/batch\n",
      "iters: 23\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 24/200...  loss: 0.000000019758302...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 24/200...  loss: 0.000000315113397...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 24/200...  loss: 0.000000021736204...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 24/200...  loss: 0.000000093398597...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 24/200...  loss: 0.000000096284822...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 24/200...  loss: 0.000000135853853...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 24/200...  loss: 0.000000071237707...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 24/200...  loss: 0.000000037434077...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 24/200...  loss: 0.000000033686963...  0.0090 sec/batch\n",
      "iters: 24\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 25/200...  loss: 0.000000015247419...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 25/200...  loss: 0.000000021847365...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 25/200...  loss: 0.000000014797408...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 25/200...  loss: 0.000000144105655...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 25/200...  loss: 0.000255427527009...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 25/200...  loss: 0.000000327225962...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 25/200...  loss: 0.000000649571689...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 25/200...  loss: 0.000000306732602...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 25/200...  loss: 0.000000129938357...  0.0080 sec/batch\n",
      "iters: 25\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 26/200...  loss: 0.000000036665291...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 26/200...  loss: 0.000000041822702...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 26/200...  loss: 0.000000038858094...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 26/200...  loss: 0.000000151948925...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 26/200...  loss: 0.000000277186444...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 26/200...  loss: 0.000000238486336...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 26/200...  loss: 0.000000109287051...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 26/200...  loss: 0.000000110654433...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 26/200...  loss: 0.000000045939508...  0.0080 sec/batch\n",
      "iters: 26\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 27/200...  loss: 0.000000102150295...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 27/200...  loss: 0.000000063164592...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 27/200...  loss: 0.000000038975177...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 27/200...  loss: 0.000000043654335...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 27/200...  loss: 0.000000247209783...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 27/200...  loss: 0.000000035589245...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 27/200...  loss: 0.000000030145713...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 27/200...  loss: 0.000000033187909...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 27/200...  loss: 0.000000024025912...  0.0100 sec/batch\n",
      "iters: 27\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 28/200...  loss: 0.000000030070787...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 28/200...  loss: 0.000000034780665...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 28/200...  loss: 0.000000027617491...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 28/200...  loss: 0.000000057761081...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 28/200...  loss: 0.000000045973387...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 28/200...  loss: 0.000000034831757...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 28/200...  loss: 0.000000043525944...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 28/200...  loss: 0.000000026124685...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 28/200...  loss: 0.000000018030288...  0.0090 sec/batch\n",
      "iters: 28\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 29/200...  loss: 0.000000072819944...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 29/200...  loss: 0.000001131490308...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 29/200...  loss: 0.000000231479959...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 29/200...  loss: 0.000000216837606...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 29/200...  loss: 0.000000506850881...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 29/200...  loss: 0.000000129993452...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 29/200...  loss: 0.000000059788562...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 29/200...  loss: 0.000000050221441...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 29/200...  loss: 0.000000028546889...  0.0090 sec/batch\n",
      "iters: 29\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 30/200...  loss: 0.000000026034975...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 30/200...  loss: 0.000000019146940...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 30/200...  loss: 0.000000013766473...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 30/200...  loss: 0.000000010721164...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 30/200...  loss: 0.000000028441869...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 30/200...  loss: 0.000000011780601...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 30/200...  loss: 0.000000010846359...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 30/200...  loss: 0.000000009256515...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 30/200...  loss: 0.000000008516563...  0.0100 sec/batch\n",
      "iters: 30\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 31/200...  loss: 0.000000011674502...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 31/200...  loss: 0.000000009675637...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 31/200...  loss: 0.000000007051624...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 31/200...  loss: 0.000000004750486...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 31/200...  loss: 0.000000012141585...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 31/200...  loss: 0.000000004212411...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 31/200...  loss: 0.000000004158335...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 31/200...  loss: 0.000000003455431...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 31/200...  loss: 0.000000003242165...  0.0080 sec/batch\n",
      "iters: 31\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 32/200...  loss: 0.000000003894981...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 32/200...  loss: 0.000000003281171...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 32/200...  loss: 0.000000002408362...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 32/200...  loss: 0.000000001857366...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 32/200...  loss: 0.000000004112216...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 32/200...  loss: 0.000000001691259...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 32/200...  loss: 0.000000001597703...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 32/200...  loss: 0.000000001298972...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 32/200...  loss: 0.000000001223550...  0.0100 sec/batch\n",
      "iters: 32\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 33/200...  loss: 0.000000001198286...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 33/200...  loss: 0.000000000907103...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 33/200...  loss: 0.000000000847044...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 33/200...  loss: 0.000000000880468...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 33/200...  loss: 0.000000005044782...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 33/200...  loss: 0.000000001810690...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 33/200...  loss: 0.000000001362432...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 33/200...  loss: 0.000000000970654...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 33/200...  loss: 0.000000000528505...  0.0070 sec/batch\n",
      "iters: 33\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 34/200...  loss: 0.000000003878302...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 34/200...  loss: 0.000000635082870...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 34/200...  loss: 0.000001263060312...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 34/200...  loss: 0.000000703351191...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 34/200...  loss: 0.000000430812122...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 34/200...  loss: 0.000000303412264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 34/200...  loss: 0.000000146284336...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 34/200...  loss: 0.000000104933399...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 34/200...  loss: 0.000000092813046...  0.0080 sec/batch\n",
      "iters: 34\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 35/200...  loss: 0.000000059881359...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 35/200...  loss: 0.000000059604488...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 35/200...  loss: 0.000000038198852...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 35/200...  loss: 0.000000039616687...  0.0090 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 35/200...  loss: 0.000000062816419...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 35/200...  loss: 0.000000028197944...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 35/200...  loss: 0.000000024860691...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 35/200...  loss: 0.000000021797732...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 35/200...  loss: 0.000000018759655...  0.0090 sec/batch\n",
      "iters: 35\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 36/200...  loss: 0.000000014490487...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 36/200...  loss: 0.000000013174075...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 36/200...  loss: 0.000000010991667...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 36/200...  loss: 0.000000010177575...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 36/200...  loss: 0.000000024105638...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 36/200...  loss: 0.000000009268770...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 36/200...  loss: 0.000000008299626...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 36/200...  loss: 0.000000007080630...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 36/200...  loss: 0.000000006179091...  0.0080 sec/batch\n",
      "iters: 36\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 37/200...  loss: 0.000000004945269...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 37/200...  loss: 0.000000004508298...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 37/200...  loss: 0.000000004148673...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 37/200...  loss: 0.000000004463494...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 37/200...  loss: 0.000000009340954...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 37/200...  loss: 0.000000004613482...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 37/200...  loss: 0.000000004088687...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 37/200...  loss: 0.000000003213403...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 37/200...  loss: 0.000000003143337...  0.0080 sec/batch\n",
      "iters: 37\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 38/200...  loss: 0.000000003101751...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 38/200...  loss: 0.000000003890929...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 38/200...  loss: 0.000000003175718...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 38/200...  loss: 0.000000003036879...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 38/200...  loss: 0.000000005232470...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 38/200...  loss: 0.000000002594903...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 38/200...  loss: 0.000000002233774...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 38/200...  loss: 0.000000001837663...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 38/200...  loss: 0.000000001625374...  0.0080 sec/batch\n",
      "iters: 38\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 39/200...  loss: 0.000000001968743...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 39/200...  loss: 0.000000001486025...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 39/200...  loss: 0.000000001599667...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 39/200...  loss: 0.000000001589435...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 39/200...  loss: 0.000000003070264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 39/200...  loss: 0.000000000972494...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 39/200...  loss: 0.000000000807399...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 39/200...  loss: 0.000000000684531...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 39/200...  loss: 0.000000000626795...  0.0090 sec/batch\n",
      "iters: 39\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 40/200...  loss: 0.000000001362567...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 40/200...  loss: 0.000000000820063...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 40/200...  loss: 0.000000022241830...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 40/200...  loss: 0.000000248560838...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 40/200...  loss: 0.000001013086603...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 40/200...  loss: 0.000000081768420...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 40/200...  loss: 0.000000032825067...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 40/200...  loss: 0.000000017845265...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 40/200...  loss: 0.000000012677413...  0.0080 sec/batch\n",
      "iters: 40\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 41/200...  loss: 0.000000006970234...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 41/200...  loss: 0.000000011755546...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 41/200...  loss: 0.000000076869604...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 41/200...  loss: 0.000000069855780...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 41/200...  loss: 0.000000092648733...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 41/200...  loss: 0.000000017147370...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 41/200...  loss: 0.000000008991115...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 41/200...  loss: 0.000000010384985...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 41/200...  loss: 0.000000006885222...  0.0100 sec/batch\n",
      "iters: 41\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 42/200...  loss: 0.000000004620860...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 42/200...  loss: 0.000000016739440...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 42/200...  loss: 0.000000013005339...  0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 42/200...  loss: 0.000000165403819...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 42/200...  loss: 0.000000424792688...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 42/200...  loss: 0.000000126056136...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 42/200...  loss: 0.000000098266852...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 42/200...  loss: 0.000000051152369...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 42/200...  loss: 0.000000056584938...  0.0090 sec/batch\n",
      "iters: 42\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 43/200...  loss: 0.000000102975115...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 43/200...  loss: 0.000000417532334...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 43/200...  loss: 0.000000137106426...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 43/200...  loss: 0.000000058160438...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 43/200...  loss: 0.000000158665088...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 43/200...  loss: 0.000000020744739...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 43/200...  loss: 0.000000019083577...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 43/200...  loss: 0.000000016611580...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 43/200...  loss: 0.000000014559529...  0.0100 sec/batch\n",
      "iters: 43\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 44/200...  loss: 0.000000095903097...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 44/200...  loss: 0.000000029345534...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 44/200...  loss: 0.000000020186686...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 44/200...  loss: 0.000000014945620...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 44/200...  loss: 0.000000059859126...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 44/200...  loss: 0.000000026159249...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 44/200...  loss: 0.000000028619338...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 44/200...  loss: 0.000000013706604...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 44/200...  loss: 0.000000009795468...  0.0090 sec/batch\n",
      "iters: 44\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 45/200...  loss: 0.000000002416857...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 45/200...  loss: 0.000000072720653...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 45/200...  loss: 0.000000018396015...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 45/200...  loss: 0.000000009865129...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 45/200...  loss: 0.000000247105277...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 45/200...  loss: 0.000000016483153...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 45/200...  loss: 0.000000003737808...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 45/200...  loss: 0.000000002625434...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 45/200...  loss: 0.000000003031348...  0.0090 sec/batch\n",
      "iters: 45\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 46/200...  loss: 0.000000379782534...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 46/200...  loss: 0.000000113535144...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 46/200...  loss: 0.000000056374986...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 46/200...  loss: 0.000000414724354...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 46/200...  loss: 0.000000167452768...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 46/200...  loss: 0.000000104436765...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 46/200...  loss: 0.000000077318596...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 46/200...  loss: 0.000000069201597...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 46/200...  loss: 0.000000051510462...  0.0080 sec/batch\n",
      "iters: 46\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 47/200...  loss: 0.000000050340539...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 47/200...  loss: 0.000000043308987...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 47/200...  loss: 0.000000038405254...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 47/200...  loss: 0.000000033847382...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 47/200...  loss: 0.000000057792967...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 47/200...  loss: 0.000000037229686...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 47/200...  loss: 0.000000041968807...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 47/200...  loss: 0.000000030773016...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 47/200...  loss: 0.000000023301009...  0.0100 sec/batch\n",
      "iters: 47\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 48/200...  loss: 0.000000021507867...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 48/200...  loss: 0.000000018496475...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 48/200...  loss: 0.000000016460021...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 48/200...  loss: 0.000000012514564...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 48/200...  loss: 0.000000022786766...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 48/200...  loss: 0.000000013624613...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 48/200...  loss: 0.000000011385617...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 48/200...  loss: 0.000000008820638...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 48/200...  loss: 0.000000007682416...  0.0080 sec/batch\n",
      "iters: 48\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 49/200...  loss: 0.000000007620637...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 49/200...  loss: 0.000000006764151...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 49/200...  loss: 0.000000006374624...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 49/200...  loss: 0.000000005314230...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 49/200...  loss: 0.000000009153087...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 49/200...  loss: 0.000000005318910...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 49/200...  loss: 0.000000004623171...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 49/200...  loss: 0.000000003457403...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 49/200...  loss: 0.000000002928612...  0.0090 sec/batch\n",
      "iters: 49\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 50/200...  loss: 0.000000002871178...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 50/200...  loss: 0.000000002403620...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 50/200...  loss: 0.000000001955911...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 50/200...  loss: 0.000000002032532...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 50/200...  loss: 0.000000003968214...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 50/200...  loss: 0.000000002035733...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 50/200...  loss: 0.000000001734484...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 50/200...  loss: 0.000000001272982...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 50/200...  loss: 0.000000001085972...  0.0080 sec/batch\n",
      "iters: 50\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 51/200...  loss: 0.000000001073074...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 51/200...  loss: 0.000000000886042...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 51/200...  loss: 0.000000000736760...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 51/200...  loss: 0.000000000650092...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 51/200...  loss: 0.000000001631980...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 51/200...  loss: 0.000000000690849...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 51/200...  loss: 0.000000000611938...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 51/200...  loss: 0.000000000464674...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 51/200...  loss: 0.000000000396510...  0.0080 sec/batch\n",
      "iters: 51\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 52/200...  loss: 0.000000000393920...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 52/200...  loss: 0.000000000345197...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 52/200...  loss: 0.000000000274496...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 52/200...  loss: 0.000000000245720...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 52/200...  loss: 0.000000000706983...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 52/200...  loss: 0.000000000277591...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 52/200...  loss: 0.000000000243101...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 52/200...  loss: 0.000000000188805...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 52/200...  loss: 0.000000000154280...  0.0090 sec/batch\n",
      "iters: 52\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 53/200...  loss: 0.000000000161197...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 53/200...  loss: 0.000000000137705...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 53/200...  loss: 0.000000000106843...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 53/200...  loss: 0.000000000102793...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 53/200...  loss: 0.000000000329824...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 53/200...  loss: 0.000000000098600...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 53/200...  loss: 0.000000000089402...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 53/200...  loss: 0.000000000069759...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 53/200...  loss: 0.000000000061987...  0.0080 sec/batch\n",
      "iters: 53\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 54/200...  loss: 0.000000000054502...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 54/200...  loss: 0.000000000050310...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 54/200...  loss: 0.000000000040962...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 54/200...  loss: 0.000000000048227...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 54/200...  loss: 0.000000000167809...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 54/200...  loss: 0.000000000065216...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 54/200...  loss: 0.000000000057500...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 54/200...  loss: 0.000000000043540...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 54/200...  loss: 0.000000000037610...  0.0080 sec/batch\n",
      "iters: 54\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 55/200...  loss: 0.000000000047543...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 55/200...  loss: 0.000000000030975...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 55/200...  loss: 0.000000000025612...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 55/200...  loss: 0.000000000037258...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 55/200...  loss: 0.000000000114233...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 55/200...  loss: 0.000000000023353...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 55/200...  loss: 0.000000000021707...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 55/200...  loss: 0.000000000017508...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 55/200...  loss: 0.000000000015395...  0.0090 sec/batch\n",
      "iters: 55\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 56/200...  loss: 0.000000000010792...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 56/200...  loss: 0.000000000017264...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 56/200...  loss: 0.000000000016629...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 56/200...  loss: 0.000000000011842...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 56/200...  loss: 0.000000000067801...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 56/200...  loss: 0.000000000019280...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 56/200...  loss: 0.000000000014794...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 56/200...  loss: 0.000000000014991...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 56/200...  loss: 0.000000000012248...  0.0080 sec/batch\n",
      "iters: 56\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 57/200...  loss: 0.000000019740417...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 57/200...  loss: 0.000000141579122...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 57/200...  loss: 0.000000041512877...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 57/200...  loss: 0.000000033691780...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 57/200...  loss: 0.000000065747578...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 57/200...  loss: 0.000000476785431...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 57/200...  loss: 0.000000104319540...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 57/200...  loss: 0.000000045278718...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 57/200...  loss: 0.000000028465724...  0.0080 sec/batch\n",
      "iters: 57\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 58/200...  loss: 0.000000030866399...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 58/200...  loss: 0.000000027390762...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 58/200...  loss: 0.000000017162376...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 58/200...  loss: 0.000000012320359...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 58/200...  loss: 0.000000136013483...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 58/200...  loss: 0.000000012917243...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 58/200...  loss: 0.000000008982314...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 58/200...  loss: 0.000000008254233...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 58/200...  loss: 0.000000006063033...  0.0080 sec/batch\n",
      "iters: 58\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 59/200...  loss: 0.000000009850567...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 59/200...  loss: 0.000000008822261...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 59/200...  loss: 0.000000007061868...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 59/200...  loss: 0.000000005064390...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 59/200...  loss: 0.000000050029932...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 59/200...  loss: 0.000000005252057...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 59/200...  loss: 0.000000004561444...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 59/200...  loss: 0.000000002788884...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 59/200...  loss: 0.000000002599607...  0.0080 sec/batch\n",
      "iters: 59\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 60/200...  loss: 0.000000002922663...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 60/200...  loss: 0.000000002801458...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 60/200...  loss: 0.000000002387397...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 60/200...  loss: 0.000000001709812...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 60/200...  loss: 0.000000028972179...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 60/200...  loss: 0.000000001603545...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 60/200...  loss: 0.000000001563639...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 60/200...  loss: 0.000000000975694...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 60/200...  loss: 0.000000000911405...  0.0090 sec/batch\n",
      "iters: 60\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 61/200...  loss: 0.000000001036186...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 61/200...  loss: 0.000000000882226...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 61/200...  loss: 0.000000000809501...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 61/200...  loss: 0.000000000584902...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 61/200...  loss: 0.000000016396530...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 61/200...  loss: 0.000000000625095...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 61/200...  loss: 0.000000000500299...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 61/200...  loss: 0.000000000326545...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 61/200...  loss: 0.000000000295278...  0.0070 sec/batch\n",
      "iters: 61\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 62/200...  loss: 0.000000000305285...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 62/200...  loss: 0.000000000277571...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 62/200...  loss: 0.000000000224073...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 62/200...  loss: 0.000000000161413...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 62/200...  loss: 0.000000009146770...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 62/200...  loss: 0.000000000179684...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 62/200...  loss: 0.000000000143419...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 62/200...  loss: 0.000000000097703...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 62/200...  loss: 0.000000000090386...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters: 62\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 63/200...  loss: 0.000000000080497...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 63/200...  loss: 0.000000000073742...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 63/200...  loss: 0.000000000058139...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 63/200...  loss: 0.000000000043616...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 63/200...  loss: 0.000000004691506...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 63/200...  loss: 0.000000000062568...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 63/200...  loss: 0.000000000049171...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 63/200...  loss: 0.000000000034210...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 63/200...  loss: 0.000000000032115...  0.0080 sec/batch\n",
      "iters: 63\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 64/200...  loss: 0.000000000030690...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 64/200...  loss: 0.000000000028286...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 64/200...  loss: 0.000000000021365...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 64/200...  loss: 0.000000000015398...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 64/200...  loss: 0.000000002119098...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 64/200...  loss: 0.000000000020040...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 64/200...  loss: 0.000000000017010...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 64/200...  loss: 0.000000000012811...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 64/200...  loss: 0.000000000012297...  0.0080 sec/batch\n",
      "iters: 64\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 65/200...  loss: 0.000000000010508...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 65/200...  loss: 0.000000000009990...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 65/200...  loss: 0.000000000007806...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 65/200...  loss: 0.000000000006149...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 65/200...  loss: 0.000000000667086...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 65/200...  loss: 0.000000000010533...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 65/200...  loss: 0.000000000008980...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 65/200...  loss: 0.000000000006629...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 65/200...  loss: 0.000000000006302...  0.0080 sec/batch\n",
      "iters: 65\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 66/200...  loss: 0.000000000007110...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 66/200...  loss: 0.000000000006632...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 66/200...  loss: 0.000000000005082...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 66/200...  loss: 0.000000000003623...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 66/200...  loss: 0.000000000293341...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 66/200...  loss: 0.000000000004582...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 66/200...  loss: 0.000000000004185...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 66/200...  loss: 0.000000000003303...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 66/200...  loss: 0.000000000003178...  0.0080 sec/batch\n",
      "iters: 66\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 67/200...  loss: 0.000000000003812...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 67/200...  loss: 0.000000000003611...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 67/200...  loss: 0.000000000002991...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 67/200...  loss: 0.000000000002200...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 67/200...  loss: 0.000000000236860...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 67/200...  loss: 0.000000000002974...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 67/200...  loss: 0.000000000002699...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 67/200...  loss: 0.000000000002104...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 67/200...  loss: 0.000000000001999...  0.0080 sec/batch\n",
      "iters: 67\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 68/200...  loss: 0.000000000001587...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 68/200...  loss: 0.000000000001603...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 68/200...  loss: 0.000000000001442...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 68/200...  loss: 0.000000000001164...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 68/200...  loss: 0.000000000096297...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 68/200...  loss: 0.000000000001821...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 68/200...  loss: 0.000000000001688...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 68/200...  loss: 0.000000000001251...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 68/200...  loss: 0.000000000001215...  0.0080 sec/batch\n",
      "iters: 68\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 69/200...  loss: 0.000000000001723...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 69/200...  loss: 0.000003703113634...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 69/200...  loss: 0.000000164376885...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 69/200...  loss: 0.000000011011743...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 69/200...  loss: 0.000000022470566...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 69/200...  loss: 0.000000007178125...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 69/200...  loss: 0.000000006250210...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 69/200...  loss: 0.000000004720497...  0.0100 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 69/200...  loss: 0.000000004207546...  0.0080 sec/batch\n",
      "iters: 69\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 70/200...  loss: 0.000000007311920...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 70/200...  loss: 0.000000018998485...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 70/200...  loss: 0.000000009331060...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 70/200...  loss: 0.000000005255492...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 70/200...  loss: 0.000000007785497...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 70/200...  loss: 0.000000003667776...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 70/200...  loss: 0.000000003109403...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 70/200...  loss: 0.000000014596374...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 70/200...  loss: 0.000000002046797...  0.0090 sec/batch\n",
      "iters: 70\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 71/200...  loss: 0.000000000945414...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 71/200...  loss: 0.000000000411207...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 71/200...  loss: 0.000000000606171...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 71/200...  loss: 0.000000000926968...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 71/200...  loss: 0.000000004041060...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 71/200...  loss: 0.000000000967588...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 71/200...  loss: 0.000000000864525...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 71/200...  loss: 0.000000000609259...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 71/200...  loss: 0.000000000586613...  0.0080 sec/batch\n",
      "iters: 71\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 72/200...  loss: 0.000000000574293...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 72/200...  loss: 0.000000000923983...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 72/200...  loss: 0.000000000796847...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 72/200...  loss: 0.000000000577541...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 72/200...  loss: 0.000000003443021...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 72/200...  loss: 0.000000000564531...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 72/200...  loss: 0.000000000497488...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 72/200...  loss: 0.000000000372566...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 72/200...  loss: 0.000000000347592...  0.0080 sec/batch\n",
      "iters: 72\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 73/200...  loss: 0.000000000372309...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 73/200...  loss: 0.000000000361316...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 73/200...  loss: 0.000000000345145...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 73/200...  loss: 0.000000000257648...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 73/200...  loss: 0.000000002284886...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 73/200...  loss: 0.000000000266424...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 73/200...  loss: 0.000000000243009...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 73/200...  loss: 0.000000000190042...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 73/200...  loss: 0.000000000176992...  0.0090 sec/batch\n",
      "iters: 73\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 74/200...  loss: 0.000000000190072...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 74/200...  loss: 0.000000000180782...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 74/200...  loss: 0.000000000170375...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 74/200...  loss: 0.000000000125430...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 74/200...  loss: 0.000000001444080...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 74/200...  loss: 0.000000000132387...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 74/200...  loss: 0.000000000123971...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 74/200...  loss: 0.000000000101494...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 74/200...  loss: 0.000000000094453...  0.0080 sec/batch\n",
      "iters: 74\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 75/200...  loss: 0.000000000097906...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 75/200...  loss: 0.000000000089952...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 75/200...  loss: 0.000000000084273...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 75/200...  loss: 0.000000000064620...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 75/200...  loss: 0.000000000879469...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 75/200...  loss: 0.000000000069129...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 75/200...  loss: 0.000000000065561...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 75/200...  loss: 0.000000000056233...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 75/200...  loss: 0.000000000052409...  0.0080 sec/batch\n",
      "iters: 75\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 76/200...  loss: 0.000000000047066...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 76/200...  loss: 0.000000000042693...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 76/200...  loss: 0.000000000041656...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 76/200...  loss: 0.000000000037252...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 76/200...  loss: 0.000000000536718...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 76/200...  loss: 0.000000000034755...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 76/200...  loss: 0.000000000033359...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 76/200...  loss: 0.000000000030644...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 76/200...  loss: 0.000000000029108...  0.0080 sec/batch\n",
      "iters: 76\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 77/200...  loss: 0.000000000025407...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 77/200...  loss: 0.000000000022455...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 77/200...  loss: 0.000000000021719...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 77/200...  loss: 0.000000000021494...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 77/200...  loss: 0.000000000290822...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 77/200...  loss: 0.000000000019623...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 77/200...  loss: 0.000000000018968...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 77/200...  loss: 0.000000000018630...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 77/200...  loss: 0.000000000017732...  0.0090 sec/batch\n",
      "iters: 77\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 78/200...  loss: 0.000000000015486...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 78/200...  loss: 0.000000000013928...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 78/200...  loss: 0.000000000014139...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 78/200...  loss: 0.000000000015312...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 78/200...  loss: 0.000000000173456...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 78/200...  loss: 0.000000000011911...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 78/200...  loss: 0.000000000011556...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 78/200...  loss: 0.000000000012125...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 78/200...  loss: 0.000000000011579...  0.0090 sec/batch\n",
      "iters: 78\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 79/200...  loss: 0.000000000009562...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 79/200...  loss: 0.000000000008824...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 79/200...  loss: 0.000000000009373...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 79/200...  loss: 0.000000000010748...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 79/200...  loss: 0.000000000112904...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 79/200...  loss: 0.000000000008109...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 79/200...  loss: 0.000000000007873...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 79/200...  loss: 0.000000000008555...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 79/200...  loss: 0.000000000008181...  0.0080 sec/batch\n",
      "iters: 79\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 80/200...  loss: 0.000000000006561...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 80/200...  loss: 0.000000000006187...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 80/200...  loss: 0.000000000006801...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 80/200...  loss: 0.000000000007974...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 80/200...  loss: 0.000000000080714...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 80/200...  loss: 0.000000000006013...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 80/200...  loss: 0.000000000005844...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 80/200...  loss: 0.000000000006499...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 80/200...  loss: 0.000000000006227...  0.0090 sec/batch\n",
      "iters: 80\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 81/200...  loss: 0.000000000004902...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 81/200...  loss: 0.000000000004708...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 81/200...  loss: 0.000000000005254...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 81/200...  loss: 0.000000000006205...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 81/200...  loss: 0.000000000063031...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 81/200...  loss: 0.000000000004737...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 81/200...  loss: 0.000000000004610...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 81/200...  loss: 0.000000000005199...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 81/200...  loss: 0.000000000004996...  0.0100 sec/batch\n",
      "iters: 81\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 82/200...  loss: 0.000000000003895...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 82/200...  loss: 0.000000000003792...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 82/200...  loss: 0.000000000004254...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 82/200...  loss: 0.000000000005032...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 82/200...  loss: 0.000000000052175...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 82/200...  loss: 0.000000000003898...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 82/200...  loss: 0.000000000003802...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 82/200...  loss: 0.000000000004320...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 82/200...  loss: 0.000000000004162...  0.0080 sec/batch\n",
      "iters: 82\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 83/200...  loss: 0.000000000003234...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 83/200...  loss: 0.000000000003178...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 83/200...  loss: 0.000000000003564...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 83/200...  loss: 0.000000000004211...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 83/200...  loss: 0.000000000044835...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 83/200...  loss: 0.000000000003306...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 83/200...  loss: 0.000000000003232...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 83/200...  loss: 0.000000000003687...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 83/200...  loss: 0.000000000003559...  0.0110 sec/batch\n",
      "iters: 83\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 84/200...  loss: 0.000000000002764...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 84/200...  loss: 0.000000000002732...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 84/200...  loss: 0.000000000003061...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 84/200...  loss: 0.000000000003607...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 84/200...  loss: 0.000000000039465...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 84/200...  loss: 0.000000000002868...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 84/200...  loss: 0.000000000002807...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 84/200...  loss: 0.000000000003207...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 84/200...  loss: 0.000000000003101...  0.0080 sec/batch\n",
      "iters: 84\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 85/200...  loss: 0.000000000002415...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 85/200...  loss: 0.000000000002401...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 85/200...  loss: 0.000000000002680...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 85/200...  loss: 0.000000000003146...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 85/200...  loss: 0.000000000035372...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 85/200...  loss: 0.000000000002528...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 85/200...  loss: 0.000000000002478...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 85/200...  loss: 0.000000000002830...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 85/200...  loss: 0.000000000002742...  0.0080 sec/batch\n",
      "iters: 85\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 86/200...  loss: 0.000000000002143...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 86/200...  loss: 0.000000000002138...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 86/200...  loss: 0.000000000002378...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 86/200...  loss: 0.000000000002781...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 86/200...  loss: 0.000000000032078...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 86/200...  loss: 0.000000000002257...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 86/200...  loss: 0.000000000002215...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 86/200...  loss: 0.000000000002527...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 86/200...  loss: 0.000000000002452...  0.0090 sec/batch\n",
      "iters: 86\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 87/200...  loss: 0.000000000001924...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 87/200...  loss: 0.000000000001925...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 87/200...  loss: 0.000000000002133...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 87/200...  loss: 0.000000000002485...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 87/200...  loss: 0.000000000029436...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 87/200...  loss: 0.000000000002034...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 87/200...  loss: 0.000000000001998...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 87/200...  loss: 0.000000000002276...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 87/200...  loss: 0.000000000002212...  0.0090 sec/batch\n",
      "iters: 87\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 88/200...  loss: 0.000000000001745...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 88/200...  loss: 0.000000000001749...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 88/200...  loss: 0.000000000001931...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 88/200...  loss: 0.000000000002241...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 88/200...  loss: 0.000000000027207...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 88/200...  loss: 0.000000000001849...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 88/200...  loss: 0.000000000001818...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 88/200...  loss: 0.000000000002067...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 88/200...  loss: 0.000000000002011...  0.0080 sec/batch\n",
      "iters: 88\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 89/200...  loss: 0.000000000001595...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 89/200...  loss: 0.000000000001601...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 89/200...  loss: 0.000000000001761...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 89/200...  loss: 0.000000000002036...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 89/200...  loss: 0.000000000025321...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 89/200...  loss: 0.000000000001691...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 89/200...  loss: 0.000000000001664...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 89/200...  loss: 0.000000000001889...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 89/200...  loss: 0.000000000001840...  0.0080 sec/batch\n",
      "iters: 89\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 90/200...  loss: 0.000000000001467...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 90/200...  loss: 0.000000000001473...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 90/200...  loss: 0.000000000001615...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 90/200...  loss: 0.000000000001860...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 90/200...  loss: 0.000000000023687...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 90/200...  loss: 0.000000000001555...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 90/200...  loss: 0.000000000001532...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 90/200...  loss: 0.000000000001735...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 90/200...  loss: 0.000000000001691...  0.0080 sec/batch\n",
      "iters: 90\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 91/200...  loss: 0.000000000001356...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 91/200...  loss: 0.000000000001363...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 91/200...  loss: 0.000000000001490...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 91/200...  loss: 0.000000000001710...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 91/200...  loss: 0.000000000022276...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 91/200...  loss: 0.000000000001438...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 91/200...  loss: 0.000000000001417...  0.0160 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 91/200...  loss: 0.000000000001601...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 91/200...  loss: 0.000000000001563...  0.0090 sec/batch\n",
      "iters: 91\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 92/200...  loss: 0.000000000001260...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 92/200...  loss: 0.000000000001268...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 92/200...  loss: 0.000000000001381...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 92/200...  loss: 0.000000000001579...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 92/200...  loss: 0.000000000021024...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 92/200...  loss: 0.000000000001335...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 92/200...  loss: 0.000000000001317...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 92/200...  loss: 0.000000000001485...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 92/200...  loss: 0.000000000001451...  0.0080 sec/batch\n",
      "iters: 92\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 93/200...  loss: 0.000000000001176...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 93/200...  loss: 0.000000000001183...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 93/200...  loss: 0.000000000001285...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 93/200...  loss: 0.000000000001465...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 93/200...  loss: 0.000000000019925...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 93/200...  loss: 0.000000000001244...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 93/200...  loss: 0.000000000001228...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 93/200...  loss: 0.000000000001383...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 93/200...  loss: 0.000000000001352...  0.0080 sec/batch\n",
      "iters: 93\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 94/200...  loss: 0.000000000001100...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 94/200...  loss: 0.000000000001108...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 94/200...  loss: 0.000000000001199...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 94/200...  loss: 0.000000000001363...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 94/200...  loss: 0.000000000018932...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 94/200...  loss: 0.000000000001163...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 94/200...  loss: 0.000000000001148...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 94/200...  loss: 0.000000000001291...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 94/200...  loss: 0.000000000001263...  0.0080 sec/batch\n",
      "iters: 94\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 95/200...  loss: 0.000000000001033...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 95/200...  loss: 0.000000000001041...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 95/200...  loss: 0.000000000001124...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 95/200...  loss: 0.000000000001274...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 95/200...  loss: 0.000000000018049...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 95/200...  loss: 0.000000000001091...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 95/200...  loss: 0.000000000001078...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 95/200...  loss: 0.000000000001210...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 95/200...  loss: 0.000000000001184...  0.0090 sec/batch\n",
      "iters: 95\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 96/200...  loss: 0.000000000000973...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 96/200...  loss: 0.000000000000981...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 96/200...  loss: 0.000000000001056...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 96/200...  loss: 0.000000000001194...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 96/200...  loss: 0.000000000017253...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 96/200...  loss: 0.000000000001027...  0.0130 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 96/200...  loss: 0.000000000001015...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 96/200...  loss: 0.000000000001137...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 96/200...  loss: 0.000000000001114...  0.0090 sec/batch\n",
      "iters: 96\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 97/200...  loss: 0.000000000000919...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 97/200...  loss: 0.000000000000926...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 97/200...  loss: 0.000000000000995...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 97/200...  loss: 0.000000000001122...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 97/200...  loss: 0.000000000016525...  0.0130 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 97/200...  loss: 0.000000000000969...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 97/200...  loss: 0.000000000000957...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 97/200...  loss: 0.000000000001072...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 97/200...  loss: 0.000000000001050...  0.0080 sec/batch\n",
      "iters: 97\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 98/200...  loss: 0.000000000000870...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 98/200...  loss: 0.000000000000877...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 98/200...  loss: 0.000000000000940...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 98/200...  loss: 0.000000000001058...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 98/200...  loss: 0.000000000015862...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 98/200...  loss: 0.000000000000916...  0.0130 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 98/200...  loss: 0.000000000000905...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 98/200...  loss: 0.000000000001012...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 98/200...  loss: 0.000000000000992...  0.0080 sec/batch\n",
      "iters: 98\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 99/200...  loss: 0.000000000000825...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 99/200...  loss: 0.000000000000832...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 99/200...  loss: 0.000000000000889...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 99/200...  loss: 0.000000000000999...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 99/200...  loss: 0.000000000015252...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 99/200...  loss: 0.000000000000867...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 99/200...  loss: 0.000000000000858...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 99/200...  loss: 0.000000000000958...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 99/200...  loss: 0.000000000000940...  0.0090 sec/batch\n",
      "iters: 99\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 100/200...  loss: 0.000000000000784...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 100/200...  loss: 0.000000000000790...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 100/200...  loss: 0.000000000000843...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 100/200...  loss: 0.000000000000945...  0.0140 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 100/200...  loss: 0.000000000014695...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 100/200...  loss: 0.000000000000823...  0.0170 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 100/200...  loss: 0.000000000000814...  0.0130 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 100/200...  loss: 0.000000000000908...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 100/200...  loss: 0.000000000000891...  0.0090 sec/batch\n",
      "iters: 100\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 101/200...  loss: 0.000000000000746...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 101/200...  loss: 0.000000000000752...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 101/200...  loss: 0.000000000000801...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 101/200...  loss: 0.000000000000897...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 101/200...  loss: 0.000000000014179...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 101/200...  loss: 0.000000000000783...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 101/200...  loss: 0.000000000000775...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 101/200...  loss: 0.000000000000863...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 101/200...  loss: 0.000000000000848...  0.0090 sec/batch\n",
      "iters: 101\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 102/200...  loss: 0.000000000000712...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 102/200...  loss: 0.000000000000718...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 102/200...  loss: 0.000000000000763...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 102/200...  loss: 0.000000000000852...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 102/200...  loss: 0.000000000013702...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 102/200...  loss: 0.000000000000746...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 102/200...  loss: 0.000000000000738...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 102/200...  loss: 0.000000000000822...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 102/200...  loss: 0.000000000000807...  0.0080 sec/batch\n",
      "iters: 102\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 103/200...  loss: 0.000000000000680...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 103/200...  loss: 0.000000000000686...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 103/200...  loss: 0.000000000000727...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 103/200...  loss: 0.000000000000812...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 103/200...  loss: 0.000000000013257...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 103/200...  loss: 0.000000000000711...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 103/200...  loss: 0.000000000000704...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 103/200...  loss: 0.000000000000783...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 103/200...  loss: 0.000000000000770...  0.0090 sec/batch\n",
      "iters: 103\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 104/200...  loss: 0.000000000000651...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 104/200...  loss: 0.000000000000656...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 104/200...  loss: 0.000000000000695...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 104/200...  loss: 0.000000000000774...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 104/200...  loss: 0.000000000012843...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 104/200...  loss: 0.000000000000680...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 104/200...  loss: 0.000000000000673...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 104/200...  loss: 0.000000000000748...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 104/200...  loss: 0.000000000000736...  0.0080 sec/batch\n",
      "iters: 104\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 105/200...  loss: 0.000000000000623...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 105/200...  loss: 0.000000000000628...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 105/200...  loss: 0.000000000000664...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 105/200...  loss: 0.000000000000739...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 105/200...  loss: 0.000000000012455...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 105/200...  loss: 0.000000000000650...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 105/200...  loss: 0.000000000000644...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 105/200...  loss: 0.000000000000716...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 105/200...  loss: 0.000000000000704...  0.0090 sec/batch\n",
      "iters: 105\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 106/200...  loss: 0.000000000000599...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 106/200...  loss: 0.000000000000602...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 106/200...  loss: 0.000000000000636...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 106/200...  loss: 0.000000000000707...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 106/200...  loss: 0.000000000012093...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 106/200...  loss: 0.000000000000623...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 106/200...  loss: 0.000000000000618...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 106/200...  loss: 0.000000000000685...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 106/200...  loss: 0.000000000000674...  0.0100 sec/batch\n",
      "iters: 106\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 107/200...  loss: 0.000000000000574...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 107/200...  loss: 0.000000000000578...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 107/200...  loss: 0.000000000000610...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 107/200...  loss: 0.000000000000677...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 107/200...  loss: 0.000000000011753...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 107/200...  loss: 0.000000000000598...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 107/200...  loss: 0.000000000000592...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 107/200...  loss: 0.000000000000657...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 107/200...  loss: 0.000000000000647...  0.0080 sec/batch\n",
      "iters: 107\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 108/200...  loss: 0.000000000000552...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 108/200...  loss: 0.000000000000556...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 108/200...  loss: 0.000000000000586...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 108/200...  loss: 0.000000000000650...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 108/200...  loss: 0.000000000011434...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 108/200...  loss: 0.000000000000574...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 108/200...  loss: 0.000000000000569...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 108/200...  loss: 0.000000000000631...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 108/200...  loss: 0.000000000000621...  0.0080 sec/batch\n",
      "iters: 108\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 109/200...  loss: 0.000000000000531...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 109/200...  loss: 0.000000000000536...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 109/200...  loss: 0.000000000000563...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 109/200...  loss: 0.000000000000624...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 109/200...  loss: 0.000000000011132...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 109/200...  loss: 0.000000000000552...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 109/200...  loss: 0.000000000000548...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 109/200...  loss: 0.000000000000607...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 109/200...  loss: 0.000000000000597...  0.0100 sec/batch\n",
      "iters: 109\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 110/200...  loss: 0.000000000000512...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 110/200...  loss: 0.000000000000516...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 110/200...  loss: 0.000000000000542...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 110/200...  loss: 0.000000000000600...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 110/200...  loss: 0.000000000010848...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 110/200...  loss: 0.000000000000532...  0.0140 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 110/200...  loss: 0.000000000000527...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 110/200...  loss: 0.000000000000584...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 110/200...  loss: 0.000000000000575...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters: 110\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 111/200...  loss: 0.000000000000493...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 111/200...  loss: 0.000000000000497...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 111/200...  loss: 0.000000000000521...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 111/200...  loss: 0.000000000000577...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 111/200...  loss: 0.000000000010578...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 111/200...  loss: 0.000000000000512...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 111/200...  loss: 0.000000000000508...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 111/200...  loss: 0.000000000000563...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 111/200...  loss: 0.000000000000554...  0.0080 sec/batch\n",
      "iters: 111\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 112/200...  loss: 0.000000000000476...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 112/200...  loss: 0.000000000000480...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 112/200...  loss: 0.000000000000503...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 112/200...  loss: 0.000000000000556...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 112/200...  loss: 0.000000000010322...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 112/200...  loss: 0.000000000000494...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 112/200...  loss: 0.000000000000490...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 112/200...  loss: 0.000000000000543...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 112/200...  loss: 0.000000000000534...  0.0080 sec/batch\n",
      "iters: 112\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 113/200...  loss: 0.000000000000460...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 113/200...  loss: 0.000000000000464...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 113/200...  loss: 0.000000000000485...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 113/200...  loss: 0.000000000000536...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 113/200...  loss: 0.000000000010076...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 113/200...  loss: 0.000000000000477...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 113/200...  loss: 0.000000000000473...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 113/200...  loss: 0.000000000000524...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 113/200...  loss: 0.000000000000516...  0.0070 sec/batch\n",
      "iters: 113\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 114/200...  loss: 0.000000000000445...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 114/200...  loss: 0.000000000000449...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 114/200...  loss: 0.000000000000469...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 114/200...  loss: 0.000000000000518...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 114/200...  loss: 0.000000000009846...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 114/200...  loss: 0.000000000000461...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 114/200...  loss: 0.000000000000457...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 114/200...  loss: 0.000000000000506...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 114/200...  loss: 0.000000000000499...  0.0100 sec/batch\n",
      "iters: 114\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 115/200...  loss: 0.000000000000430...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 115/200...  loss: 0.000000000000434...  0.0140 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 115/200...  loss: 0.000000000000453...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 115/200...  loss: 0.000000000000500...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 115/200...  loss: 0.000000000009624...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 115/200...  loss: 0.000000000000445...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 115/200...  loss: 0.000000000000442...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 115/200...  loss: 0.000000000000489...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 115/200...  loss: 0.000000000000482...  0.0090 sec/batch\n",
      "iters: 115\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 116/200...  loss: 0.000000000000417...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 116/200...  loss: 0.000000000000420...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 116/200...  loss: 0.000000000000438...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 116/200...  loss: 0.000000000000484...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 116/200...  loss: 0.000000000009411...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 116/200...  loss: 0.000000000000431...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 116/200...  loss: 0.000000000000428...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 116/200...  loss: 0.000000000000473...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 116/200...  loss: 0.000000000000467...  0.0080 sec/batch\n",
      "iters: 116\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 117/200...  loss: 0.000000000000404...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 117/200...  loss: 0.000000000000407...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 117/200...  loss: 0.000000000000424...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 117/200...  loss: 0.000000000000468...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 117/200...  loss: 0.000000000009211...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 117/200...  loss: 0.000000000000417...  0.0150 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 117/200...  loss: 0.000000000000414...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 117/200...  loss: 0.000000000000458...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 117/200...  loss: 0.000000000000452...  0.0090 sec/batch\n",
      "iters: 117\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 118/200...  loss: 0.000000000000392...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 118/200...  loss: 0.000000000000395...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 118/200...  loss: 0.000000000000411...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 118/200...  loss: 0.000000000000453...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 118/200...  loss: 0.000000000009021...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 118/200...  loss: 0.000000000000404...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 118/200...  loss: 0.000000000000402...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 118/200...  loss: 0.000000000000444...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 118/200...  loss: 0.000000000000438...  0.0080 sec/batch\n",
      "iters: 118\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 119/200...  loss: 0.000000000000380...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 119/200...  loss: 0.000000000000383...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 119/200...  loss: 0.000000000000399...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 119/200...  loss: 0.000000000000439...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 119/200...  loss: 0.000000000008837...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 119/200...  loss: 0.000000000000392...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 119/200...  loss: 0.000000000000389...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 119/200...  loss: 0.000000000000431...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 119/200...  loss: 0.000000000000425...  0.0080 sec/batch\n",
      "iters: 119\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 120/200...  loss: 0.000000000000369...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 120/200...  loss: 0.000000000000372...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 120/200...  loss: 0.000000000000387...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 120/200...  loss: 0.000000000000426...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 120/200...  loss: 0.000000000008661...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 120/200...  loss: 0.000000000000381...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 120/200...  loss: 0.000000000000378...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 120/200...  loss: 0.000000000000418...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 120/200...  loss: 0.000000000000412...  0.0080 sec/batch\n",
      "iters: 120\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 121/200...  loss: 0.000000000000358...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 121/200...  loss: 0.000000000000361...  0.0180 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 121/200...  loss: 0.000000000000375...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 121/200...  loss: 0.000000000000414...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 121/200...  loss: 0.000000000008491...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 121/200...  loss: 0.000000000000369...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 121/200...  loss: 0.000000000000367...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 121/200...  loss: 0.000000000000406...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 121/200...  loss: 0.000000000000400...  0.0080 sec/batch\n",
      "iters: 121\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 122/200...  loss: 0.000000000000348...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 122/200...  loss: 0.000000000000351...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 122/200...  loss: 0.000000000000364...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 122/200...  loss: 0.000000000000402...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 122/200...  loss: 0.000000000008329...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 122/200...  loss: 0.000000000000359...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 122/200...  loss: 0.000000000000357...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 122/200...  loss: 0.000000000000394...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 122/200...  loss: 0.000000000000389...  0.0080 sec/batch\n",
      "iters: 122\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 123/200...  loss: 0.000000000000339...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 123/200...  loss: 0.000000000000341...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 123/200...  loss: 0.000000000000354...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 123/200...  loss: 0.000000000000390...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 123/200...  loss: 0.000000000008173...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 123/200...  loss: 0.000000000000349...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 123/200...  loss: 0.000000000000347...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 123/200...  loss: 0.000000000000383...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 123/200...  loss: 0.000000000000378...  0.0080 sec/batch\n",
      "iters: 123\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 124/200...  loss: 0.000000000000330...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 124/200...  loss: 0.000000000000332...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 124/200...  loss: 0.000000000000344...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 124/200...  loss: 0.000000000000380...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 124/200...  loss: 0.000000000008020...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 124/200...  loss: 0.000000000000339...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 124/200...  loss: 0.000000000000337...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 124/200...  loss: 0.000000000000373...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 124/200...  loss: 0.000000000000368...  0.0090 sec/batch\n",
      "iters: 124\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 125/200...  loss: 0.000000000000321...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 125/200...  loss: 0.000000000000323...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 125/200...  loss: 0.000000000000335...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 125/200...  loss: 0.000000000000369...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 125/200...  loss: 0.000000000007877...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 125/200...  loss: 0.000000000000330...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 125/200...  loss: 0.000000000000328...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 125/200...  loss: 0.000000000000363...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 125/200...  loss: 0.000000000000358...  0.0080 sec/batch\n",
      "iters: 125\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 126/200...  loss: 0.000000000000313...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 126/200...  loss: 0.000000000000315...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 126/200...  loss: 0.000000000000326...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 126/200...  loss: 0.000000000000359...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 126/200...  loss: 0.000000000007737...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 126/200...  loss: 0.000000000000322...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 126/200...  loss: 0.000000000000319...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 126/200...  loss: 0.000000000000354...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 126/200...  loss: 0.000000000000349...  0.0080 sec/batch\n",
      "iters: 126\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 127/200...  loss: 0.000000000000305...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 127/200...  loss: 0.000000000000307...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 127/200...  loss: 0.000000000000318...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 127/200...  loss: 0.000000000000350...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 127/200...  loss: 0.000000000007603...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 127/200...  loss: 0.000000000000313...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 127/200...  loss: 0.000000000000311...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 127/200...  loss: 0.000000000000345...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 127/200...  loss: 0.000000000000340...  0.0080 sec/batch\n",
      "iters: 127\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 128/200...  loss: 0.000000000000297...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 128/200...  loss: 0.000000000000299...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 128/200...  loss: 0.000000000000309...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 128/200...  loss: 0.000000000000341...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 128/200...  loss: 0.000000000007473...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 128/200...  loss: 0.000000000000305...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 128/200...  loss: 0.000000000000303...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 128/200...  loss: 0.000000000000336...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 128/200...  loss: 0.000000000000332...  0.0090 sec/batch\n",
      "iters: 128\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 129/200...  loss: 0.000000000000290...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 129/200...  loss: 0.000000000000292...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 129/200...  loss: 0.000000000000302...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 129/200...  loss: 0.000000000000333...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 129/200...  loss: 0.000000000007347...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 129/200...  loss: 0.000000000000298...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 129/200...  loss: 0.000000000000296...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 129/200...  loss: 0.000000000000328...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 129/200...  loss: 0.000000000000324...  0.0080 sec/batch\n",
      "iters: 129\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 130/200...  loss: 0.000000000000283...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 130/200...  loss: 0.000000000000285...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 130/200...  loss: 0.000000000000294...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 130/200...  loss: 0.000000000000325...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 130/200...  loss: 0.000000000007224...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 130/200...  loss: 0.000000000000290...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 130/200...  loss: 0.000000000000289...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 130/200...  loss: 0.000000000000320...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 130/200...  loss: 0.000000000000316...  0.0080 sec/batch\n",
      "iters: 130\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 131/200...  loss: 0.000000000000276...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 131/200...  loss: 0.000000000000278...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 131/200...  loss: 0.000000000000287...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 131/200...  loss: 0.000000000000317...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 131/200...  loss: 0.000000000007107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 131/200...  loss: 0.000000000000283...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 131/200...  loss: 0.000000000000282...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 131/200...  loss: 0.000000000000312...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 131/200...  loss: 0.000000000000309...  0.0090 sec/batch\n",
      "iters: 131\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 132/200...  loss: 0.000000000000270...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 132/200...  loss: 0.000000000000272...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 132/200...  loss: 0.000000000000280...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 132/200...  loss: 0.000000000000309...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 132/200...  loss: 0.000000000006994...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 132/200...  loss: 0.000000000000276...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 132/200...  loss: 0.000000000000275...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 132/200...  loss: 0.000000000000305...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 132/200...  loss: 0.000000000000301...  0.0080 sec/batch\n",
      "iters: 132\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 133/200...  loss: 0.000000000000264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 133/200...  loss: 0.000000000000266...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 133/200...  loss: 0.000000000000274...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 133/200...  loss: 0.000000000000302...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 133/200...  loss: 0.000000000006884...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 133/200...  loss: 0.000000000000270...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 133/200...  loss: 0.000000000000269...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 133/200...  loss: 0.000000000000298...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 133/200...  loss: 0.000000000000294...  0.0080 sec/batch\n",
      "iters: 133\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 134/200...  loss: 0.000000000000258...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 134/200...  loss: 0.000000000000260...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 134/200...  loss: 0.000000000000267...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 134/200...  loss: 0.000000000000295...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 134/200...  loss: 0.000000000006776...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 134/200...  loss: 0.000000000000264...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 134/200...  loss: 0.000000000000263...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 134/200...  loss: 0.000000000000291...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 134/200...  loss: 0.000000000000288...  0.0080 sec/batch\n",
      "iters: 134\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 135/200...  loss: 0.000000000000252...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 135/200...  loss: 0.000000000000254...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 135/200...  loss: 0.000000000000261...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 135/200...  loss: 0.000000000000288...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 135/200...  loss: 0.000000000006672...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 135/200...  loss: 0.000000000000258...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 135/200...  loss: 0.000000000000257...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 135/200...  loss: 0.000000000000285...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 135/200...  loss: 0.000000000000281...  0.0080 sec/batch\n",
      "iters: 135\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 136/200...  loss: 0.000000000000246...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 136/200...  loss: 0.000000000000248...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 136/200...  loss: 0.000000000000255...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 136/200...  loss: 0.000000000000282...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 136/200...  loss: 0.000000000006572...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 136/200...  loss: 0.000000000000252...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 136/200...  loss: 0.000000000000251...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 136/200...  loss: 0.000000000000279...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 136/200...  loss: 0.000000000000275...  0.0090 sec/batch\n",
      "iters: 136\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 137/200...  loss: 0.000000000000241...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 137/200...  loss: 0.000000000000243...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 137/200...  loss: 0.000000000000250...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 137/200...  loss: 0.000000000000276...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 137/200...  loss: 0.000000000006474...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 137/200...  loss: 0.000000000000247...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 137/200...  loss: 0.000000000000245...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 137/200...  loss: 0.000000000000272...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 137/200...  loss: 0.000000000000269...  0.0080 sec/batch\n",
      "iters: 137\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 138/200...  loss: 0.000000000000236...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 138/200...  loss: 0.000000000000238...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 138/200...  loss: 0.000000000000244...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 138/200...  loss: 0.000000000000270...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 138/200...  loss: 0.000000000006380...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 138/200...  loss: 0.000000000000241...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 138/200...  loss: 0.000000000000240...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 138/200...  loss: 0.000000000000267...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 138/200...  loss: 0.000000000000264...  0.0080 sec/batch\n",
      "iters: 138\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 139/200...  loss: 0.000000000000231...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 139/200...  loss: 0.000000000000233...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 139/200...  loss: 0.000000000000239...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 139/200...  loss: 0.000000000000264...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 139/200...  loss: 0.000000000006288...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 139/200...  loss: 0.000000000000236...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 139/200...  loss: 0.000000000000235...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 139/200...  loss: 0.000000000000261...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 139/200...  loss: 0.000000000000258...  0.0100 sec/batch\n",
      "iters: 139\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 140/200...  loss: 0.000000000000226...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 140/200...  loss: 0.000000000000228...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 140/200...  loss: 0.000000000000234...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 140/200...  loss: 0.000000000000259...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 140/200...  loss: 0.000000000006197...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 140/200...  loss: 0.000000000000231...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 140/200...  loss: 0.000000000000230...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 140/200...  loss: 0.000000000000256...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 140/200...  loss: 0.000000000000253...  0.0100 sec/batch\n",
      "iters: 140\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 141/200...  loss: 0.000000000000222...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 141/200...  loss: 0.000000000000223...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 141/200...  loss: 0.000000000000229...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 141/200...  loss: 0.000000000000254...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 141/200...  loss: 0.000000000006112...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 141/200...  loss: 0.000000000000227...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 141/200...  loss: 0.000000000000226...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 141/200...  loss: 0.000000000000251...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 141/200...  loss: 0.000000000000248...  0.0080 sec/batch\n",
      "iters: 141\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 142/200...  loss: 0.000000000000217...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 142/200...  loss: 0.000000000000219...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 142/200...  loss: 0.000000000000225...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 142/200...  loss: 0.000000000000248...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 142/200...  loss: 0.000000000006028...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 142/200...  loss: 0.000000000000222...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 142/200...  loss: 0.000000000000221...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 142/200...  loss: 0.000000000000246...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 142/200...  loss: 0.000000000000243...  0.0080 sec/batch\n",
      "iters: 142\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 143/200...  loss: 0.000000000000213...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 143/200...  loss: 0.000000000000215...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 143/200...  loss: 0.000000000000220...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 143/200...  loss: 0.000000000000244...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 143/200...  loss: 0.000000000005945...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 143/200...  loss: 0.000000000000218...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 143/200...  loss: 0.000000000000217...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 143/200...  loss: 0.000000000000241...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 143/200...  loss: 0.000000000000238...  0.0090 sec/batch\n",
      "iters: 143\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 144/200...  loss: 0.000000000000209...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 144/200...  loss: 0.000000000000211...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 144/200...  loss: 0.000000000000216...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 144/200...  loss: 0.000000000000239...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 144/200...  loss: 0.000000000005866...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 144/200...  loss: 0.000000000000213...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 144/200...  loss: 0.000000000000212...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 144/200...  loss: 0.000000000000236...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 144/200...  loss: 0.000000000000234...  0.0100 sec/batch\n",
      "iters: 144\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 145/200...  loss: 0.000000000000205...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 145/200...  loss: 0.000000000000206...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 145/200...  loss: 0.000000000000212...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 145/200...  loss: 0.000000000000234...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 145/200...  loss: 0.000000000005788...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 145/200...  loss: 0.000000000000209...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 145/200...  loss: 0.000000000000208...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 145/200...  loss: 0.000000000000232...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 145/200...  loss: 0.000000000000229...  0.0070 sec/batch\n",
      "iters: 145\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 146/200...  loss: 0.000000000000201...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 146/200...  loss: 0.000000000000203...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 146/200...  loss: 0.000000000000208...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 146/200...  loss: 0.000000000000230...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 146/200...  loss: 0.000000000005711...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 146/200...  loss: 0.000000000000205...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 146/200...  loss: 0.000000000000204...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 146/200...  loss: 0.000000000000227...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 146/200...  loss: 0.000000000000225...  0.0070 sec/batch\n",
      "iters: 146\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 147/200...  loss: 0.000000000000197...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 147/200...  loss: 0.000000000000199...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 147/200...  loss: 0.000000000000204...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 147/200...  loss: 0.000000000000225...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 147/200...  loss: 0.000000000005638...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 147/200...  loss: 0.000000000000201...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 147/200...  loss: 0.000000000000200...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 147/200...  loss: 0.000000000000223...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 147/200...  loss: 0.000000000000221...  0.0080 sec/batch\n",
      "iters: 147\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 148/200...  loss: 0.000000000000194...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 148/200...  loss: 0.000000000000195...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 148/200...  loss: 0.000000000000200...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 148/200...  loss: 0.000000000000221...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 148/200...  loss: 0.000000000005566...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 148/200...  loss: 0.000000000000198...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 148/200...  loss: 0.000000000000197...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 148/200...  loss: 0.000000000000219...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 148/200...  loss: 0.000000000000217...  0.0080 sec/batch\n",
      "iters: 148\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 149/200...  loss: 0.000000000000190...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 149/200...  loss: 0.000000000000192...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 149/200...  loss: 0.000000000000196...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 149/200...  loss: 0.000000000000217...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 149/200...  loss: 0.000000000005495...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 149/200...  loss: 0.000000000000194...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 149/200...  loss: 0.000000000000193...  0.0130 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 149/200...  loss: 0.000000000000215...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 149/200...  loss: 0.000000000000213...  0.0080 sec/batch\n",
      "iters: 149\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 150/200...  loss: 0.000000000000187...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 150/200...  loss: 0.000000000000188...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 150/200...  loss: 0.000000000000193...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 150/200...  loss: 0.000000000000213...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 150/200...  loss: 0.000000000005425...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 150/200...  loss: 0.000000000000190...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 150/200...  loss: 0.000000000000190...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 150/200...  loss: 0.000000000000211...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 150/200...  loss: 0.000000000000209...  0.0080 sec/batch\n",
      "iters: 150\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 151/200...  loss: 0.000000000000184...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 151/200...  loss: 0.000000000000185...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 151/200...  loss: 0.000000000000189...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 151/200...  loss: 0.000000000000210...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 151/200...  loss: 0.000000000005358...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 151/200...  loss: 0.000000000000187...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 151/200...  loss: 0.000000000000186...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 151/200...  loss: 0.000000000000208...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 151/200...  loss: 0.000000000000205...  0.0080 sec/batch\n",
      "iters: 151\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 152/200...  loss: 0.000000000000180...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 152/200...  loss: 0.000000000000182...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 152/200...  loss: 0.000000000000186...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 152/200...  loss: 0.000000000000206...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 152/200...  loss: 0.000000000005293...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 152/200...  loss: 0.000000000000184...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 152/200...  loss: 0.000000000000183...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 152/200...  loss: 0.000000000000204...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 152/200...  loss: 0.000000000000202...  0.0080 sec/batch\n",
      "iters: 152\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 153/200...  loss: 0.000000000000177...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 153/200...  loss: 0.000000000000178...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 153/200...  loss: 0.000000000000182...  0.0191 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 153/200...  loss: 0.000000000000202...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 153/200...  loss: 0.000000000005229...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 153/200...  loss: 0.000000000000180...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 153/200...  loss: 0.000000000000180...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 153/200...  loss: 0.000000000000201...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 153/200...  loss: 0.000000000000198...  0.0090 sec/batch\n",
      "iters: 153\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 154/200...  loss: 0.000000000000174...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 154/200...  loss: 0.000000000000175...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 154/200...  loss: 0.000000000000179...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 154/200...  loss: 0.000000000000199...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 154/200...  loss: 0.000000000005166...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 154/200...  loss: 0.000000000000177...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 154/200...  loss: 0.000000000000177...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 154/200...  loss: 0.000000000000197...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 154/200...  loss: 0.000000000000195...  0.0080 sec/batch\n",
      "iters: 154\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 155/200...  loss: 0.000000000000171...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 155/200...  loss: 0.000000000000172...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 155/200...  loss: 0.000000000000176...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 155/200...  loss: 0.000000000000196...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 155/200...  loss: 0.000000000005105...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 155/200...  loss: 0.000000000000174...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 155/200...  loss: 0.000000000000174...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 155/200...  loss: 0.000000000000193...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 155/200...  loss: 0.000000000000192...  0.0090 sec/batch\n",
      "iters: 155\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 156/200...  loss: 0.000000000000168...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 156/200...  loss: 0.000000000000170...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 156/200...  loss: 0.000000000000173...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 156/200...  loss: 0.000000000000192...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 156/200...  loss: 0.000000000005046...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 156/200...  loss: 0.000000000000171...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 156/200...  loss: 0.000000000000171...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 156/200...  loss: 0.000000000000191...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 156/200...  loss: 0.000000000000189...  0.0080 sec/batch\n",
      "iters: 156\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 157/200...  loss: 0.000000000000166...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 157/200...  loss: 0.000000000000167...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 157/200...  loss: 0.000000000000170...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 157/200...  loss: 0.000000000000189...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 157/200...  loss: 0.000000000004987...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 157/200...  loss: 0.000000000000169...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 157/200...  loss: 0.000000000000168...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 157/200...  loss: 0.000000000000188...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 157/200...  loss: 0.000000000000186...  0.0080 sec/batch\n",
      "iters: 157\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 158/200...  loss: 0.000000000000163...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 158/200...  loss: 0.000000000000164...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 158/200...  loss: 0.000000000000168...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 158/200...  loss: 0.000000000000186...  0.0090 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 158/200...  loss: 0.000000000004930...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 158/200...  loss: 0.000000000000166...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 158/200...  loss: 0.000000000000165...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 158/200...  loss: 0.000000000000185...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 158/200...  loss: 0.000000000000183...  0.0090 sec/batch\n",
      "iters: 158\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 159/200...  loss: 0.000000000000160...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 159/200...  loss: 0.000000000000161...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 159/200...  loss: 0.000000000000165...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 159/200...  loss: 0.000000000000183...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 159/200...  loss: 0.000000000004874...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 159/200...  loss: 0.000000000000163...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 159/200...  loss: 0.000000000000162...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 159/200...  loss: 0.000000000000182...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 159/200...  loss: 0.000000000000180...  0.0080 sec/batch\n",
      "iters: 159\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 160/200...  loss: 0.000000000000158...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 160/200...  loss: 0.000000000000159...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 160/200...  loss: 0.000000000000162...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 160/200...  loss: 0.000000000000180...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 160/200...  loss: 0.000000000004820...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 160/200...  loss: 0.000000000000161...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 160/200...  loss: 0.000000000000160...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 160/200...  loss: 0.000000000000179...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 160/200...  loss: 0.000000000000177...  0.0080 sec/batch\n",
      "iters: 160\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 161/200...  loss: 0.000000000000155...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 161/200...  loss: 0.000000000000156...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 161/200...  loss: 0.000000000000160...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 161/200...  loss: 0.000000000000178...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 161/200...  loss: 0.000000000004767...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 161/200...  loss: 0.000000000000158...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 161/200...  loss: 0.000000000000157...  0.0140 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 161/200...  loss: 0.000000000000176...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 161/200...  loss: 0.000000000000174...  0.0080 sec/batch\n",
      "iters: 161\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 162/200...  loss: 0.000000000000153...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 162/200...  loss: 0.000000000000154...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 162/200...  loss: 0.000000000000157...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 162/200...  loss: 0.000000000000175...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 162/200...  loss: 0.000000000004715...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 162/200...  loss: 0.000000000000156...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 162/200...  loss: 0.000000000000155...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 162/200...  loss: 0.000000000000173...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 162/200...  loss: 0.000000000000172...  0.0100 sec/batch\n",
      "iters: 162\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 163/200...  loss: 0.000000000000151...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 163/200...  loss: 0.000000000000152...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 163/200...  loss: 0.000000000000155...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 163/200...  loss: 0.000000000000172...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 163/200...  loss: 0.000000000004664...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 163/200...  loss: 0.000000000000153...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 163/200...  loss: 0.000000000000153...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 163/200...  loss: 0.000000000000171...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 163/200...  loss: 0.000000000000169...  0.0080 sec/batch\n",
      "iters: 163\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 164/200...  loss: 0.000000000000148...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 164/200...  loss: 0.000000000000149...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 164/200...  loss: 0.000000000000152...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 164/200...  loss: 0.000000000000170...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 164/200...  loss: 0.000000000004614...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 164/200...  loss: 0.000000000000151...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 164/200...  loss: 0.000000000000150...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 164/200...  loss: 0.000000000000168...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 164/200...  loss: 0.000000000000167...  0.0080 sec/batch\n",
      "iters: 164\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 165/200...  loss: 0.000000000000146...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 165/200...  loss: 0.000000000000147...  0.0090 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 165/200...  loss: 0.000000000000150...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 165/200...  loss: 0.000000000000167...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 165/200...  loss: 0.000000000004565...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 165/200...  loss: 0.000000000000148...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 165/200...  loss: 0.000000000000148...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 165/200...  loss: 0.000000000000166...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 165/200...  loss: 0.000000000000164...  0.0080 sec/batch\n",
      "iters: 165\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 166/200...  loss: 0.000000000000144...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 166/200...  loss: 0.000000000000145...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 166/200...  loss: 0.000000000000148...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 166/200...  loss: 0.000000000000165...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 166/200...  loss: 0.000000000004518...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 166/200...  loss: 0.000000000000146...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 166/200...  loss: 0.000000000000146...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 166/200...  loss: 0.000000000000163...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 166/200...  loss: 0.000000000000162...  0.0080 sec/batch\n",
      "iters: 166\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 167/200...  loss: 0.000000000000142...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 167/200...  loss: 0.000000000000143...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 167/200...  loss: 0.000000000000146...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 167/200...  loss: 0.000000000000162...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 167/200...  loss: 0.000000000004470...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 167/200...  loss: 0.000000000000144...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 167/200...  loss: 0.000000000000144...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 167/200...  loss: 0.000000000000161...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 167/200...  loss: 0.000000000000159...  0.0080 sec/batch\n",
      "iters: 167\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 168/200...  loss: 0.000000000000140...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 168/200...  loss: 0.000000000000141...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 168/200...  loss: 0.000000000000143...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 168/200...  loss: 0.000000000000160...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 168/200...  loss: 0.000000000004425...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 168/200...  loss: 0.000000000000142...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 168/200...  loss: 0.000000000000141...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 168/200...  loss: 0.000000000000159...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 168/200...  loss: 0.000000000000157...  0.0080 sec/batch\n",
      "iters: 168\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 169/200...  loss: 0.000000000000138...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 169/200...  loss: 0.000000000000139...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 169/200...  loss: 0.000000000000141...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 169/200...  loss: 0.000000000000158...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 169/200...  loss: 0.000000000004380...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 169/200...  loss: 0.000000000000140...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 169/200...  loss: 0.000000000000139...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 169/200...  loss: 0.000000000000157...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 169/200...  loss: 0.000000000000155...  0.0080 sec/batch\n",
      "iters: 169\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 170/200...  loss: 0.000000000000136...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 170/200...  loss: 0.000000000000137...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 170/200...  loss: 0.000000000000139...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 170/200...  loss: 0.000000000000155...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 170/200...  loss: 0.000000000004335...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 170/200...  loss: 0.000000000000138...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 170/200...  loss: 0.000000000000138...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 170/200...  loss: 0.000000000000154...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 170/200...  loss: 0.000000000000153...  0.0090 sec/batch\n",
      "iters: 170\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 171/200...  loss: 0.000000000000134...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 171/200...  loss: 0.000000000000135...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 171/200...  loss: 0.000000000000137...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 171/200...  loss: 0.000000000000153...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 171/200...  loss: 0.000000000004292...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 171/200...  loss: 0.000000000000136...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 171/200...  loss: 0.000000000000136...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 171/200...  loss: 0.000000000000152...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 171/200...  loss: 0.000000000000151...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters: 171\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 172/200...  loss: 0.000000000000132...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 172/200...  loss: 0.000000000000133...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 172/200...  loss: 0.000000000000135...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 172/200...  loss: 0.000000000000151...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 172/200...  loss: 0.000000000004250...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 172/200...  loss: 0.000000000000134...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 172/200...  loss: 0.000000000000134...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 172/200...  loss: 0.000000000000150...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 172/200...  loss: 0.000000000000149...  0.0110 sec/batch\n",
      "iters: 172\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 173/200...  loss: 0.000000000000130...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 173/200...  loss: 0.000000000000131...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 173/200...  loss: 0.000000000000133...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 173/200...  loss: 0.000000000000149...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 173/200...  loss: 0.000000000004208...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 173/200...  loss: 0.000000000000132...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 173/200...  loss: 0.000000000000132...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 173/200...  loss: 0.000000000000148...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 173/200...  loss: 0.000000000000147...  0.0090 sec/batch\n",
      "iters: 173\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 174/200...  loss: 0.000000000000128...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 174/200...  loss: 0.000000000000129...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 174/200...  loss: 0.000000000000132...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 174/200...  loss: 0.000000000000147...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 174/200...  loss: 0.000000000004167...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 174/200...  loss: 0.000000000000130...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 174/200...  loss: 0.000000000000130...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 174/200...  loss: 0.000000000000146...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 174/200...  loss: 0.000000000000145...  0.0090 sec/batch\n",
      "iters: 174\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 175/200...  loss: 0.000000000000127...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 175/200...  loss: 0.000000000000128...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 175/200...  loss: 0.000000000000130...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 175/200...  loss: 0.000000000000145...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 175/200...  loss: 0.000000000004127...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 175/200...  loss: 0.000000000000129...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 175/200...  loss: 0.000000000000128...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 175/200...  loss: 0.000000000000144...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 175/200...  loss: 0.000000000000143...  0.0090 sec/batch\n",
      "iters: 175\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 176/200...  loss: 0.000000000000125...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 176/200...  loss: 0.000000000000126...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 176/200...  loss: 0.000000000000128...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 176/200...  loss: 0.000000000000143...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 176/200...  loss: 0.000000000004088...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 176/200...  loss: 0.000000000000127...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 176/200...  loss: 0.000000000000126...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 176/200...  loss: 0.000000000000142...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 176/200...  loss: 0.000000000000141...  0.0080 sec/batch\n",
      "iters: 176\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 177/200...  loss: 0.000000000000123...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 177/200...  loss: 0.000000000000124...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 177/200...  loss: 0.000000000000126...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 177/200...  loss: 0.000000000000141...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 177/200...  loss: 0.000000000004050...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 177/200...  loss: 0.000000000000125...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 177/200...  loss: 0.000000000000125...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 177/200...  loss: 0.000000000000140...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 177/200...  loss: 0.000000000000139...  0.0100 sec/batch\n",
      "iters: 177\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 178/200...  loss: 0.000000000000122...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 178/200...  loss: 0.000000000000123...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 178/200...  loss: 0.000000000000125...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 178/200...  loss: 0.000000000000139...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 178/200...  loss: 0.000000000004012...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 178/200...  loss: 0.000000000000123...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 178/200...  loss: 0.000000000000123...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 178/200...  loss: 0.000000000000139...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 178/200...  loss: 0.000000000000137...  0.0090 sec/batch\n",
      "iters: 178\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 179/200...  loss: 0.000000000000120...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 179/200...  loss: 0.000000000000121...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 179/200...  loss: 0.000000000000123...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 179/200...  loss: 0.000000000000138...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 179/200...  loss: 0.000000000003975...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 179/200...  loss: 0.000000000000122...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 179/200...  loss: 0.000000000000121...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 179/200...  loss: 0.000000000000137...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 179/200...  loss: 0.000000000000136...  0.0080 sec/batch\n",
      "iters: 179\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 180/200...  loss: 0.000000000000119...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 180/200...  loss: 0.000000000000119...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 180/200...  loss: 0.000000000000121...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 180/200...  loss: 0.000000000000136...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 180/200...  loss: 0.000000000003939...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 180/200...  loss: 0.000000000000120...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 180/200...  loss: 0.000000000000120...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 180/200...  loss: 0.000000000000135...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 180/200...  loss: 0.000000000000134...  0.0080 sec/batch\n",
      "iters: 180\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 181/200...  loss: 0.000000000000117...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 181/200...  loss: 0.000000000000118...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 181/200...  loss: 0.000000000000120...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 181/200...  loss: 0.000000000000134...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 181/200...  loss: 0.000000000003903...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 181/200...  loss: 0.000000000000119...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 181/200...  loss: 0.000000000000118...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 181/200...  loss: 0.000000000000133...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 181/200...  loss: 0.000000000000132...  0.0090 sec/batch\n",
      "iters: 181\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 182/200...  loss: 0.000000000000116...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 182/200...  loss: 0.000000000000116...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 182/200...  loss: 0.000000000000118...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 182/200...  loss: 0.000000000000132...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 182/200...  loss: 0.000000000003868...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 182/200...  loss: 0.000000000000117...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 182/200...  loss: 0.000000000000117...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 182/200...  loss: 0.000000000000132...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 182/200...  loss: 0.000000000000130...  0.0090 sec/batch\n",
      "iters: 182\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 183/200...  loss: 0.000000000000114...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 183/200...  loss: 0.000000000000115...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 183/200...  loss: 0.000000000000117...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 183/200...  loss: 0.000000000000131...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 183/200...  loss: 0.000000000003833...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 183/200...  loss: 0.000000000000116...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 183/200...  loss: 0.000000000000115...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 183/200...  loss: 0.000000000000130...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 183/200...  loss: 0.000000000000129...  0.0080 sec/batch\n",
      "iters: 183\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 184/200...  loss: 0.000000000000113...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 184/200...  loss: 0.000000000000113...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 184/200...  loss: 0.000000000000115...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 184/200...  loss: 0.000000000000129...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 184/200...  loss: 0.000000000003799...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 184/200...  loss: 0.000000000000114...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 184/200...  loss: 0.000000000000114...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 184/200...  loss: 0.000000000000128...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 184/200...  loss: 0.000000000000127...  0.0080 sec/batch\n",
      "iters: 184\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 185/200...  loss: 0.000000000000111...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 185/200...  loss: 0.000000000000112...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 185/200...  loss: 0.000000000000114...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 185/200...  loss: 0.000000000000128...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 185/200...  loss: 0.000000000003765...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 185/200...  loss: 0.000000000000113...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 185/200...  loss: 0.000000000000112...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 185/200...  loss: 0.000000000000127...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 185/200...  loss: 0.000000000000126...  0.0080 sec/batch\n",
      "iters: 185\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 186/200...  loss: 0.000000000000110...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 186/200...  loss: 0.000000000000111...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 186/200...  loss: 0.000000000000112...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 186/200...  loss: 0.000000000000126...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 186/200...  loss: 0.000000000003732...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 186/200...  loss: 0.000000000000111...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 186/200...  loss: 0.000000000000111...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 186/200...  loss: 0.000000000000125...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 186/200...  loss: 0.000000000000124...  0.0080 sec/batch\n",
      "iters: 186\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 187/200...  loss: 0.000000000000109...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 187/200...  loss: 0.000000000000109...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 187/200...  loss: 0.000000000000111...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 187/200...  loss: 0.000000000000124...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 187/200...  loss: 0.000000000003700...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 187/200...  loss: 0.000000000000110...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 187/200...  loss: 0.000000000000110...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 187/200...  loss: 0.000000000000124...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 187/200...  loss: 0.000000000000123...  0.0090 sec/batch\n",
      "iters: 187\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 188/200...  loss: 0.000000000000107...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 188/200...  loss: 0.000000000000108...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 188/200...  loss: 0.000000000000110...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 188/200...  loss: 0.000000000000123...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 188/200...  loss: 0.000000000003669...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 188/200...  loss: 0.000000000000109...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 188/200...  loss: 0.000000000000108...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 188/200...  loss: 0.000000000000122...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 188/200...  loss: 0.000000000000121...  0.0080 sec/batch\n",
      "iters: 188\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 189/200...  loss: 0.000000000000106...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 189/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 189/200...  loss: 0.000000000000108...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 189/200...  loss: 0.000000000000122...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 189/200...  loss: 0.000000000003638...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 189/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 189/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 189/200...  loss: 0.000000000000121...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 189/200...  loss: 0.000000000000120...  0.0080 sec/batch\n",
      "iters: 189\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 190/200...  loss: 0.000000000000105...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 190/200...  loss: 0.000000000000105...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 190/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 190/200...  loss: 0.000000000000120...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 190/200...  loss: 0.000000000003607...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 190/200...  loss: 0.000000000000106...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 190/200...  loss: 0.000000000000106...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 190/200...  loss: 0.000000000000119...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 190/200...  loss: 0.000000000000118...  0.0080 sec/batch\n",
      "iters: 190\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 191/200...  loss: 0.000000000000103...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 191/200...  loss: 0.000000000000104...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 191/200...  loss: 0.000000000000106...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 191/200...  loss: 0.000000000000119...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 191/200...  loss: 0.000000000003577...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 191/200...  loss: 0.000000000000105...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 191/200...  loss: 0.000000000000104...  0.0150 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 191/200...  loss: 0.000000000000118...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 191/200...  loss: 0.000000000000117...  0.0090 sec/batch\n",
      "iters: 191\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 192/200...  loss: 0.000000000000102...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 192/200...  loss: 0.000000000000103...  0.0160 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 192/200...  loss: 0.000000000000104...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 192/200...  loss: 0.000000000000117...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 192/200...  loss: 0.000000000003547...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 192/200...  loss: 0.000000000000104...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 192/200...  loss: 0.000000000000103...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 192/200...  loss: 0.000000000000117...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 192/200...  loss: 0.000000000000116...  0.0090 sec/batch\n",
      "iters: 192\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 193/200...  loss: 0.000000000000101...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 193/200...  loss: 0.000000000000102...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 193/200...  loss: 0.000000000000103...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 193/200...  loss: 0.000000000000116...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 193/200...  loss: 0.000000000003518...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 193/200...  loss: 0.000000000000102...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 193/200...  loss: 0.000000000000102...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 193/200...  loss: 0.000000000000115...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 193/200...  loss: 0.000000000000114...  0.0080 sec/batch\n",
      "iters: 193\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 194/200...  loss: 0.000000000000100...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 194/200...  loss: 0.000000000000101...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 194/200...  loss: 0.000000000000102...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 194/200...  loss: 0.000000000000115...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 194/200...  loss: 0.000000000003490...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 194/200...  loss: 0.000000000000101...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 194/200...  loss: 0.000000000000101...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 194/200...  loss: 0.000000000000114...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 194/200...  loss: 0.000000000000113...  0.0090 sec/batch\n",
      "iters: 194\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 195/200...  loss: 0.000000000000099...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 195/200...  loss: 0.000000000000099...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 195/200...  loss: 0.000000000000101...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 195/200...  loss: 0.000000000000113...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 195/200...  loss: 0.000000000003462...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 195/200...  loss: 0.000000000000100...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 195/200...  loss: 0.000000000000100...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 195/200...  loss: 0.000000000000113...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 195/200...  loss: 0.000000000000112...  0.0080 sec/batch\n",
      "iters: 195\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 196/200...  loss: 0.000000000000098...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 196/200...  loss: 0.000000000000098...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 196/200...  loss: 0.000000000000100...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 196/200...  loss: 0.000000000000112...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 196/200...  loss: 0.000000000003434...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 196/200...  loss: 0.000000000000099...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 196/200...  loss: 0.000000000000099...  0.0120 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 196/200...  loss: 0.000000000000111...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 196/200...  loss: 0.000000000000111...  0.0100 sec/batch\n",
      "iters: 196\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 197/200...  loss: 0.000000000000097...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 197/200...  loss: 0.000000000000097...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 197/200...  loss: 0.000000000000098...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 197/200...  loss: 0.000000000000111...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 197/200...  loss: 0.000000000003407...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 197/200...  loss: 0.000000000000098...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 197/200...  loss: 0.000000000000097...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 197/200...  loss: 0.000000000000110...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 197/200...  loss: 0.000000000000109...  0.0100 sec/batch\n",
      "iters: 197\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 198/200...  loss: 0.000000000000095...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 198/200...  loss: 0.000000000000096...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 198/200...  loss: 0.000000000000097...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 198/200...  loss: 0.000000000000110...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 198/200...  loss: 0.000000000003380...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 198/200...  loss: 0.000000000000097...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 198/200...  loss: 0.000000000000096...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 198/200...  loss: 0.000000000000109...  0.0110 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 198/200...  loss: 0.000000000000108...  0.0080 sec/batch\n",
      "iters: 198\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 199/200...  loss: 0.000000000000094...  0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 199/200...  loss: 0.000000000000095...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 199/200...  loss: 0.000000000000096...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 199/200...  loss: 0.000000000000108...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 199/200...  loss: 0.000000000003353...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 199/200...  loss: 0.000000000000096...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 199/200...  loss: 0.000000000000095...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 199/200...  loss: 0.000000000000108...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 199/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "iters: 199\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 200/200...  loss: 0.000000000000093...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 200/200...  loss: 0.000000000000094...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 200/200...  loss: 0.000000000000095...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 200/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 200/200...  loss: 0.000000000003327...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 200/200...  loss: 0.000000000000094...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 200/200...  loss: 0.000000000000094...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 200/200...  loss: 0.000000000000107...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 200/200...  loss: 0.000000000000106...  0.0090 sec/batch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if os.path.exists(save_path) is False:\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "train_input, train_target, test_input, test_target = batch_generator(x_input.values, \n",
    "                                                              y_label.values, \n",
    "                                                              batch_size=batch_size, \n",
    "                                                              seq_len=seq_len)\n",
    "\n",
    "model = Seq2Seq(batch_size=batch_size, \n",
    "                seq_max_len=seq_len,\n",
    "                lstm_size=lstm_size,\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "model.train(train_input, \n",
    "            train_target,\n",
    "            iters=iters,\n",
    "            save_every_n=1000,\n",
    "            log_every_n =200\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./seq2seq_models/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20173852733788"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating graph (by TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./seq2seq_models/model',graph=tf.get_default_graph())\n",
    "writer.close()\n",
    "'''\n",
    "1. in terminal：　tensorboard --logdir path/to/modelfile\n",
    "2. view graph in browser\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tensorflow.python.layers:\n",
    "layers 模塊提供用於深度學習的更高層次封裝的 API，\n",
    "\n",
    "tf.layers 模塊提供的方法有：\n",
    "    Input(…): 用於實例化一個輸入 Tensor，作為神經網絡的輸入。\n",
    "    average_pooling1d(…): 一維平均池化層\n",
    "    average_pooling2d(…): 二維平均池化層\n",
    "    average_pooling3d(…): 三維平均池化層\n",
    "    batch_normalization(…): 批量標準化層\n",
    "    conv1d(…): 一維卷積層\n",
    "    conv2d(…): 二維卷積層\n",
    "    conv2d_transpose(…): 二維反捲積層\n",
    "    conv3d(…): 三維卷積層\n",
    "    conv3d_transpose(…): 三維反捲積層\n",
    "    dense(…): 全連接層\n",
    "    dropout(…): Dropout層\n",
    "    flatten(…): Flatten層，即把一個 Tensor 展平\n",
    "    max_pooling1d(…): 一維最大池化層\n",
    "    max_pooling2d(…): 二維最大池化層\n",
    "    max_pooling3d(…): 三維最大池化層\n",
    "    separable_conv2d(…): 二維深度可分離卷積層\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
