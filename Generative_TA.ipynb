{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(train_data_path, train_label_path, test_data_path):\n",
    "    \n",
    "    X_train = pd.read_csv(train_data_path, sep=',', header=0)\n",
    "    X_train = np.array(X_train.values)\n",
    "    \n",
    "    Y_train = pd.read_csv(train_label_path, sep=',', header=0)\n",
    "    Y_train = np.array(Y_train.values)\n",
    "    \n",
    "    X_test = pd.read_csv(test_data_path, sep=',', header=0)\n",
    "    X_test = np.array(X_test.values)\n",
    "    \n",
    "    return (X_train, Y_train, X_test)\n",
    "\n",
    "# spe=' ': Delimiter(分隔符號) to use\n",
    "# heater: Row number(s) to use as the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _shuffle(X, Y):\n",
    "    '''shuffle the array (洗牌) '''\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "    return (X[randomize], Y[randomize])\n",
    "\n",
    "# np.random.shuffle: Shuffle the sequence x in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X_all, X_test):\n",
    "    '''Feature normalization with train and test X'''\n",
    "    X_train_test = np.concatenate((X_all, X_test))\n",
    "    # conbine two array\n",
    "    \n",
    "    mu = (sum(X_train_test) / X_train_test.shape[0]) # Calculate Mean\n",
    "    sigma = np.std(X_train_test, axis=0) # standard deviation\n",
    "    \n",
    "    mu = np.tile(mu, (X_train_test.shape[0], 1))\n",
    "    sigma = np.tile(sigma, (X_train_test.shape[0], 1))\n",
    "    # Construct an array by repeating A the number of times given by reps.\n",
    "    \n",
    "    X_train_test_normed = (X_train_test - mu) / sigma #normalize\n",
    "    \n",
    "    # Split to train, test again\n",
    "    X_all = X_train_test_normed[0:X_all.shape[0]]\n",
    "    X_test = X_train_test_normed[X_all.shape[0]:]\n",
    "    return X_all, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_valid_set(X_all, Y_all, percentage):\n",
    "    '''split valid set from one train data'''\n",
    "    all_data_size = len(X_all)\n",
    "    valid_data_size = int(floor(all_data_size * percentage))\n",
    "    # Return the floor of x (the integer of a float value )\n",
    "    \n",
    "    X_all, Y_all = _shuffle(X_all, Y_all)\n",
    "    # call  _shuffle() function to shuffle data \n",
    "    \n",
    "    # split the data\n",
    "    X_valid, Y_valid = X_all[0:valid_data_size], Y_all[0:valid_data_size]\n",
    "    X_train, Y_train = X_all[valid_data_size:], Y_all[valid_data_size:]\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "# If you wish to get the same shuffle result\n",
    "# np.random.seed(2401)\n",
    "#This method is called when RandomState is initialized. \n",
    "#It can be called again to re-seed the generator. For details, see RandomState."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1.0 + np.exp(-z))\n",
    "    return np.clip(res, 1e-8, 1-(1e-8))\n",
    "# np.clip(a, a_min, a_max, out=None) : Clip (limit) the values in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(X_valid, Y_valid, mu1, mu2, shared_sigma, N1, N2):\n",
    "    ''' when model was trained, use valid set to check the accuracy'''\n",
    "    sigma_inverse = np.linalg.inv(shared_sigma)\n",
    "    w = np.dot( (mu1-mu2), sigma_inverse)\n",
    "    \n",
    "    x = X_valid.T\n",
    "    b = (-0.5) * np.dot(np.dot([mu1], sigma_inverse), mu1) + (0.5) * np.dot(np.dot([mu2], sigma_inverse), mu2) + np.log(float(N1)/N2)\n",
    "    \n",
    "    a = np.dot(w, x) + b\n",
    "    y = sigmoid(a)\n",
    "    y_ = np.around(y)\n",
    "    result = (np.squeeze(Y_valid) == y_)\n",
    "    print('Valid acc = %f' % (float(result.sum()) / result.shape[0]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_all, Y_all, save_dir):\n",
    "    '''in Generative model, so call training just calculate u and matrix'''\n",
    "    \n",
    "    # Split a 10%-validation set from the training set\n",
    "    valid_set_percentage = 0.1\n",
    "    X_train, Y_train, X_valid, Y_valid = split_valid_set(X_all, Y_all, valid_set_percentage)\n",
    "    \n",
    "    \n",
    "    # Gaussian distribution parameters\n",
    "    train_data_size = X_train.shape[0]\n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "\n",
    "    mu1 = np.zeros((106,))\n",
    "    mu2 = np.zeros((106,))\n",
    "    for i in range(train_data_size):\n",
    "        if Y_train[i] == 1:\n",
    "            mu1 += X_train[i]\n",
    "            cnt1 += 1\n",
    "        else:\n",
    "            mu2 += X_train[i]\n",
    "            cnt2 += 1\n",
    "    mu1 /= cnt1\n",
    "    mu2 /= cnt2\n",
    "\n",
    "    sigma1 = np.zeros((106,106))\n",
    "    sigma2 = np.zeros((106,106))\n",
    "    for i in range(train_data_size):\n",
    "        if Y_train[i] == 1:\n",
    "            sigma1 += np.dot(np.transpose([X_train[i] - mu1]), [(X_train[i] - mu1)])\n",
    "        else:\n",
    "            sigma2 += np.dot(np.transpose([X_train[i] - mu2]), [(X_train[i] - mu2)])\n",
    "    sigma1 /= cnt1\n",
    "    sigma2 /= cnt2\n",
    "    \n",
    "    \n",
    "    shared_sigma = (float(cnt1) / train_data_size) * sigma1 + (float(cnt2) / train_data_size) * sigma2\n",
    "    N1 = cnt1\n",
    "    N2 = cnt2\n",
    "\n",
    "    print('=====Saving Param=====')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    param_dict = {'mu1':mu1, 'mu2':mu2, 'shared_sigma':shared_sigma, 'N1':[N1], 'N2':[N2]}\n",
    "    for key in sorted(param_dict):\n",
    "        print('Saving %s' % key)\n",
    "        np.savetxt(os.path.join(save_dir, ('%s' % key)), param_dict[key])\n",
    "    \n",
    "    print('=====Validating=====')\n",
    "    valid(X_valid, Y_valid, mu1, mu2, shared_sigma, N1, N2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(opts):\n",
    "    # Load feature and label\n",
    "    X_all, Y_all, X_test = load_data(opts.train_data_path, opts.train_label_path, opts.test_data_path)\n",
    "    # Normalization\n",
    "    X_all, X_test = normalize(X_all, X_test)\n",
    "    \n",
    "    # To train or to infer\n",
    "    if opts.train:\n",
    "        train(X_all, Y_all, opts.save_dir)\n",
    "    elif opts.infer:\n",
    "        infer(X_test, opts.save_dir, opts.output_dir)\n",
    "    else:\n",
    "        print(\"Error: Argument --train or --infer not found\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "                description='Probabilistic Generative Model for Binary Classification'\n",
    "             )\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "    group.add_argument('--train', action='store_true', default=False,\n",
    "                        dest='train', help='Input --train to Train')\n",
    "    group.add_argument('--infer', action='store_true',default=False,\n",
    "                        dest='infer', help='Input --infer to Infer')\n",
    "    parser.add_argument('--train_data_path', type=str,\n",
    "                        default='feature/X_train', dest='train_data_path',\n",
    "                        help='Path to training data')\n",
    "    parser.add_argument('--train_label_path', type=str,\n",
    "                        default='feature/Y_train', dest='train_label_path',\n",
    "                        help='Path to training data\\'s label')\n",
    "    parser.add_argument('--test_data_path', type=str,\n",
    "                        default='feature/X_test', dest='test_data_path',\n",
    "                        help='Path to testing data')\n",
    "    parser.add_argument('--save_dir', type=str, \n",
    "                        default='generative_params/', dest='save_dir',\n",
    "                        help='Path to save the model parameters')\n",
    "    parser.add_argument('--output_dir', type=str, \n",
    "                        default='generative_output/', dest='output_dir',\n",
    "                        help='Path to save output')\n",
    "    opts = parser.parse_args()\n",
    "    main(opts)\n",
    "    \n",
    "# the recommended command-line parsing module in the Python standard library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
