{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noriginal Author: Gananath R\\nDrugAI-WGAN: \\nContact: https://github.com/gananath\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code resource: https://github.com/Gananath/DrugAI\n",
    "\n",
    "'''\n",
    "original Author: Gananath R\n",
    "DrugAI-WGAN: \n",
    "Contact: https://github.com/gananath\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv1D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    '''Loss dunction'''\n",
    "    return K.mean(y_true * y_pred)\n",
    "    \n",
    "\n",
    "def dimX(x, ts):\n",
    "    '''time step addtition to feature'''\n",
    "    x = np.asarray(x)\n",
    "    newX = []\n",
    "    for i, c in enumerate(x):\n",
    "        newX.append([])\n",
    "        for j in range(ts):\n",
    "            newX[i].append(c)\n",
    "    return np.array(newX)\n",
    "\n",
    "\n",
    "def dimY(Y, ts, char_idx, chars):\n",
    "    '''time step addtition to feature'''\n",
    "    temp = np.zeros((len(Y), ts, len(chars)), dtype=np.bool)\n",
    "    for i, c in enumerate(Y):\n",
    "        for j, s in enumerate(c):\n",
    "            # print i, j, s\n",
    "            temp[i, j, char_idx[s]] = 1\n",
    "    return np.array(temp)\n",
    "\n",
    "\n",
    "def train_test_split(X, y, percentage=0.75):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def prediction(preds):\n",
    "    '''prediction of argmax'''\n",
    "    y_pred = []\n",
    "    for i, c in enumerate(preds):\n",
    "        y_pred.append([])\n",
    "        for j in c:\n",
    "            y_pred[i].append(np.argmax(j))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def seq_txt(y_pred, idx_char):\n",
    "    '''sequence to text conversion'''\n",
    "    newY = []\n",
    "    for i, c in enumerate(y_pred):\n",
    "        newY.append([])\n",
    "        for j in c:\n",
    "            newY[i].append(idx_char[j])\n",
    "\n",
    "    return np.array(newY)\n",
    "\n",
    "\n",
    "def smiles_output(s):\n",
    "    '''joined smiles output'''\n",
    "    smiles = np.array([])\n",
    "    for i in s:\n",
    "        j = ''.join(str(k) for k in i)\n",
    "        smiles = np.append(smiles, j)\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>cox2</th>\n",
       "      <th>estrogen</th>\n",
       "      <th>gelatinase</th>\n",
       "      <th>neuramidase</th>\n",
       "      <th>kinase</th>\n",
       "      <th>thrombin</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>N[S](=O)(=O)C1=CC=C(C=C1)C2=CC(=N[N]2C3=CC=C(F...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C=C(F)C(=C2)F)C3...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C(=C)C2)C3=CC=CC=C3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>CCC(CC)NC1=NC(=CC=N1)C2=C(N=C[N]2C3CC[NH](C)CC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>CCOC1=C(Cl)C2=C(C=C(C=C2)[NH+]=C(N)N)C(=O)O1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>CC1=C(C(OC2=C1C=C(O)C=C2)C3=CC=C(OCC[NH]4CCCCC...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>CNC(=O)C(CC1=CC=CC=C1)NC(=O)C(CC(C)C)NC(CCN2C(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>CC12CCC3C(CCC4=C3C=CC(=C4)O)C1CCCC2O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>COC1=CC(=CC=C1)SCC2=N[N](C3=CC=C(C=C3)[S](C)(=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>CC(C1=CC(=C(O)C(=C1)C(C)(C)C)C(C)(C)C)=C2NC(=N...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES  cox2  estrogen  \\\n",
       "21   N[S](=O)(=O)C1=CC=C(C=C1)C2=CC(=N[N]2C3=CC=C(F...     1         0   \n",
       "30   C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C=C(F)C(=C2)F)C3...     1         0   \n",
       "102  C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C(=C)C2)C3=CC=CC=C3     1         0   \n",
       "250  CCC(CC)NC1=NC(=CC=N1)C2=C(N=C[N]2C3CC[NH](C)CC...     0         0   \n",
       "299       CCOC1=C(Cl)C2=C(C=C(C=C2)[NH+]=C(N)N)C(=O)O1     0         0   \n",
       "172  CC1=C(C(OC2=C1C=C(O)C=C2)C3=CC=C(OCC[NH]4CCCCC...     0         1   \n",
       "214  CNC(=O)C(CC1=CC=CC=C1)NC(=O)C(CC(C)C)NC(CCN2C(...     0         0   \n",
       "145               CC12CCC3C(CCC4=C3C=CC(=C4)O)C1CCCC2O     0         1   \n",
       "50   COC1=CC(=CC=C1)SCC2=N[N](C3=CC=C(C=C3)[S](C)(=...     1         0   \n",
       "121  CC(C1=CC(=C(O)C(=C1)C(C)(C)C)C(C)(C)C)=C2NC(=N...     1         0   \n",
       "\n",
       "     gelatinase  neuramidase  kinase  thrombin  none  \n",
       "21            0            0       0         0     0  \n",
       "30            0            0       0         0     0  \n",
       "102           0            0       0         0     0  \n",
       "250           0            0       1         0     0  \n",
       "299           0            0       0         1     0  \n",
       "172           0            0       0         0     0  \n",
       "214           1            0       0         0     0  \n",
       "145           0            0       0         0     0  \n",
       "50            0            0       0         0     0  \n",
       "121           0            0       0         0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file\n",
    "data = pd.read_csv('stahl.csv')\n",
    "data = data.reindex(np.random.permutation(data.index))\n",
    "print('Number of data:',len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21     N[S](=O)(=O)C1=CC=C(C=C1)C2=CC(=N[N]2C3=CC=C(F...\n",
       "30     C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C=C(F)C(=C2)F)C3...\n",
       "102    C[S](=O)(=O)C1=CC=C(C=C1)C2=C(C(=C)C2)C3=CC=CC=C3\n",
       "250    CCC(CC)NC1=NC(=CC=N1)C2=C(N=C[N]2C3CC[NH](C)CC...\n",
       "299         CCOC1=C(Cl)C2=C(C=C(C=C2)[NH+]=C(N)N)C(=O)O1\n",
       "Name: SMILES, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the SMILES string\n",
    "Y=data.SMILES\n",
    "print(type(Y))\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:7] # in this case, take the data of column 1:7\n",
    "# DataFrame.iloc: Purely integer-location based indexing for selection by position.\n",
    "X = X.values\n",
    "X = X.astype('int')\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts=116\n",
      "total chars: 25\n",
      "Shape\n",
      " X=(335, 6) Y=(335, 116, 25)\n"
     ]
    }
   ],
   "source": [
    "# padding smiles to same length by adding \"|\" at the end of smiles\n",
    "maxY = Y.str.len().max() + 11 # find the max length of SMILES\n",
    "y = Y.str.ljust(maxY, fillchar='|') # the maxY-th number frim left side, fill '|'\n",
    "ts = y.str.len().max()\n",
    "print (\"ts={0}\".format(ts))\n",
    "\n",
    "# CharToIndex and IndexToChar functions\n",
    "chars = sorted(list(set(\"\".join(y.values.flatten()))))\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "y_dash = dimY(y, ts, char_idx, chars)\n",
    "x_dash = X\n",
    "print(\"Shape\\n X={0} Y={1}\".format(x_dash.shape, y_dash.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(y_dash, dropout=0.4, lr=0.00001, PATH=\"Dis.h5\"):\n",
    "    \"\"\"Creates a discriminator CNN model that takes a sequence as input and outputs a single value(Real or Fake) \"\"\"\n",
    "    model = Sequential()\n",
    "    # First convolution layer\n",
    "    model.add(Conv1D(input_shape=(y_dash.shape[1], y_dash.shape[2]),\n",
    "                     nb_filter=25,\n",
    "                     filter_length=4,\n",
    "                     border_mode='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(MaxPooling1D())\n",
    "    \n",
    "    # 2-th convolution layere\n",
    "    model.add(Conv1D(nb_filter=10,\n",
    "                     filter_length=4,\n",
    "                     border_mode='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 3-th layer DNN\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    opt = Adam(lr, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=30, min_lr=0.000001, verbose=1)\n",
    "    checkpoint_D = ModelCheckpoint(filepath=PATH, \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=wasserstein_loss,\n",
    "                  metrics=['accuracy'])\n",
    "    return model, checkpoint_D\n",
    "\n",
    "\n",
    "\n",
    "def Generator(x_dash, y_dash, dropout=0.4, lr=0.00001, PATH=\"Gen.h5\"):\n",
    "    \"\"\"Creates a Generator DNN model that takes OneHot as input and outputs a sequence \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "     # Input layer\n",
    "    model.add(Dense(x_dash.shape[1], activation=\"relu\", input_shape=(6,)))\n",
    "    model.add(Dense( int(y_dash.shape[1]/4 * y_dash.shape[2]*8), #(None, 5800)\n",
    "             activation=\"relu\"))\n",
    "    model.add(Reshape((int(y_dash.shape[1] / 4), y_dash.shape[2] * 8)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(UpSampling1D())\n",
    "    \n",
    "    # 1-th convolution layere\n",
    "    model.add(Conv1D(y_dash.shape[2] * 8, kernel_size=4, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(UpSampling1D())\n",
    "    \n",
    "    # 2-th convolution layere\n",
    "    model.add(Conv1D(y_dash.shape[2] * 2, kernel_size=4, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # 3-th convolution layere\n",
    "    model.add(Conv1D(y_dash.shape[2] * 1, kernel_size=4, padding=\"same\"))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    opt = Adam(lr, beta_1=0.5, beta_2=0.9)\n",
    "    checkpoint_G = ModelCheckpoint(filepath=PATH, \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model, checkpoint_G\n",
    "\n",
    "\n",
    "def Gan(PATH=\"GAN.h5\", lr=0.00001):\n",
    "    '''GAN model'''\n",
    "    GAN = Sequential()\n",
    "    GAN.add(G) # Generating mosel\n",
    "    \n",
    "    D.trainable = False # Weight of dis model will not change when training GAN\n",
    "    # How model.trainable = False works in keras (GAN model)\n",
    "    # https://gist.github.com/naotokui/a9274f12af9d946e99b6df73a5d2af6d\n",
    "    GAN.add(D) # Discriminator model\n",
    "    checkpoint_GAN = ModelCheckpoint(filepath=PATH, \n",
    "                                     verbose=1, \n",
    "                                     save_best_only=True)\n",
    "    GAN.compile(loss=wasserstein_loss,\n",
    "                optimizer=Adam( lr,\n",
    "                                beta_1=0.5,\n",
    "                                beta_2=0.9))\n",
    "    return GAN, checkpoint_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HALF_BATCH = int(BATCH_SIZE / 2)\n",
    "CLIP = 0.01\n",
    "epochs = 100000\n",
    "n_critic = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eric/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(116, 25), filters=25, kernel_size=4, padding=\"same\")`\n",
      "  \n",
      "/home/eric/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=10, kernel_size=4, padding=\"same\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Building Model\n",
    "G, checkG = Generator(x_dash, y_dash)\n",
    "D, checkD = Discriminator(y_dash)\n",
    "GAN, checkGAN = Gan()\n",
    "# Enable training in discrimator\n",
    "D.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for _ in range(n_critic):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of sequence\n",
    "        idx = np.random.randint(0, y_dash.shape[0], HALF_BATCH)\n",
    "        imgs = y_dash[idx]\n",
    "\n",
    "        # noise = np.random.normal(0, 1, (HALF_BATCH, 100))\n",
    "        noise = x_dash[0:HALF_BATCH]\n",
    "        # Generate a half batch of new sequence\n",
    "        gen_imgs = G.predict(noise)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = D.train_on_batch(imgs, -np.ones((HALF_BATCH, 1)))  # linear activation\n",
    "        d_loss_fake = D.train_on_batch(gen_imgs, np.ones((HALF_BATCH, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "        # Clip discriminator weights\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -CLIP, CLIP) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "            \n",
    "        # ------------------------\n",
    "        #  Train Generator\n",
    "        # ------------------------\n",
    "        # noise = np.random.normal(0, 1, (BATCH_SIZE, 100))\n",
    "        noise = x_dash[0:BATCH_SIZE]\n",
    "        # Train the generator\n",
    "        g_loss = GAN.train_on_batch(\n",
    "            noise, -np.ones((BATCH_SIZE, 1)))  # linear activation\n",
    "    print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss))\n",
    "    \n",
    "    \n",
    "    if epoch % (epochs / 1000) == 0:\n",
    "        # for saving files\n",
    "        G.save_weights(\".\\\\Output\\\\Gen.h5\")\n",
    "        D.save_weights(\".\\\\Output\\\\Dis.h5\")\n",
    "        GAN.save_weights(\".\\\\Output\\\\GAN.h5\")\n",
    "\n",
    "        # For Prediction\n",
    "        Ghash, checkG = Generator(x_dash, y_dash)\n",
    "        print(\"Prediction\")\n",
    "        Ghash.load_weights('.\\\\output\\\\Gen.h5')\n",
    "        x_pred = [[0, 0, 0, 1, 0, 0],\n",
    "                  [0, 1, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 1]]\n",
    "        preds = Ghash.predict(x_pred)\n",
    "        y_pred = prediction(preds)\n",
    "        y_pred = seq_txt(y_pred, idx_char)\n",
    "        s = smiles_output(y_pred)\n",
    "        print(s)\n",
    "        # end prediction'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
