{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import History\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Purpose: understand TimeDistributedDense\n",
    "TimeDistributedDense applies a same Dense (fully-connected) \n",
    "operation to every timestep of a 3D tensor.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-One LSTM for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Input & otuput data\n",
    "seq = np.array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(len(seq), 1, 1) # input data must 3-dim\n",
    "y = seq.reshape(len(seq), 1) # output data must 2-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 5\n",
    "a =  4*((1+1)*length + length**2) # calculate number of lSTM layer parameters\n",
    "# imput:m, number of cell:n;  number of parameters = 4*(m+1 + n)*n\n",
    "# m = input-dim + bias, n cell have n-dim of ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# try understand the LSTM & Sequence\n",
    "n_epoch = 1  # key 1 only for check parameter\n",
    "\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = length\n",
    "\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(1, 1))) # 5 LSTM cell as hiden layer\n",
    "model.add(Dense(1)) # one neural to output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 3s - loss: 0.2103\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
    "\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "for value in result:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-One LSTM for Sequence Prediction (without  TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Input & otuput data\n",
    "seq = np.array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, len(seq), 1) # input data must 3-dim\n",
    "y = seq.reshape(1, len(seq)) # output data must 2-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 170\n",
      "Trainable params: 170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# try understand the LSTM & Sequence\n",
    "n_epoch = 1  # key 1 only for check parameter\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1))) # 5 LSTM cell ; 5-dim input \n",
    "model.add(Dense(length)) # output layer with 5 neurals\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "# five neural * 5 input + 5bias  = 30 (output layer parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 3s - loss: 0.2052\n",
      "-0.0\n",
      "0.1\n",
      "-0.1\n",
      "0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "for value in result[0,:]:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-Many LSTM for Sequence Prediction (with TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Input & otuput data\n",
    "length = 5\n",
    "seq = np.array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 5, 1)              6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 5\n",
    "\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons,       # 5 LSTM cell\n",
    "               input_shape=(length, 1), # 5-dim input \n",
    "               return_sequences=True))  # True: output at all steps. False: output as last step.\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "# use the TimeDistributed on the output layer to wrap a fully connected Dense layer with a single output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "# output layer only needs one connection to each LSTM unit (plus one bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 5s - loss: 0.3167\n",
      "Epoch 2/5\n",
      " - 0s - loss: 0.3139\n",
      "Epoch 3/5\n",
      " - 0s - loss: 0.3112\n",
      "Epoch 4/5\n",
      " - 0s - loss: 0.3085\n",
      "Epoch 5/5\n",
      " - 0s - loss: 0.3058\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.1\n",
      "-0.1\n"
     ]
    }
   ],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "for value in result[0,:,0]:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Purpose: understand TimeDistributedDense\\nTimeDistributedDense applies a same Dense (fully-connected) \\noperation to every timestep of a 3D tensor.\\nEnd\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Purpose: understand TimeDistributedDense\n",
    "TimeDistributedDense applies a same Dense (fully-connected) \n",
    "operation to every timestep of a 3D tensor.\n",
    "End\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
