{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noriginal Author: Gananath R\\nDrugAI-GAN: Experiments with GAN for drug like molecule generation\\nContact: https://github.com/gananath\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code resource: https://github.com/Gananath/DrugAI/blob/d1f37917ae75e36b93b7ae4ff3cfc62032e78d68/DrugAI-GAN.py#L43\n",
    "\n",
    "'''\n",
    "original Author: Gananath R\n",
    "DrugAI-GAN: Experiments with GAN for drug like molecule generation\n",
    "Contact: https://github.com/gananath\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n. GAN訓練目標是訓練兩組參數: 1.讓分類準確率最高的判別器參數。  2.欺騙率最高的生成器參數。\\n. Cost fuction V(G,D) 包含了生成器和判別器的參數。\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    ". GAN訓練目標是訓練兩組參數: 1.讓分類準確率最高的判別器參數。  2.欺騙率最高的生成器參數。\n",
    ". Cost fuction V(G,D) 包含了生成器和判別器的參數。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import History\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create folder\n",
    "if not os.path.exists(os.getcwd()+'\\\\Output'):\n",
    "    os.makedirs(os.getcwd()+'\\\\Output')\n",
    "# os.path.exists: Return True if path refers to an existing path\n",
    "# getcwd() returns current working directory of a process.\n",
    "\n",
    "\n",
    "# seed for random number reproductio\n",
    "np.random.seed(180221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eric\\\\Anaconda3\\\\4.Algorithm_Practice\\\\TensorFlow'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>cox2</th>\n",
       "      <th>estrogen</th>\n",
       "      <th>gelatinase</th>\n",
       "      <th>neuramidase</th>\n",
       "      <th>kinase</th>\n",
       "      <th>thrombin</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>C[N]1C(=CC(=C1C(=O)C2=CC=C(Cl)C=C2)C)CC(O)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>CN1C(=C(O)C2=C(C=CC=C2)[S]1(=O)=O)C(=O)NC3=NC=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>CCC(C1=CC=C(O)C=C1)=C(CC)C2=CC=C(O)C=C2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>CCC1=C([N](N=C1C2=CC=C(O)C=C2)C3=CC=CC=C3)C4=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CC1=CC(=CN=C1)C2=C(C=C(Cl)C=N2)C3=CC=C(C=C3)[S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>CC12CCC3=C4C=CC(=CC4=CC=C3C1CCC2=O)O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C[S](=O)(=O)NC1=C(SC2=C(F)C=C(F)C=C2)C=C(C=C1)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NC(N)=[NH+]CCCCNC(=O)C1CCCN1C(=O)C([NH3+])CC2=...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>OC1=CC=C(C=C1)C2=C(CC3=CC=C(OCC[NH]4CCCCC4)C=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CCC1=C(Cl)C=C2C=C(C(OC2=C1)C(F)(F)F)C(O)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES  cox2  estrogen  \\\n",
       "65        C[N]1C(=CC(=C1C(=O)C2=CC=C(Cl)C=C2)C)CC(O)=O     1         0   \n",
       "74   CN1C(=C(O)C2=C(C=CC=C2)[S]1(=O)=O)C(=O)NC3=NC=...     1         0   \n",
       "129            CCC(C1=CC=C(O)C=C1)=C(CC)C2=CC=C(O)C=C2     0         1   \n",
       "168  CCC1=C([N](N=C1C2=CC=C(O)C=C2)C3=CC=CC=C3)C4=C...     0         1   \n",
       "99   CC1=CC(=CN=C1)C2=C(C=C(Cl)C=N2)C3=CC=C(C=C3)[S...     1         0   \n",
       "147               CC12CCC3=C4C=CC(=CC4=CC=C3C1CCC2=O)O     0         1   \n",
       "3    C[S](=O)(=O)NC1=C(SC2=C(F)C=C(F)C=C2)C=C(C=C1)...     1         0   \n",
       "269  NC(N)=[NH+]CCCCNC(=O)C1CCCN1C(=O)C([NH3+])CC2=...     0         0   \n",
       "160  OC1=CC=C(C=C1)C2=C(CC3=CC=C(OCC[NH]4CCCCC4)C=C...     0         1   \n",
       "92          CCC1=C(Cl)C=C2C=C(C(OC2=C1)C(F)(F)F)C(O)=O     1         0   \n",
       "\n",
       "     gelatinase  neuramidase  kinase  thrombin  none  \n",
       "65            0            0       0         0     0  \n",
       "74            0            0       0         0     0  \n",
       "129           0            0       0         0     0  \n",
       "168           0            0       0         0     0  \n",
       "99            0            0       0         0     0  \n",
       "147           0            0       0         0     0  \n",
       "3             0            0       0         0     0  \n",
       "269           0            0       0         1     0  \n",
       "160           0            0       0         0     0  \n",
       "92            0            0       0         0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##read csv file\n",
    "data = pd.read_csv('stahl.csv')\n",
    "data = data.reindex(np.random.permutation(data.index))\n",
    "print('Number of data:',len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65         C[N]1C(=CC(=C1C(=O)C2=CC=C(Cl)C=C2)C)CC(O)=O\n",
       "74    CN1C(=C(O)C2=C(C=CC=C2)[S]1(=O)=O)C(=O)NC3=NC=...\n",
       "Name: SMILES, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the SMILES string\n",
    "Y=data.SMILES\n",
    "print(type(Y))\n",
    "Y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:7] # in this case, take the data of column 1:7\n",
    "# DataFrame.iloc: Purely integer-location based indexing for selection by position.\n",
    "X = X.values\n",
    "X = X.astype('int')\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dimX(x,ts):\n",
    "    '''Adding timestep to feature'''\n",
    "    x=np.asarray(x)\n",
    "    newX=[]\n",
    "    for i, c in enumerate(x):\n",
    "        newX.append([])\n",
    "        for j in range(ts):\n",
    "            newX[i].append(c)\n",
    "    return np.array(newX)\n",
    "    # np.asarray(a): convert the input a to an array\n",
    "\n",
    "    \n",
    "def dimY(Y,ts):\n",
    "    '''adding timestep to target'''\n",
    "    temp = np.zeros((len(Y), ts, len(chars)), dtype=np.bool) \n",
    "    for i, c in enumerate(Y):\n",
    "        for j, s in enumerate(c):\n",
    "            #print i, j, s\n",
    "            temp[i, j, char_idx[s]] = 1\n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C[S](=O)(=O)NC1=C(OC2CCCCC2)C=C(C=C1)[N](=O)=O|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##padding smiles to same length by adding \"|\" at the end of smiles\n",
    "maxY = Y.str.len().max() # find the max length of SMILES \n",
    "y = Y.str.ljust(maxY, fillchar='|') # the maxY-th number frim left side, fill '|' \n",
    "ts = y.str.len().max()\n",
    "\n",
    "print(maxY, ts)\n",
    "y[0]\n",
    "#  pandas.series.str\n",
    "#  ljust(): returns the string left justified in a string of length width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 25\n",
      "y_dash shape: (335, 105, 25)\n",
      "x_dash shape: (335, 105, 6)\n"
     ]
    }
   ],
   "source": [
    "# CharToIndex and IndexToChar functions\n",
    "chars = sorted(list( set(\"\".join(y.values.flatten())))) # list with all chars \n",
    "# join() returns a string in which the string elements of \n",
    "#        sequence have been joined by str separator.\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "char_idx= dict((c, i) for i, c in enumerate(chars))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "y_dash = dimY(y,ts)\n",
    "x_dash = dimX(X,ts)\n",
    "\n",
    "print('y_dash shape:', y_dash.shape)\n",
    "print('x_dash shape:', x_dash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gen():\n",
    "    '''Generator model: generating sequence with random noise'''\n",
    "    G = Sequential() # The keras.model.Sequential() model is a linear stack of layers\n",
    "    G.add(TimeDistributed(Dense(x_dash.shape[2]), input_shape=(x_dash.shape[1], x_dash.shape[2])))\n",
    "    # intput a onehot encode (x_dash)\n",
    "    # TimeDistributedDense applies a same Dense (fully-connected) operation to every timestep of a 3D tensor.\n",
    "    \n",
    "    # Hidden layer 1 with 216 LSTM cell \n",
    "    G.add(LSTM(216, return_sequences=True)) \n",
    "    G.add(Dropout(0.3))\n",
    "    # True: output at all steps. False: output as last step.\n",
    "    \n",
    "    # Hidden layer 1 with 216 LSTM cell\n",
    "    G.add(LSTM(216, return_sequences=True))\n",
    "    G.add(Dropout(0.3))\n",
    "    \n",
    "     # Hidden layer 3 with 216 LSTM cell\n",
    "    G.add(LSTM(216, return_sequences=True))\n",
    "    #G.add(BatchNormalization(momentum=0.9))\n",
    "    \n",
    "    # output a SMILES sequence(generating) \n",
    "    G.add(TimeDistributed(Dense(y_dash.shape[2], activation='softmax')))\n",
    "    G.compile(loss='categorical_crossentropy', optimizer=Adam(lr=2e-4))\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def Dis():\n",
    "    '''Discriminator model'''\n",
    "    D = Sequential()\n",
    "    D.add(TimeDistributed(Dense(y_dash.shape[2]), input_shape=(y_dash.shape[1], y_dash.shape[2])))\n",
    "    # Input SMILES sequence\n",
    "    \n",
    "    # Hidden layer 1 with 216 LSTM cell\n",
    "    D.add(LSTM(216, return_sequences=True))\n",
    "    D.add(Dropout(0.3))\n",
    "    \n",
    "    # Hidden layer 1 with 60 LSTM cell\n",
    "    D.add(LSTM(60, return_sequences=True))\n",
    "    D.add(Flatten())\n",
    "    \n",
    "    # output layer with one neural(Real or Fake)\n",
    "    D.add(Dense(1, activation='sigmoid'))\n",
    "    D.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.001))\n",
    "    return D\n",
    "\n",
    "\n",
    "def Gan():\n",
    "    '''Generative adversarial network'''\n",
    "    GAN=Sequential()\n",
    "    GAN.add(G) # Generating mosel\n",
    "    D.trainable=False # Weight of dis model will not change when training GAN\n",
    "    # How model.trainable = False works in keras (GAN model)\n",
    "    # https://gist.github.com/naotokui/a9274f12af9d946e99b6df73a5d2af6d\n",
    "    \n",
    "    GAN.add(D) # Discriminator model\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=Adam(lr=2e-4))\n",
    "    # Cost function including two model result\n",
    "    return GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dash.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing models\n",
    "G=Gen()\n",
    "D=Dis()\n",
    "GAN=Gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif os.path.exists(os.getcwd()+\"/output/Gen.h5\")==True and os.path.exists(os.getcwd()+\"/output/Dis.h5\")==True and os.path.exists(os.getcwd()+\"/output/Gan.h5\")==True:\\n        #loading weights if exits\\n        G.load_weights(os.getcwd()+\"/output/Gen.h5\")\\n        D.load_weights(os.getcwd()+\"/output/Dis.h5\")\\n        GAN.load_weights(os.getcwd()+\"/output/Gan.h5\")\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if os.path.exists(os.getcwd()+\"/output/Gen.h5\")==True and os.path.exists(os.getcwd()+\"/output/Dis.h5\")==True and os.path.exists(os.getcwd()+\"/output/Gan.h5\")==True:\n",
    "        #loading weights if exits\n",
    "        G.load_weights(os.getcwd()+\"/output/Gen.h5\")\n",
    "        D.load_weights(os.getcwd()+\"/output/Dis.h5\")\n",
    "        GAN.load_weights(os.getcwd()+\"/output/Gan.h5\")\n",
    "'''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN input  : (None, 105, 6)\n",
      "GAN output : (None, 1)\n",
      "-----------------------------------\n",
      "Gen input  : (None, 105, 6)\n",
      "Gen output : (None, 105, 25)\n",
      "-----------------------------------\n",
      "Dis input  : (None, 105, 25)\n",
      "Dis output : (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"GAN input  : \"+str(GAN.input_shape))\n",
    "print(\"GAN output : \"+str(GAN.output_shape))\n",
    "print('-----------------------------------')\n",
    "print(\"Gen input  : \"+str(G.input_shape))\n",
    "print(\"Gen output : \"+str(G.output_shape))\n",
    "print('-----------------------------------')\n",
    "print(\"Dis input  : \"+str(D.input_shape))\n",
    "print(\"Dis output : \"+str(D.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_3 (TimeDist (None, 105, 25)           650       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 105, 216)          209088    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 105, 216)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 105, 60)           66480     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6300)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 6301      \n",
      "=================================================================\n",
      "Total params: 282,519\n",
      "Trainable params: 0\n",
      "Non-trainable params: 282,519\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 105, 6)            42        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 105, 216)          192672    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 105, 216)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 105, 216)          374112    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 105, 216)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 105, 216)          374112    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 105, 25)           5425      \n",
      "=================================================================\n",
      "Total params: 946,363\n",
      "Trainable params: 946,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 105, 25)           946363    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 282519    \n",
      "=================================================================\n",
      "Total params: 1,228,882\n",
      "Trainable params: 946,363\n",
      "Non-trainable params: 282,519\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training discrimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle3D(arr):\n",
    "    for a in arr:\n",
    "        np.random.shuffle(a)\n",
    "        \n",
    "\n",
    "def trainDis(data=None,mc=None):\n",
    "    if data is None and mc is None:\n",
    "        # Train on fake data        \n",
    "        fake_data= G.predict(x_dash) # Generating fake data\n",
    "        targets = np.zeros(x_dash.shape[0]).astype(int) # all target = 0\n",
    "        Dloss = D.fit(fake_data, targets, nb_epoch=1) # Train fake data\n",
    "             \n",
    "    elif data is None and mc==\"mc\":\n",
    "        #preventing mode collapse\n",
    "        #artificial noice training \n",
    "        fake_ydata = np.copy(y_dash)\n",
    "        shuffle3D(fake_ydata) # call shuffle3D function to adding noise\n",
    "        targets = np.zeros(x_dash.shape[0]).astype(int) # all target = 0\n",
    "        Dloss = D.fit(fake_ydata, targets,nb_epoch=1) # Train shuffling data  \n",
    "            \n",
    "    else:\n",
    "        # Train on real data\n",
    "        targets = np.ones(x_dash.shape[0]).astype(int) # all target = 1\n",
    "        Dloss = D.fit(data,targets,nb_epoch=1)  # Train real data   \n",
    "    return Dloss.history['loss'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "335/335 [==============================] - 13s 40ms/step - loss: 0.6842\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 28ms/step - loss: 0.6771\n",
      "Pre Training Discrimator 0.677102665047\n",
      "\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 27ms/step - loss: 0.6839\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.6693\n",
      "Pre Training Discrimator 0.669257113649\n",
      "\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.6835\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 28ms/step - loss: 0.6623\n",
      "Pre Training Discrimator 0.66226115458\n",
      "\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.6830\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.6552\n",
      "Pre Training Discrimator 0.65522992095\n",
      "\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 28ms/step - loss: 0.6825\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 28ms/step - loss: 0.6480\n",
      "Pre Training Discrimator 0.647999076701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D.trainable=True\n",
    "\n",
    "#pre training\n",
    "for i in range(5): # con tring 20 or more times\n",
    "    shuffleData = np.random.permutation(y_dash)\n",
    "    # np.random.permutation: Randomly permute a sequence, or return a permuted range.\n",
    "    trainDis() # Train on fake data \n",
    "    dloss = trainDis(shuffleData) # Train on shuffle data\n",
    "    print(\"Pre Training Discrimator \"+str(dloss)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(preds):\n",
    "    '''prediction of sequence with argmax'''\n",
    "    y_pred=[]\n",
    "    for i,c in enumerate(preds):\n",
    "        y_pred.append([])\n",
    "        for j in c:\n",
    "            y_pred[i].append(np.argmax(j))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def seq_txt(y_pred):\n",
    "    '''sequence to text conversion'''\n",
    "    newY=[]\n",
    "    for i,c in enumerate(y_pred):\n",
    "        newY.append([])\n",
    "        for j in c:\n",
    "            newY[i].append(idx_char[j])\n",
    "    return np.array(newY)\n",
    "\n",
    "\n",
    "def smiles_output(s):\n",
    "    '''joined smiles output'''\n",
    "    smiles=np.array([])\n",
    "    for i in s:\n",
    "        j=''.join(str(k) for k in i)\n",
    "        smiles=np.append(smiles,j)\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainGAN():\n",
    "    '''train GAN model'''    \n",
    "    target = np.ones(x_dash.shape[0]).astype(int) # target = 1\n",
    "    gan_loss = GAN.fit(x_dash, target,nb_epoch=1)\n",
    "    \n",
    "    return gan_loss.history['loss'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "335/335 [==============================] - 8s 25ms/step - loss: 0.6817\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 27ms/step - loss: 0.6401\n",
      "Epoch 1/1\n",
      "335/335 [==============================] - 9s 28ms/step - loss: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\engine\\training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "335/335 [==============================] - 51s 151ms/step - loss: 0.7115\n",
      "D loss=0.719996391304 GAN loss=0.711496711845\n",
      "Predicting Molecule\n",
      "[ '222222222222222222222222222||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||'\n",
      " '|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||'\n",
      " '|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||']\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "\n",
    "for episode in range(episodes):\n",
    "    print(\"Epoch \"+str(episode)+\"/\"+str(episodes))\n",
    "    trainDis() # Train on fake data \n",
    "    \n",
    "    shuffleData = np.random.permutation(y_dash)\n",
    "    disloss = trainDis(y_dash) # Train on real data (undate D weight)\n",
    "    disloss = trainDis(mc=\"mc\") # Train on shuffle (fake) data (undate D weight)    \n",
    "    \n",
    "    ganloss = trainGAN() # update G weight   \n",
    "    print(\"D loss=\"+str(disloss)+\" GAN loss=\"+str(ganloss))\n",
    "    \n",
    "    if episode%(episodes/10)==0:\n",
    "        #Saving files            \n",
    "        G.save_weights(\".\\\\Output\\\\Gen_mc.h5\")\n",
    "        D.save_weights(\".\\\\Output\\\\Dis_mc.h5\")\n",
    "        GAN.save_weights(\".\\\\Output\\\\GAN_mc.h5\")\n",
    "        \n",
    "    if episode%(episodes/25)==0:\n",
    "        print(\"Predicting Molecule\")\n",
    "        x_pred = [[0,0,0,1,0,0],[0,1,0,0,0,0],[0,0,0,0,0,1]]\n",
    "        x_pred = dimX(x_pred,ts)   \n",
    "        preds = G.predict(x_pred) # Generating SEMIS\n",
    "        y_pred = prediction(preds)\n",
    "        y_pred = seq_txt(y_pred)\n",
    "        s = smiles_output(y_pred)\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##For Prediction\n",
    "\n",
    "'''\n",
    "#start Prediction\n",
    "Ghash=Gen()\n",
    "Ghash.load_weights('Gen_mc.h5')\n",
    "x_pred=[[0,0,0,1,0,0],\n",
    "        [0,1,0,0,0,0],\n",
    "        [0,0,0,0,0,1]]\n",
    "x_pred=[[0.6,0,0,0,0,0],\n",
    "        [.3,0,0,0,0,0],\n",
    "        [0.7,0,0,0,0,0]]\n",
    "\t\n",
    "x_pred=dimX(x_pred,ts)      \n",
    "preds=Ghash.predict(x_pred)\n",
    "y_pred=prediction(preds)\n",
    "y_pred=seq_txt(y_pred)\n",
    "s=smiles_output(y_pred)\n",
    "print s\n",
    "#end prediction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
