{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# __all__ = [\"AttentionModel\"]\n",
    "print(\"TensorFlow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read data (already reduce dimension)'''\n",
    "x_input = pd.read_csv('plc_x_reduce.csv')\n",
    "y_label = pd.read_csv('plc_y_reduce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_input,\n",
    "                    y_label,\n",
    "                    batch_size=1, \n",
    "                    seq_len=1,\n",
    "                    test_ratio=0.2):\n",
    "    ''' Generating eaach batch data(np.array) into a list'''\n",
    "    \n",
    "    batchs = int(y_label.shape[0] / seq_len / batch_size)\n",
    "    test_batch = int(batchs * test_ratio)\n",
    "    train_batchs = batchs - test_batch\n",
    "    \n",
    "    print('Train Batch: {} ; Test Batch: {}'.format(train_batchs, test_batch))\n",
    "    \n",
    "    train_input = []\n",
    "    train_target = []\n",
    "    test_input = []\n",
    "    test_target = []\n",
    "\n",
    "    up = 0\n",
    "    down = seq_len\n",
    "    for i in range(train_batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            #print(b, x.shape, range(up,down))\n",
    "            x[b, :, :] = x_input[up : down, :]\n",
    "            y[b, :, :] = y_label[up : down, :]\n",
    "            up = down\n",
    "            down = down+seq_len\n",
    "        train_input.append(x)\n",
    "        train_target.append(y)\n",
    "        \n",
    "    for i in range(train_batchs,batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            #print(b, x.shape, range(up,down))\n",
    "            x[b, :, :] = x_input[up : down, :]\n",
    "            y[b, :, :] = y_label[up : down, :]\n",
    "            up = down\n",
    "            down = down+seq_len\n",
    "        test_input.append(x)\n",
    "        test_target.append(y)\n",
    "    return train_input, train_target, test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self,\n",
    "                 seq_max_len=1.,  \n",
    "                 input_len=41.,\n",
    "                 output_len=71.,\n",
    "                 batch_size=1,\n",
    "                 lstm_size=[128., 128., 128.],\n",
    "                 learning_rate=0.005,\n",
    "                 grad_clip=2.,\n",
    "                 keep_prob=0.8,\n",
    "                 forward_only= None):\n",
    "        \n",
    "        self.seq_max_len = seq_max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_len = np.array([])\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_units = self.lstm_size[-1]\n",
    "        self.num_layers = len(self.lstm_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.train_keep_prob = keep_prob\n",
    "        self.go_token = 9.\n",
    "        self.batch_seq_len = np.int32(np.ones(shape=([self.batch_size])) * self.seq_max_len)\n",
    "        \n",
    "        '''Execution method'''\n",
    "        tf.reset_default_graph() #Clears the default graph stack and resets the global default graph\n",
    "        self.build_inputs()\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.saver = tf.train.Saver() #Saves and restores variables.\n",
    " \n",
    "\n",
    "    def build_inputs(self):\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, \n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.input_len),\n",
    "                                         name='inputs')\n",
    "        self.targets = tf.placeholder(tf.float32,\n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.output_len),\n",
    "                                         name='targets')\n",
    "        self.decoder_inputs = tf.placeholder(tf.float32,\n",
    "                                                shape=(self.batch_size, self.seq_max_len, self.output_len),  \n",
    "                                                name='decoder_inputs')        \n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "         \n",
    "        '''if seq is different， sequence input was needed :\n",
    "        self.input_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='input_length')\n",
    "        self.decoder_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='decoder_inputs_length')\n",
    "        self.target_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.float32, name='target_sequence_length')\n",
    "        '''\n",
    "        \n",
    "\n",
    "    # Encoder Model==========================================================================\n",
    "    def build_encoder(self):\n",
    "        ''' Encoder Model'''\n",
    "        def get_a_cell(lstm_size, keep_prop):\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=self.train_keep_prob)\n",
    "            return drop\n",
    "\n",
    "        with tf.variable_scope('encoder', initializer=tf.orthogonal_initializer()):\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                                 [get_a_cell(size, self.keep_prob) for size in self.lstm_size]\n",
    "                                                      )\n",
    "            self.initial_state = encoder_cell.zero_state(self.batch_size, tf.float32)\n",
    "            # 透過dynamic_rnn對cell展開時間維度\n",
    "            self.encoder_outputs, self.encoder_state  = tf.nn.dynamic_rnn(\n",
    "                                                           encoder_cell, \n",
    "                                                           self.encoder_inputs,                                                    \n",
    "                                                           initial_state=self.initial_state\n",
    "                                                                          )\n",
    "\n",
    "            \n",
    "    # Decoder Model==============================================================================\n",
    "    def build_decoder(self):\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(self.lstm_size[-1])\n",
    "        #decoder_cell = tf.contrib.rnn.GRUCell(self.lstm_size[-1])\n",
    "       \n",
    "        '''Project layer (output layer / full connecting layers)'''\n",
    "        project_layer = layers_core.Dense(self.output_len, \n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(mean=0.1,stddev=0.1), \n",
    "                                          name=\"output_projection\") \n",
    "        \n",
    "        ''' Two decoder model:\n",
    "        . training_decoder : for training & target as input\n",
    "        . predict_decoder : for predecting & input by beam search etc...\n",
    "        '''\n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            '''1. Training decoder & output \n",
    "                  Time_major =False(default): [batch_size, max_seq_len, vector_len]\n",
    "                  Time_major =True : [max_seq_len, batch_size, vector_len]\n",
    "            '''\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                                                 self.decoder_inputs, \n",
    "                                                 self.batch_seq_len, \n",
    "                                                 time_major=False)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                                                  cell=decoder_cell,\n",
    "                                                  helper=training_helper,\n",
    "                                                  initial_state=self.encoder_state[-1],#self.encoder_state,\n",
    "                                                  output_layer=project_layer)\n",
    "            train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            self.logits = train_outputs.rnn_output\n",
    "            self.train_prediction = tf.sigmoid(self.logits, name='train_predictions')\n",
    "            t_pred = tf.identity(self.train_prediction, name='t_pred')\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"decode\", reuse=True):\n",
    "            '''2. Predicting decoder & output (same parameter) '''\n",
    "            \n",
    "            '''Three function for CustomHelper'''\n",
    "            def initial_fn():\n",
    "                initial_elements_finished = self.go_token\n",
    "                initial_input = tf.concat(self.go_token, shape=[self.batch_size, self.output_len])\n",
    "                return initial_elements_finished, initial_input\n",
    "\n",
    "            def sample_fn(time, outputs, state):\n",
    "                # 选择logit最大的下标作为sample\n",
    "                prediction = tf.to_int32(outputs)\n",
    "                return prediction\n",
    "\n",
    "            def next_inputs_fn(time, outputs, state, sample_ids):\n",
    "                next_input = tf.concat((outputs, encoder_outputs[time]), 1)\n",
    "                elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n",
    "                next_state = state\n",
    "                return elements_finished, next_inputs, next_state\n",
    "        \n",
    "        \n",
    "            predicting_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)\n",
    "\n",
    "            predicting_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                                                 helper=predicting_helper,\n",
    "                                                                 initial_state=self.encoder_state[-1],\n",
    "                                                                 output_layer=project_layer)\n",
    "            predicting_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            predict_logits = train_outputs.rnn_output\n",
    "            self.final_prediction = tf.sigmoid(predict_logits, name='model_predictions')\n",
    "            model_pred = tf.identity(self.final_prediction, name='model_pred')\n",
    "        \n",
    "        \n",
    "\n",
    "    # Loss & Optimizer ==============================================================================\n",
    "    def build_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            #self.y_reshaped = tf.reshape(self.targets,  self.logits.get_shape())\n",
    "            #self.loss =tf.losses.mean_squared_error(predictions=self.logits, labels=self.targets)\n",
    "            loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, labels=self.targets)\n",
    "            self.loss = tf.reduce_mean(loss)\n",
    "\n",
    "    def build_optimizer(self):\n",
    "        # Using \"clipping\" gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), self.grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimizer = train_op.apply_gradients(zip(grads, tvars))  \n",
    "        \n",
    "        \n",
    "\n",
    "    # Training===============================================================================    \n",
    "    def train(self, x, y, iters=10,  save_every_n=200, log_every_n=200):\n",
    "        self.train_graph = tf.Graph()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(self.initial_state)           \n",
    "            \n",
    "            for ite in range(iters):\n",
    "                step = 0\n",
    "                print('iters: {}'.format(ite))\n",
    "                for i in range(len(x)):\n",
    "                    step += 1\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    feed = {self.encoder_inputs: x[i], \n",
    "                            self.targets: y[i],\n",
    "                            self.decoder_inputs : y[i],\n",
    "                            self.keep_prob: self.train_keep_prob}\n",
    "                            #self.initial_state: new_state}\n",
    "                    \n",
    "                    batch_loss, new_state, pred, target = sess.run([self.loss,\n",
    "                                                      self.optimizer,\n",
    "                                                      self.train_prediction,\n",
    "                                                      self.targets],\n",
    "                                                      feed_dict=feed)\n",
    "                    end = time.time()\n",
    "                    \n",
    "                    # control the print lines\n",
    "                    if step % log_every_n == 0:\n",
    "                        print(\"=======================================================\\n\")\n",
    "                        print('step: {} in iter: {}/{}... '.format(step, ite+1, iters),\n",
    "                              'loss: {:.15f}... '.format(batch_loss),\n",
    "                              '{:.4f} sec/batch'.format((end - start)))\n",
    "\n",
    "                    if (step % save_every_n == 0):\n",
    "                        self.saver.save(sess, './seq2seq_(y_to_x)/model')\n",
    "    \n",
    "    \n",
    "    def predict(self, x, y, variable_name='model_pred'):\n",
    "        with tf.Session() as sess:\n",
    "            loader = tf.train.import_meta_graph('./seq2seq_(y_to_x)/model.meta')\n",
    "            loader.restore(sess, './seq2seq_(y_to_x)/model')\n",
    "            graph = tf.get_default_graph()\n",
    "            \n",
    "            '''Get the tensor'''\n",
    "            encoder_input = graph.get_tensor_by_name('inputs:0')\n",
    "            decoder_input = graph.get_tensor_by_name('decoder_inputs:0')\n",
    "            target = graph.get_tensor_by_name('targets:0')\n",
    "            keep_prob= graph.get_tensor_by_name('keep_prob:0')\n",
    "            '''Note the same name will be added \"_1\" with default'''\n",
    "            prediction = sess.graph.get_tensor_by_name('decode_1/model_pred:0')\n",
    "            \n",
    "            self.count = 0\n",
    "            self.total = 0\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                feed = {self.encoder_inputs: x[i], \n",
    "                                self.targets: y[0], # just make sure target not influence result\n",
    "                                self.decoder_inputs : y[0], # just make sure target not influence result\n",
    "                                self.keep_prob: 1.}\n",
    "                self.answer = sess.run(prediction, feed_dict=feed)\n",
    "                c, t = self.accuracy(self.answer, y[i])\n",
    "                self.count += c\n",
    "                self.total += t\n",
    "        return self.count/self.total\n",
    "            # print(answer)\n",
    "        \n",
    "    \n",
    "    def accuracy(self, pred, target):\n",
    "        pred = np.array(pred)\n",
    "        pred = np.array(pred >= 0.5).astype(int)\n",
    "        result = np.abs(pred - target)\n",
    "        \n",
    "        count = np.sum(result)\n",
    "        total = result.size\n",
    "\n",
    "        for i in range(result.shape[0]):\n",
    "            np.savetxt(\"result_\" + str(i) + \".csv\", result[i], delimiter=',')\n",
    "        return count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 1\n",
    "lstm_size=[102., 102., 102., 102., 102.]\n",
    "learning_rate=0.1\n",
    "keep_prob=0.005\n",
    "\n",
    "iters=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch: 42400 ; Test Batch: 10599\n",
      "iters: 0\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 1/200...  loss: 0.000721882621292...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 1/200...  loss: 1.583938002586365...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 1/200...  loss: 4.622543334960938...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 1/200...  loss: 7.988380908966064...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 1/200...  loss: 11.524027824401855...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 1/200...  loss: 0.000081164638686...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 1/200...  loss: 0.000059726222389...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 1/200...  loss: 0.000048330373829...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 1/200...  loss: 0.000041008221160...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2000 in iter: 1/200...  loss: 0.000035749191738...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2200 in iter: 1/200...  loss: 0.000031689360185...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2400 in iter: 1/200...  loss: 0.000028398284485...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2600 in iter: 1/200...  loss: 0.000025638220905...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2800 in iter: 1/200...  loss: 14.548367500305176...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 3000 in iter: 1/200...  loss: 0.325093775987625...  0.0030 sec/batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-6e50fe7ff37f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0msave_every_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mlog_every_n\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             )\n",
      "\u001b[1;32m<ipython-input-90-4873dad45ce8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, iters, save_every_n, log_every_n)\u001b[0m\n\u001b[0;32m    185\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_prediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                                                       self.targets],\n\u001b[1;32m--> 187\u001b[1;33m                                                       feed_dict=feed)\n\u001b[0m\u001b[0;32m    188\u001b[0m                     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if os.path.exists(save_path) is False:\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "train_input, train_target, test_input, test_target = batch_generator(y_label.values,\n",
    "                                                                     x_input.values, \n",
    "                                                               \n",
    "                                                              batch_size=batch_size, \n",
    "                                                              seq_len=seq_len)\n",
    "\n",
    "model = Seq2Seq(batch_size=batch_size, \n",
    "                seq_max_len=seq_len,\n",
    "                lstm_size=lstm_size,\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "model.train(train_input, \n",
    "            train_target,\n",
    "            iters=iters,\n",
    "            save_every_n=1000,\n",
    "            log_every_n =200\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./seq2seq_(y_to_x)/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06363933007025604"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.14581670115479609"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating graph (by TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./seq2seq_models/model',graph=tf.get_default_graph())\n",
    "writer.close()\n",
    "'''\n",
    "1. in terminal：　tensorboard --logdir path/to/modelfile\n",
    "2. view graph in browser\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tensorflow.python.layers:\n",
    "layers 模塊提供用於深度學習的更高層次封裝的 API，\n",
    "\n",
    "tf.layers 模塊提供的方法有：\n",
    "    Input(…): 用於實例化一個輸入 Tensor，作為神經網絡的輸入。\n",
    "    average_pooling1d(…): 一維平均池化層\n",
    "    average_pooling2d(…): 二維平均池化層\n",
    "    average_pooling3d(…): 三維平均池化層\n",
    "    batch_normalization(…): 批量標準化層\n",
    "    conv1d(…): 一維卷積層\n",
    "    conv2d(…): 二維卷積層\n",
    "    conv2d_transpose(…): 二維反捲積層\n",
    "    conv3d(…): 三維卷積層\n",
    "    conv3d_transpose(…): 三維反捲積層\n",
    "    dense(…): 全連接層\n",
    "    dropout(…): Dropout層\n",
    "    flatten(…): Flatten層，即把一個 Tensor 展平\n",
    "    max_pooling1d(…): 一維最大池化層\n",
    "    max_pooling2d(…): 二維最大池化層\n",
    "    max_pooling3d(…): 三維最大池化層\n",
    "    separable_conv2d(…): 二維深度可分離卷積層\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
