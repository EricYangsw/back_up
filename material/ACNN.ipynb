{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "deepchem/contrib/atomicconv/models/atomicnet.py\n",
    "https://github.com/deepchem/deepchem/blob/10e276690c15cf21b2c37a5109f3f4bdcb1f3894/contrib/atomicconv/models/atomicnet.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "#__author__ = \"Joseph Gomes\"\n",
    "#__copyright__ = \"Copyright 2016, Stanford University\"\n",
    "#__license__ = \"MIT\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepchem.data import DiskDataset\n",
    "from deepchem.nn import model_ops\n",
    "from legacy import TensorflowGraph, TensorflowGraphModel, TensorflowMultiTaskRegressor\n",
    "from deepchem.utils.save import log\n",
    "import atomicnet_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorflowFragmentRegressor(TensorflowMultiTaskRegressor):\n",
    "    \"\"\"Create atomic convolution neural network potential for binding energy.\n",
    "    Example:\n",
    "    >>> B = 10 # batch_size\n",
    "    >>> N_1 = 6 # frag1_n_atoms\n",
    "    >>> N_2 = 6 # frag2_n_atoms\n",
    "    >>> N = 12 # complex_n_atoms\n",
    "    >>> M = 6 # n_neighbors\n",
    "    >>> n_tasks = 1\n",
    "    >>> C_1 = np.zeros((N_1, 3))\n",
    "    >>> C_2 = np.zeros((N_2, 3))\n",
    "    >>> C = np.zeros((N, 3))\n",
    "    >>> NL_1 = {}\n",
    "    >>> for i in range(n_atoms): NL_1[i] = [0 for m in range(M)]\n",
    "    >>> NL_2 = {}\n",
    "    >>> for i in range(n_atoms): NL_2[i] = [0 for m in range(M)]\n",
    "    >>> NL = {}\n",
    "    >>> for i in range(n_atoms): NL[i] = [0 for m in range(M)]\n",
    "    >>> Z_1 = np.zeros((N))\n",
    "    >>> Z_2 = np.zeros((N))\n",
    "    >>> Z = np.zeros((N))\n",
    "    >>> X = [(C_1, NL_1, Z_1, C_2, NL_2, Z_2, C, NL, Z) for i in range(B)]\n",
    "    >>> y = np.zeros(B, n_tasks)\n",
    "    >>> w = np.zeros(B, n_tasks)\n",
    "    >>> ids = np.zeros(B,)\n",
    "    >>> dataset = dc.data.NumpyDataset(X, y, w, ids)\n",
    "    >>> rp = [[12.0, 0.0, 0.04]]\n",
    "    >>> at = None\n",
    "    >>> model = TensorflowFragmentRegressor(n_tasks, rp, at, N_1, N_2, N, M)\n",
    "    >>> model.fit(dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        \n",
    "        n_tasks,\n",
    "        radial_params,\n",
    "        atom_types,\n",
    "        frag1_num_atoms,\n",
    "        frag2_num_atoms,\n",
    "        complex_num_atoms,\n",
    "        max_num_neighbors,\n",
    "        logdir=None,\n",
    "\n",
    "        # Tensorflow related parameter\n",
    "        layer_sizes=[100],\n",
    "        weight_init_stddevs=[0.1],\n",
    "        bias_init_consts=[1.],\n",
    "        penalty=0.0,\n",
    "        penalty_type=\"l2\",\n",
    "        dropouts=[0.5],\n",
    "        learning_rate=.001,\n",
    "        momentum=.8,\n",
    "        optimizer=\"adam\",\n",
    "        batch_size=48,\n",
    "        conv_layers=1,\n",
    "        boxsize=None,\n",
    "        verbose=True,\n",
    "        seed=None):\n",
    "        \"\"\"Initialize TensorflowFragmentRegressor.\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_tasks: int\n",
    "                 Number of tasks.\n",
    "        radial_params: list\n",
    "                       Of length l, where l is number of radial filters learned.\n",
    "        atom_types: list\n",
    "                    Of length a, where a is number of atom_types for filtering.\n",
    "        frag1_num_atoms: int\n",
    "                         Maximum number of atoms in fragment 1.\n",
    "        frag2_num_atoms: int\n",
    "                         Maximum number of atoms in fragment 2.\n",
    "        complex_num_atoms: int\n",
    "                           Maximum number of atoms in complex.\n",
    "        max_num_neighbors: int\n",
    "                           Maximum number of neighbors per atom.\n",
    "        logdir: str\n",
    "                Path to model save directory.\n",
    "        layer_sizes: list\n",
    "                     List of layer sizes.\n",
    "        weight_init_stddevs: list\n",
    "                             List of standard deviations for weights (sampled from zero-mean\n",
    "                             gaussians). One for each layer.\n",
    "        bias_init_consts: list\n",
    "                          List of bias initializations. One for each layer.\n",
    "        penalty: float\n",
    "                 Amount of penalty (l2 or l1 applied)\n",
    "        penalty_type: str\n",
    "                      Either \"l2\" or \"l1\"\n",
    "        dropouts: list\n",
    "                  List of dropout amounts. One for each layer.\n",
    "        learning_rate: float\n",
    "                       Learning rate for model.\n",
    "        momentum: float\n",
    "                  Momentum. Only applied if optimizer==\"momentum\"\n",
    "        optimizer: str\n",
    "                   Type of optimizer applied.\n",
    "        batch_size: int\n",
    "                    Size of minibatches for training.\n",
    "        conv_layers: int\n",
    "                     Number of atomic convolution layers (experimental feature).\n",
    "        boxsize: float or None\n",
    "                 Simulation box length [Angstrom]. If None, no periodic boundary conditions.\n",
    "        verbose: bool, optional (Default True)\n",
    "                 Whether to perform logging.\n",
    "        seed: int, optional (Default None)\n",
    "              If not none, is used as random seed for tensorflow.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_tasks = n_tasks\n",
    "        self.radial_params = radial_params\n",
    "        self.atom_types = atom_types\n",
    "        self.frag1_num_atoms = frag1_num_atoms\n",
    "        self.frag2_num_atoms = frag2_num_atoms\n",
    "        self.complex_num_atoms = complex_num_atoms\n",
    "        self.max_num_neighbors = max_num_neighbors\n",
    "        self.conv_layers = conv_layers\n",
    "        self.boxsize = boxsize\n",
    "\n",
    "        # from legacy import TensorflowGraphModel\n",
    "        TensorflowGraphModel.__init__(\n",
    "            self,\n",
    "            n_tasks,\n",
    "            None,\n",
    "            logdir,\n",
    "            layer_sizes=layer_sizes,\n",
    "            weight_init_stddevs=weight_init_stddevs,\n",
    "            bias_init_consts=bias_init_consts,\n",
    "            penalty=penalty,\n",
    "            penalty_type=penalty_type,\n",
    "            dropouts=dropouts,\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=momentum,\n",
    "            optimizer=optimizer,\n",
    "            batch_size=batch_size,\n",
    "            pad_batches=True,\n",
    "            verbose=verbose,\n",
    "            seed=seed)\n",
    "    \n",
    "\n",
    "    def construct_feed_dict(self, F_b, y_b=None, w_b=None, ids_b=None):\n",
    "        \"\"\"Construct a feed dictionary from minibatch data.\n",
    "        B = batch_size, N = max_num_atoms\n",
    "        Parameters\n",
    "        ----------\n",
    "        F_b: np.ndarray of B tuples of (X_1, L_1, Z_1, X_2, L_2, Z_2, X, L, Z) \n",
    "          X_1: ndarray shape (N, 3).\n",
    "               Fragment 1 Cartesian coordinates [Angstrom].\n",
    "          L_1: dict with N keys.\n",
    "               Fragment 1 neighbor list.\n",
    "          Z_1: ndarray shape (N,).\n",
    "               Fragment 1 atomic numbers.\n",
    "          X_2: ndarray shape (N, 3).\n",
    "               Fragment 2 Cartesian coordinates [Angstrom].\n",
    "          L_2: dict with N keys.\n",
    "               Fragment 2 neighbor list.\n",
    "          Z_2: ndarray shape (N,).\n",
    "               Fragment 2 atomic numbers.\n",
    "          X: ndarray shape (N, 3).\n",
    "             Complex Cartesian coordinates [Angstrom].\n",
    "          L: dict with N keys.\n",
    "             Complex neighbor list.\n",
    "          Z: ndarray shape (N,).\n",
    "             Complex atomic numbers.\n",
    "          y_b: np.ndarray of shape (B, num_tasks)\n",
    "               Tasks.\n",
    "          w_b: np.ndarray of shape (B, num_tasks)\n",
    "               Task weights.\n",
    "          ids_b: List of length (B,) \n",
    "                 Datapoint identifiers. Not currently used.\n",
    "        Returns\n",
    "        -------\n",
    "        retval: dict\n",
    "          Tensorflow feed dict\n",
    "        \"\"\"\n",
    "\n",
    "        N = self.complex_num_atoms\n",
    "        N_1 = self.frag1_num_atoms\n",
    "        N_2 = self.frag2_num_atoms\n",
    "        M = self.max_num_neighbors\n",
    "\n",
    "        orig_dict = {}\n",
    "        batch_size = F_b.shape[0]\n",
    "        num_features = F_b[0][0].shape[1]\n",
    "        frag1_X_b = np.zeros((batch_size, N_1, num_features))\n",
    "        for i in range(batch_size):\n",
    "            frag1_X_b[i] = F_b[i][0]\n",
    "        orig_dict[\"frag1_X_placeholder\"] = frag1_X_b\n",
    "\n",
    "        frag2_X_b = np.zeros((batch_size, N_2, num_features))\n",
    "        for i in range(batch_size):\n",
    "            frag2_X_b[i] = F_b[i][3]\n",
    "        orig_dict[\"frag2_X_placeholder\"] = frag2_X_b\n",
    "\n",
    "        complex_X_b = np.zeros((batch_size, N, num_features))\n",
    "        for i in range(batch_size):\n",
    "            complex_X_b[i] = F_b[i][6]\n",
    "        orig_dict[\"complex_X_placeholder\"] = complex_X_b\n",
    "\n",
    "        frag1_Nbrs = np.zeros((batch_size, N_1, M))\n",
    "        frag1_Z_b = np.zeros((batch_size, N_1))\n",
    "        for i in range(batch_size):\n",
    "            frag1_Z_b[i] = F_b[i][2]\n",
    "        frag1_Nbrs_Z = np.zeros((batch_size, N_1, M))\n",
    "        for atom in range(N_1):\n",
    "            for i in range(batch_size):\n",
    "                atom_nbrs = F_b[i][1].get(atom, \"\")\n",
    "                frag1_Nbrs[i, atom, :len(atom_nbrs)] = np.array(atom_nbrs)\n",
    "                for j, atom_j in enumerate(atom_nbrs):\n",
    "                    frag1_Nbrs_Z[i, atom, j] = frag1_Z_b[i, atom_j]\n",
    "\n",
    "        orig_dict[\"frag1_Z_placeholder\"] = frag1_Z_b\n",
    "        orig_dict[\"frag1_Nbrs_placeholder\"] = frag1_Nbrs\n",
    "        orig_dict[\"frag1_Nbrs_Z_placeholder\"] = frag1_Nbrs_Z\n",
    "\n",
    "        frag2_Nbrs = np.zeros((batch_size, N_2, M))\n",
    "        frag2_Z_b = np.zeros((batch_size, N_2))\n",
    "        for i in range(batch_size):\n",
    "            frag2_Z_b[i] = F_b[i][5]\n",
    "        frag2_Nbrs_Z = np.zeros((batch_size, N_2, M))\n",
    "        for atom in range(N_2):\n",
    "            for i in range(batch_size):\n",
    "                atom_nbrs = F_b[i][4].get(atom, \"\")\n",
    "                frag2_Nbrs[i, atom, :len(atom_nbrs)] = np.array(atom_nbrs)\n",
    "                for j, atom_j in enumerate(atom_nbrs):\n",
    "                    frag2_Nbrs_Z[i, atom, j] = frag2_Z_b[i, atom_j]\n",
    "\n",
    "        orig_dict[\"frag2_Z_placeholder\"] = frag2_Z_b\n",
    "        orig_dict[\"frag2_Nbrs_placeholder\"] = frag2_Nbrs\n",
    "        orig_dict[\"frag2_Nbrs_Z_placeholder\"] = frag2_Nbrs_Z\n",
    "\n",
    "        complex_Nbrs = np.zeros((batch_size, N, M))\n",
    "        complex_Z_b = np.zeros((batch_size, N))\n",
    "        for i in range(batch_size):\n",
    "            complex_Z_b[i] = F_b[i][8]\n",
    "        complex_Nbrs_Z = np.zeros((batch_size, N, M))\n",
    "        for atom in range(N):\n",
    "            for i in range(batch_size):\n",
    "                atom_nbrs = F_b[i][7].get(atom, \"\")\n",
    "                complex_Nbrs[i, atom, :len(atom_nbrs)] = np.array(atom_nbrs)\n",
    "                for j, atom_j in enumerate(atom_nbrs):\n",
    "                      complex_Nbrs_Z[i, atom, j] = complex_Z_b[i, atom_j]\n",
    "\n",
    "        orig_dict[\"complex_Z_placeholder\"] = complex_Z_b\n",
    "        orig_dict[\"complex_Nbrs_placeholder\"] = complex_Nbrs\n",
    "        orig_dict[\"complex_Nbrs_Z_placeholder\"] = complex_Nbrs_Z\n",
    "        for task in range(self.n_tasks):\n",
    "            if y_b is not None:\n",
    "                orig_dict[\"labels_%d\" % task] = y_b[:, task]\n",
    "            else:\n",
    "                orig_dict[\"labels_%d\" % task] = np.zeros((self.batch_size,))\n",
    "            if w_b is not None:\n",
    "                orig_dict[\"weights_%d\" % task] = w_b[:, task]\n",
    "            else:\n",
    "                orig_dict[\"weights_%d\" % task] = np.ones((self.batch_size,))\n",
    "        return TensorflowGraph.get_feed_dict(orig_dict)\n",
    "        #from legacy import TensorflowGraph\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def build(self, graph, name_scopes, training):\n",
    "        # build model\n",
    "        N = self.complex_num_atoms\n",
    "        N_1 = self.frag1_num_atoms\n",
    "        N_2 = self.frag2_num_atoms\n",
    "        M = self.max_num_neighbors\n",
    "        B = self.batch_size\n",
    "        placeholder_scope = TensorflowGraph.get_placeholder_scope(graph,\n",
    "                                                                  name_scopes)\n",
    "        with graph.as_default():\n",
    "            # input data\n",
    "            with placeholder_scope:\n",
    "                self.frag1_X_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_1, 3], name='frag1_X_placeholder')\n",
    "                self.frag1_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_1], name='frag1_Z_placeholder')\n",
    "                self.frag1_Nbrs_placeholder = tf.placeholder(\n",
    "                    tf.int32, shape=[B, N_1, M], name=\"frag1_Nbrs_placeholder\")\n",
    "                self.frag1_Nbrs_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_1, M], name='frag1_Nbrs_Z_placeholder')\n",
    "                self.frag2_X_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_2, 3], name='frag2_X_placeholder')\n",
    "                self.frag2_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_2], name='frag2_Z_placeholder')\n",
    "                self.frag2_Nbrs_placeholder = tf.placeholder(\n",
    "                    tf.int32, shape=[B, N_2, M], name=\"frag2_Nbrs_placeholder\")\n",
    "                self.frag2_Nbrs_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N_2, M], name='frag2_Nbrs_Z_placeholder')\n",
    "                self.complex_X_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N, 3], name='complex_X_placeholder')\n",
    "                self.complex_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N], name='complex_Z_placeholder')\n",
    "                self.complex_Nbrs_placeholder = tf.placeholder(\n",
    "                    tf.int32, shape=[B, N, M], name=\"complex_Nbrs_placeholder\")\n",
    "                self.complex_Nbrs_Z_placeholder = tf.placeholder(\n",
    "                    tf.float32, shape=[B, N, M], name='complex_Nbrs_Z_placeholder')\n",
    "\n",
    "            layer_sizes = self.layer_sizes\n",
    "            weight_init_stddevs = self.weight_init_stddevs\n",
    "            bias_init_consts = self.bias_init_consts\n",
    "            dropouts = self.dropouts\n",
    "            boxsize = self.boxsize\n",
    "            conv_layers = self.conv_layers\n",
    "            lengths_set = {\n",
    "                          len(layer_sizes),\n",
    "                          len(weight_init_stddevs),\n",
    "                          len(bias_init_consts),\n",
    "                          len(dropouts),\n",
    "                           }\n",
    "            assert len(lengths_set) == 1, 'All layer params must have same length.'\n",
    "            num_layers = lengths_set.pop()\n",
    "            assert num_layers > 0, 'Must have some layers defined.'\n",
    "            radial_params = self.radial_params\n",
    "            atom_types = self.atom_types\n",
    "\n",
    "            \n",
    "            # First layer (build by atomicnet_ops.AtomicConvolutionLayer)  **import atomicnet_ops\n",
    "            frag1_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                 self.frag1_X_placeholder, self.frag1_Nbrs_placeholder,\n",
    "                 self.frag1_Nbrs_Z_placeholder, atom_types, radial_params, boxsize, B,\n",
    "                 N_1, M, 3)\n",
    "            for x in range(conv_layers - 1):\n",
    "                l = int(frag1_layer.get_shape()[-1])\n",
    "                frag1_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                    frag1_layer, self.frag1_Nbrs_placeholder,\n",
    "                    self.frag1_Nbrs_Z_placeholder, atom_types, radial_params, boxsize,\n",
    "                    B, N_1, M, l)\n",
    "                \n",
    "            # Second layer \n",
    "            frag2_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                  self.frag2_X_placeholder, self.frag2_Nbrs_placeholder,\n",
    "                  self.frag2_Nbrs_Z_placeholder, atom_types, radial_params, boxsize, B,\n",
    "                  N_2, M, 3)\n",
    "            for x in range(conv_layers - 1):\n",
    "                l = int(frag2_layer.get_shape()[-1])\n",
    "                frag2_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                    frag2_layer, self.frag2_Nbrs_placeholder,\n",
    "                    self.frag2_Nbrs_Z_placeholder, atom_types, radial_params, boxsize,\n",
    "                    B, N_2, M, l)\n",
    "                \n",
    "            # Third layer\n",
    "            complex_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                  self.complex_X_placeholder, self.complex_Nbrs_placeholder,\n",
    "                  self.complex_Nbrs_Z_placeholder, atom_types, radial_params, boxsize,\n",
    "                  B, N, M, 3)\n",
    "            for x in range(conv_layers - 1):\n",
    "                l = int(complex_layer.get_shape()[-1])\n",
    "                complex_layer = atomicnet_ops.AtomicConvolutionLayer(\n",
    "                    complex_layer, self.complex_Nbrs_placeholder,\n",
    "                    self.complex_Nbrs_Z_placeholder, atom_types, radial_params, boxsize,\n",
    "                    B, N, M, l)\n",
    "\n",
    "                \n",
    "            weights = []\n",
    "            biases = []\n",
    "            output_weights = []\n",
    "            output_biases = []\n",
    "            output = []\n",
    "\n",
    "            n_features = int(frag1_layer.get_shape()[-1])\n",
    "\n",
    "            for ind, atomtype in enumerate(atom_types):\n",
    "                prev_layer_size = n_features\n",
    "                weights.append([])\n",
    "                biases.append([])\n",
    "                output_weights.append([])\n",
    "                output_biases.append([])\n",
    "                for i in range(num_layers):\n",
    "                    weight, bias = atomicnet_ops.InitializeWeightsBiases(\n",
    "                          prev_layer_size=prev_layer_size,\n",
    "                          size=layer_sizes[i],\n",
    "                          weights=tf.truncated_normal(\n",
    "                          shape=[prev_layer_size, layer_sizes[i]],\n",
    "                          stddev=weight_init_stddevs[i]),\n",
    "                          biases=tf.constant(\n",
    "                          value=bias_init_consts[i], shape=[layer_sizes[i]]))\n",
    "                weights[ind].append(weight)\n",
    "                biases[ind].append(bias)\n",
    "                prev_layer_size = layer_sizes[i]\n",
    "                \n",
    "            # Save weight **import atomicnet_ops\n",
    "            weight, bias = atomicnet_ops.InitializeWeightsBiases(prev_layer_size, 1)\n",
    "            output_weights[ind].append(weight)\n",
    "            output_biases[ind].append(bias)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        def atomnet(current_input, atomtype):\n",
    "            prev_layer = current_input\n",
    "\n",
    "            for i in range(num_layers):\n",
    "                layer = atomicnet_ops.AtomicNNLayer(\n",
    "                      tensor=prev_layer,\n",
    "                      size=layer_sizes[i],\n",
    "                      weights=weights[atomtype][i],\n",
    "                      biases=biases[atomtype][i])\n",
    "                layer = tf.nn.relu(layer)\n",
    "                layer = model_ops.dropout(layer, dropouts[i], training)\n",
    "                prev_layer = layer\n",
    "                prev_layer_size = layer_sizes[i]\n",
    "\n",
    "            output_layer = tf.squeeze(\n",
    "                    atomicnet_ops.AtomicNNLayer(\n",
    "                    tensor=prev_layer,\n",
    "                    size=prev_layer_size,\n",
    "                    weights=output_weights[atomtype][0],\n",
    "                    biases=output_biases[atomtype][0]))\n",
    "            return output_layer\n",
    "        \n",
    "        \n",
    "\n",
    "        frag1_zeros = tf.zeros((B, N_1))\n",
    "        frag2_zeros = tf.zeros((B, N_2))\n",
    "        complex_zeros = tf.zeros((B, N))\n",
    "\n",
    "        frag1_atomtype_energy = []\n",
    "        frag2_atomtype_energy = []\n",
    "        complex_atomtype_energy = []\n",
    "\n",
    "        for ind, atomtype in enumerate(atom_types):\n",
    "\n",
    "            frag1_outputs = tf.map_fn(lambda x: atomnet(x, ind), frag1_layer)\n",
    "            frag2_outputs = tf.map_fn(lambda x: atomnet(x, ind), frag2_layer)\n",
    "            complex_outputs = tf.map_fn(lambda x: atomnet(x, ind), complex_layer)\n",
    "\n",
    "            cond = tf.equal(self.frag1_Z_placeholder, atomtype)\n",
    "            frag1_atomtype_energy.append(tf.where(cond, frag1_outputs, frag1_zeros))\n",
    "            cond = tf.equal(self.frag2_Z_placeholder, atomtype)\n",
    "            frag2_atomtype_energy.append(tf.where(cond, frag2_outputs, frag2_zeros))\n",
    "            cond = tf.equal(self.complex_Z_placeholder, atomtype)\n",
    "            complex_atomtype_energy.append(\n",
    "                tf.where(cond, complex_outputs, complex_zeros))\n",
    "\n",
    "        frag1_outputs = tf.add_n(frag1_atomtype_energy)\n",
    "        frag2_outputs = tf.add_n(frag2_atomtype_energy)\n",
    "        complex_outputs = tf.add_n(complex_atomtype_energy)\n",
    "\n",
    "        frag1_energy = tf.reduce_sum(frag1_outputs, 1)\n",
    "        frag2_energy = tf.reduce_sum(frag2_outputs, 1)\n",
    "        complex_energy = tf.reduce_sum(complex_outputs, 1)\n",
    "        binding_energy = complex_energy - (frag1_energy + frag2_energy)\n",
    "        output.append(binding_energy)\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
