{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "# __all__ = [\"AttentionModel\"]\n",
    "print(\"TensorFlow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tensorflow.python.layers:\n",
    "layers 模塊提供用於深度學習的更高層次封裝的 API，\n",
    "\n",
    "tf.layers 模塊提供的方法有：\n",
    "    Input(…): 用於實例化一個輸入 Tensor，作為神經網絡的輸入。\n",
    "    average_pooling1d(…): 一維平均池化層\n",
    "    average_pooling2d(…): 二維平均池化層\n",
    "    average_pooling3d(…): 三維平均池化層\n",
    "    batch_normalization(…): 批量標準化層\n",
    "    conv1d(…): 一維卷積層\n",
    "    conv2d(…): 二維卷積層\n",
    "    conv2d_transpose(…): 二維反捲積層\n",
    "    conv3d(…): 三維卷積層\n",
    "    conv3d_transpose(…): 三維反捲積層\n",
    "    dense(…): 全連接層\n",
    "    dropout(…): Dropout層\n",
    "    flatten(…): Flatten層，即把一個 Tensor 展平\n",
    "    max_pooling1d(…): 一維最大池化層\n",
    "    max_pooling2d(…): 二維最大池化層\n",
    "    max_pooling3d(…): 三維最大池化層\n",
    "    separable_conv2d(…): 二維深度可分離卷積層\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = pd.read_csv('plc_x_reduce.csv')\n",
    "y_label = pd.read_csv('plc_y_reduce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_input,\n",
    "                    y_label,\n",
    "                    batch_size=1, \n",
    "                    seq_len=1):\n",
    "    \n",
    "    batchs = int(y_label.shape[0] / seq_len / batch_size)\n",
    "    print(batchs)\n",
    "    \n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    \n",
    "    \n",
    "    for i in range(batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            x[b, :, :] = x_input[b*i : b*i+seq_len, :]\n",
    "            y[b, :, :] = y_label[b*i : b*i+seq_len, :]\n",
    "\n",
    "        input_data.append(x)\n",
    "        target_data.append(y)              \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self,\n",
    "                 seq_max_len=1.,  \n",
    "                 input_len=71.,\n",
    "                 output_len=41.,\n",
    "                 batch_size=1,\n",
    "                 lstm_size=[128., 128., 128.],\n",
    "                 learning_rate=0.005,\n",
    "                 grad_clip=2.,\n",
    "                 keep_prob=1.,\n",
    "                 forward_only= None):\n",
    "        \n",
    "        \n",
    "        self.seq_max_len = seq_max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_len = np.array([])\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_units = self.lstm_size[-1]\n",
    "        self.num_layers = len(self.lstm_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.train_keep_prob = keep_prob\n",
    "        \n",
    "        self.batch_seq_len = np.int32(np.ones(shape=([self.batch_size])) * self.seq_max_len)\n",
    "        \n",
    "        tf.reset_default_graph() #Clears the default graph stack and resets the global default graph\n",
    "        self.build_inputs()\n",
    "        #self.build_embedding()\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.saver = tf.train.Saver() #Saves and restores variables.\n",
    " \n",
    "        \n",
    "\n",
    "    def build_inputs(self):\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, \n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.input_len),\n",
    "                                         name='inputs')\n",
    "        self.targets = tf.placeholder(tf.float32,\n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.output_len),\n",
    "                                         name='targets')\n",
    "        self.decoder_inputs = tf.placeholder(tf.float32,\n",
    "                                                shape=(self.batch_size, self.seq_max_len, self.output_len),  \n",
    "                                                name='decoder_inputs')        \n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "         \n",
    "        '''if seq is different， we needd the sequence input :\n",
    "        self.input_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='input_length')\n",
    "        self.decoder_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='decoder_inputs_length')\n",
    "        self.target_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.float32, name='target_sequence_length')\n",
    "        '''\n",
    "\n",
    "    # Encoder Model==========================================================================\n",
    "    def build_encoder(self):\n",
    "        ''' Encoder Model'''\n",
    "        def get_a_cell(lstm_size, keep_prop):\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=self.train_keep_prob)\n",
    "            return drop\n",
    "\n",
    "        with tf.variable_scope('encoder', initializer=tf.orthogonal_initializer()):\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                                 [get_a_cell(size, self.keep_prob) for size in self.lstm_size]\n",
    "                                                      )\n",
    "            self.initial_state = encoder_cell.zero_state(self.batch_size, tf.float32)\n",
    "            # 透過dynamic_rnn對cell展開時間維度\n",
    "            self.encoder_outputs, self.encoder_state  = tf.nn.dynamic_rnn(\n",
    "                                                           encoder_cell, \n",
    "                                                           self.encoder_inputs,                                                    \n",
    "                                                           initial_state=self.initial_state\n",
    "                                                                          )\n",
    "\n",
    "            \n",
    "    # Decoder Model==============================================================================\n",
    "    def build_decoder(self):\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(self.lstm_size[-1])\n",
    "        #decoder_cell = tf.contrib.rnn.GRUCell(self.lstm_size[-1])\n",
    "        \n",
    "        '''Training Helper\n",
    "        Time_major =False(default): [batch_size, max_seq_len, vector_len]\n",
    "        Time_major =True : [max_seq_len, batch_size, vector_len]\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        '''Project layer (output layer, full connecting layers)'''\n",
    "        project_layer = layers_core.Dense(self.output_len, \n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(mean=0.1,stddev=0.1), \n",
    "                                          name=\"output_projection\")\n",
    "        \n",
    "        \n",
    "        ''' Two decoder model:\n",
    "        . training_decoder : for training & target as input\n",
    "        . predict_decoder : for predecting & beam search as input\n",
    "        '''\n",
    "        '''1. Training decoder & output '''\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                                     self.decoder_inputs, self.batch_seq_len, time_major=False)\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                                              cell=decoder_cell,\n",
    "                                              helper=training_helper,\n",
    "                                              initial_state=self.encoder_state[-1],#self.encoder_state,\n",
    "                                              output_layer=project_layer)\n",
    "        train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "        self.logits = train_outputs.rnn_output\n",
    "        self.train_prediction = tf.sigmoid(self.logits, name='predictions')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''2. Predicting decoder & output (same parameter) '''\n",
    "        #predicting_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        #                               self.encoder_state[-1], self.batch_seq_len, time_major=False)\n",
    "        \n",
    "        embedding = tf.get_variable('embedding', [self.output_len, 1])\n",
    "        start_tokens = np.int32(np.ones(shape=([self.batch_size])))\n",
    "        end_token = 0\n",
    "        predicting_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=embedding, start_tokens=start_tokens, end_token=end_token)\n",
    "\n",
    "        predicting_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                                             helper=predicting_helper,\n",
    "                                                             initial_state=self.encoder_state[-1],\n",
    "                                                             output_layer=project_layer)\n",
    "        predicting_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "        predict_logits = train_outputs.rnn_output\n",
    "        self.final_prediction = tf.sigmoid(predict_logits, name='predictions')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    # Loss & Optimizer ==============================================================================\n",
    "    def build_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            #self.y_reshaped = tf.reshape(self.targets,  self.logits.get_shape())\n",
    "            #self.loss =tf.losses.mean_squared_error(predictions=self.logits, labels=self.targets)\n",
    "            self.loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, labels=self.targets)\n",
    "            self.loss = tf.reduce_mean(self.loss)\n",
    "\n",
    "    def build_optimizer(self):\n",
    "        # Using \"clipping\" gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), self.grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    " \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # Training===============================================================================    \n",
    "    def train(self, x, y, iters=10, save_path='./models', save_every_n=200, log_every_n=200):\n",
    "        self.session = tf.Session()\n",
    "        with self.session as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # Train network\n",
    "\n",
    "            sess.run(self.initial_state)\n",
    "            #sess.run(self.d_initial_state)\n",
    "            \n",
    "            \n",
    "            for ite in range(iters):\n",
    "                step = 0\n",
    "                print('iters',ite)\n",
    "                for i in range(len(x)):\n",
    "                    step += 1\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    feed = {self.encoder_inputs: x[i], \n",
    "                            self.targets: y[i],\n",
    "                            self.decoder_inputs : y[i],\n",
    "                            self.keep_prob: self.train_keep_prob}\n",
    "                            #self.initial_state: new_state}\n",
    "                    \n",
    "                    batch_loss, new_state, pred, target = sess.run([self.loss,\n",
    "                                                      self.optimizer,\n",
    "                                                      self.train_prediction,\n",
    "                                                      self.targets],\n",
    "                                                      feed_dict=feed)\n",
    "                    # print result\n",
    "                    #self.print_result(x[i], y[i])\n",
    "                    end = time.time()\n",
    "                    \n",
    "                    # control the print lines\n",
    "                    if step % log_every_n == 0:\n",
    "                        print(\"=======================================================\\n\")\n",
    "                        print('step: {} in iter: {}/{}... '.format(step, ite+1, iters),\n",
    "                              'loss: {:.10f}... '.format(batch_loss),\n",
    "                              '{:.4f} sec/batch'.format((end - start)))\n",
    "\n",
    "                    if (step % save_every_n == 0):\n",
    "                        self.saver.save(sess, os.path.join(save_path, 'model'), global_step=step)\n",
    "                        self.jodge(pred, target)\n",
    "                        #print(\"Target: \\n\", target)\n",
    "                        #print(\"PRED: \\n\",pred)\n",
    "                # print(tf.shape(self.encoder_state), tf.shape(self.d_initial_state))\n",
    "                # print(np.array(state).shape)\n",
    "                # print(np.array(self.d_initial_state).shape, self.d_initial_state)\n",
    "                \n",
    "    \n",
    "    \n",
    "    def predict(self, x, y):\n",
    "        self.session = tf.Session()\n",
    "        with self.session as sess:\n",
    "            feed = {self.encoder_inputs: x, \n",
    "                    self.keep_prob: 1.}\n",
    "            predict = sess.run([self.final_prediction], feed_dict=feed)\n",
    "            return predict\n",
    "            \n",
    "                        \n",
    "    \n",
    "    \n",
    "                \n",
    "    # \n",
    "    def jodge(self, pred, target):\n",
    "        pred = np.array(pred)\n",
    "        pred = np.array(pred >= 0.5).astype(int)\n",
    "\n",
    "        result = np.abs(pred - target)\n",
    "\n",
    "        for i in range(result.shape[0]):\n",
    "            np.savetxt(\"result_\" + str(i) + \".csv\", result[i], delimiter=',')\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 5\n",
    "lstm_size=[128., 128., 128.]\n",
    "learning_rate=0.005\n",
    "\n",
    "iters=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2119\n",
      "iters 0\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 1/1...  loss: 0.1096691713...  0.0140 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 1/1...  loss: 0.0135252718...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 1/1...  loss: 0.0053684143...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 1/1...  loss: 0.0132287201...  0.0090 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 1/1...  loss: 0.0106951119...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 1/1...  loss: 0.0001148187...  0.0080 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 1/1...  loss: 0.0189563818...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 1/1...  loss: 0.0004311473...  0.0070 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 1/1...  loss: 0.0004814954...  0.0100 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 2000 in iter: 1/1...  loss: 0.0008978583...  0.0080 sec/batch\n"
     ]
    }
   ],
   "source": [
    "model_path = './seq2seq_models'\n",
    "\n",
    "if os.path.exists(model_path) is False:\n",
    "    os.makedirs(model_path)\n",
    "    \n",
    "input_data, target_data = batch_generator(x_input.values, \n",
    "                                          y_label.values, \n",
    "                                          batch_size=batch_size, \n",
    "                                          seq_len=seq_len)\n",
    "\n",
    "model = Seq2Seq(batch_size=batch_size, \n",
    "                seq_max_len=seq_len,\n",
    "                lstm_size=lstm_size,\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "model.train(input_data, \n",
    "            target_data,\n",
    "            iters=iters,\n",
    "            save_path=model_path,\n",
    "            save_every_n=1000,\n",
    "            log_every_n =200\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'decoder_inputs' with dtype float and shape [5,5,41]\n\t [[Node: decoder_inputs = Placeholder[dtype=DT_FLOAT, shape=[5,5,41], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'decoder_inputs', defined at:\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-105-9cfbdc765676>\", line 14, in <module>\n    learning_rate=learning_rate)\n  File \"<ipython-input-103-af43a610756e>\", line 29, in __init__\n    self.build_inputs()\n  File \"<ipython-input-103-af43a610756e>\", line 48, in build_inputs\n    name='decoder_inputs')\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'decoder_inputs' with dtype float and shape [5,5,41]\n\t [[Node: decoder_inputs = Placeholder[dtype=DT_FLOAT, shape=[5,5,41], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'decoder_inputs' with dtype float and shape [5,5,41]\n\t [[Node: decoder_inputs = Placeholder[dtype=DT_FLOAT, shape=[5,5,41], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-779e53580ad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-103-af43a610756e>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    212\u001b[0m             feed = {self.encoder_inputs: x, \n\u001b[0;32m    213\u001b[0m                     self.keep_prob: 1.}\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_prediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'decoder_inputs' with dtype float and shape [5,5,41]\n\t [[Node: decoder_inputs = Placeholder[dtype=DT_FLOAT, shape=[5,5,41], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'decoder_inputs', defined at:\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-105-9cfbdc765676>\", line 14, in <module>\n    learning_rate=learning_rate)\n  File \"<ipython-input-103-af43a610756e>\", line 29, in __init__\n    self.build_inputs()\n  File \"<ipython-input-103-af43a610756e>\", line 48, in build_inputs\n    name='decoder_inputs')\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'decoder_inputs' with dtype float and shape [5,5,41]\n\t [[Node: decoder_inputs = Placeholder[dtype=DT_FLOAT, shape=[5,5,41], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.predict(input_data[10], target_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
