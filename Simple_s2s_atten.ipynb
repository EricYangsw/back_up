{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "# __all__ = [\"AttentionModel\"]\n",
    "print(\"TensorFlow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tensorflow.python.layers:\n",
    "layers 模塊提供用於深度學習的更高層次封裝的 API，\n",
    "\n",
    "tf.layers 模塊提供的方法有：\n",
    "    Input(…): 用於實例化一個輸入 Tensor，作為神經網絡的輸入。\n",
    "    average_pooling1d(…): 一維平均池化層\n",
    "    average_pooling2d(…): 二維平均池化層\n",
    "    average_pooling3d(…): 三維平均池化層\n",
    "    batch_normalization(…): 批量標準化層\n",
    "    conv1d(…): 一維卷積層\n",
    "    conv2d(…): 二維卷積層\n",
    "    conv2d_transpose(…): 二維反捲積層\n",
    "    conv3d(…): 三維卷積層\n",
    "    conv3d_transpose(…): 三維反捲積層\n",
    "    dense(…): 全連接層\n",
    "    dropout(…): Dropout層\n",
    "    flatten(…): Flatten層，即把一個 Tensor 展平\n",
    "    max_pooling1d(…): 一維最大池化層\n",
    "    max_pooling2d(…): 二維最大池化層\n",
    "    max_pooling3d(…): 三維最大池化層\n",
    "    separable_conv2d(…): 二維深度可分離卷積層\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = pd.read_csv('plc_x_reduce.csv')\n",
    "y_label = pd.read_csv('plc_y_reduce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_input,\n",
    "                    y_label,\n",
    "                    batch_size=1, \n",
    "                    seq_len=1,\n",
    "                    test_ratio=0.1):\n",
    "    \n",
    "    batchs = int(y_label.shape[0] / seq_len / batch_size)\n",
    "    test_batch = int(batchs* test_ratio)\n",
    "    train_batchs = batchs - test_batch\n",
    "    \n",
    "    print('Train Batch: {} ; Test Batch: {}'.format(train_batchs, test_batch))\n",
    "    \n",
    "    train_input = []\n",
    "    train_target = []\n",
    "    test_input = []\n",
    "    test_target = []\n",
    "\n",
    "    \n",
    "    for i in range(train_batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            x[b, :, :] = x_input[b*i : b*i+seq_len, :]\n",
    "            y[b, :, :] = y_label[b*i : b*i+seq_len, :]\n",
    "        train_input.append(x)\n",
    "        train_target.append(y)\n",
    "        \n",
    "    \n",
    "    for i in range(train_batchs,batchs):\n",
    "        x = np.zeros(shape=(batch_size, seq_len, x_input.shape[1]))\n",
    "        y = np.zeros(shape=(batch_size, seq_len, y_label.shape[1]))\n",
    "        for b in range(batch_size):\n",
    "            x[b, :, :] = x_input[b*i : b*i+seq_len, :]\n",
    "            y[b, :, :] = y_label[b*i : b*i+seq_len, :]\n",
    "        test_input.append(x)\n",
    "        test_target.append(y)\n",
    "    \n",
    "    \n",
    "    return train_input, train_target, test_input, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self,\n",
    "                 seq_max_len=1.,  \n",
    "                 input_len=71.,\n",
    "                 output_len=41.,\n",
    "                 batch_size=1,\n",
    "                 lstm_size=[128., 128., 128.],\n",
    "                 learning_rate=0.005,\n",
    "                 grad_clip=2.,\n",
    "                 keep_prob=1.,\n",
    "                 forward_only= None):\n",
    "        \n",
    "        \n",
    "        self.seq_max_len = seq_max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_len = np.array([])\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_units = self.lstm_size[-1]\n",
    "        self.num_layers = len(self.lstm_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.train_keep_prob = keep_prob\n",
    "        self.go_token = 2.\n",
    "        \n",
    "        self.batch_seq_len = np.int32(np.ones(shape=([self.batch_size])) * self.seq_max_len)\n",
    "        \n",
    "        tf.reset_default_graph() #Clears the default graph stack and resets the global default graph\n",
    "        self.build_inputs()\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.saver = tf.train.Saver() #Saves and restores variables.\n",
    " \n",
    "        \n",
    "\n",
    "    def build_inputs(self):\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, \n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.input_len),\n",
    "                                         name='inputs')\n",
    "        self.targets = tf.placeholder(tf.float32,\n",
    "                                         shape=(self.batch_size, self.seq_max_len, self.output_len),\n",
    "                                         name='targets')\n",
    "        self.decoder_inputs = tf.placeholder(tf.float32,\n",
    "                                                shape=(self.batch_size, self.seq_max_len, self.output_len),  \n",
    "                                                name='decoder_inputs')        \n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "         \n",
    "        '''if seq is different， we needd the sequence input :\n",
    "        self.input_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='input_length')\n",
    "        self.decoder_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.int32, name='decoder_inputs_length')\n",
    "        self.target_sequence_length = tf.placeholder(shape=([self.batch_size]), dtype=tf.float32, name='target_sequence_length')\n",
    "        '''\n",
    "\n",
    "    # Encoder Model==========================================================================\n",
    "    def build_encoder(self):\n",
    "        ''' Encoder Model'''\n",
    "        def get_a_cell(lstm_size, keep_prop):\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=self.train_keep_prob)\n",
    "            return drop\n",
    "\n",
    "        with tf.variable_scope('encoder', initializer=tf.orthogonal_initializer()):\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                                 [get_a_cell(size, self.keep_prob) for size in self.lstm_size]\n",
    "                                                      )\n",
    "            self.initial_state = encoder_cell.zero_state(self.batch_size, tf.float32)\n",
    "            # 透過dynamic_rnn對cell展開時間維度\n",
    "            self.encoder_outputs, self.encoder_state  = tf.nn.dynamic_rnn(\n",
    "                                                           encoder_cell, \n",
    "                                                           self.encoder_inputs,                                                    \n",
    "                                                           initial_state=self.initial_state\n",
    "                                                                          )\n",
    "\n",
    "            \n",
    "    # Decoder Model==============================================================================\n",
    "    def build_decoder(self):\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(self.lstm_size[-1])\n",
    "        #decoder_cell = tf.contrib.rnn.GRUCell(self.lstm_size[-1])\n",
    "        \n",
    "        '''Training Helper\n",
    "        Time_major =False(default): [batch_size, max_seq_len, vector_len]\n",
    "        Time_major =True : [max_seq_len, batch_size, vector_len]\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        '''Project layer (output layer, full connecting layers)'''\n",
    "        project_layer = layers_core.Dense(self.output_len, \n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(mean=0.1,stddev=0.1), \n",
    "                                          name=\"output_projection\")\n",
    "        \n",
    "        \n",
    "        ''' Two decoder model:\n",
    "        . training_decoder : for training & target as input\n",
    "        . predict_decoder : for predecting & beam search as input\n",
    "        '''\n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            '''1. Training decoder & output '''\n",
    "            \n",
    "            #go_tokens = tf.constant(go_token, shape=[batch_size, 1, 1])\n",
    "            #dec_input = tf.concat([go_tokens, target_data], axis=1)\n",
    "            \n",
    "            \n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                                         self.decoder_inputs, self.batch_seq_len, time_major=False)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                                                  cell=decoder_cell,\n",
    "                                                  helper=training_helper,\n",
    "                                                  initial_state=self.encoder_state[-1],#self.encoder_state,\n",
    "                                                  output_layer=project_layer)\n",
    "            train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            self.logits = train_outputs.rnn_output\n",
    "            self.train_prediction = tf.sigmoid(self.logits, name='train_predictions')\n",
    "            t_pred = tf.identity(self.train_prediction, name='t_pred')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #go_tokens = tf.constant(\n",
    "        #                self.go_token, shape=[self.batch_size, 1, self.output_len])\n",
    "        #tf.concat([go_tokens, output_data], axis=1)\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"decode\", reuse=True):\n",
    "            '''2. Predicting decoder & output (same parameter) '''\n",
    "            #predicting_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            #                               self.encoder_state[-1], self.batch_seq_len, time_major=False)\n",
    "            \n",
    "            def initial_fn():\n",
    "                initial_elements_finished = self.go_token\n",
    "                initial_input = tf.concat(self.go_token, shape=[self.batch_size, self.output_len])\n",
    "                return initial_elements_finished, initial_input\n",
    "\n",
    "            def sample_fn(time, outputs, state):\n",
    "                # 选择logit最大的下标作为sample\n",
    "                prediction = tf.to_int32(outputs, axis=1)\n",
    "                return prediction\n",
    "\n",
    "            def next_inputs_fn(time, outputs, state, sample_ids):\n",
    "                next_input = tf.concat((outputs, encoder_outputs[time]), 1)\n",
    "                elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n",
    "                next_state = state\n",
    "                return elements_finished, next_inputs, next_state\n",
    "        \n",
    "        \n",
    "            predicting_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)\n",
    "\n",
    "            predicting_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                                                 helper=predicting_helper,\n",
    "                                                                 initial_state=self.encoder_state[-1],\n",
    "                                                                 output_layer=project_layer)\n",
    "            predicting_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True)\n",
    "            predict_logits = train_outputs.rnn_output\n",
    "            self.final_prediction = tf.sigmoid(predict_logits, name='model_predictions')\n",
    "            model_pred = tf.identity(self.final_prediction, name='model_pred')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    # Loss & Optimizer ==============================================================================\n",
    "    def build_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            #self.y_reshaped = tf.reshape(self.targets,  self.logits.get_shape())\n",
    "            #self.loss =tf.losses.mean_squared_error(predictions=self.logits, labels=self.targets)\n",
    "            self.loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.logits, labels=self.targets)\n",
    "            self.loss = tf.reduce_mean(self.loss)\n",
    "\n",
    "    def build_optimizer(self):\n",
    "        # Using \"clipping\" gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), self.grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    " \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # Training===============================================================================    \n",
    "    def train(self, x, y, iters=10,  save_every_n=200, log_every_n=200):\n",
    "        self.train_graph = tf.Graph()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(self.initial_state)\n",
    "            #sess.run(self.d_initial_state)\n",
    "            \n",
    "            \n",
    "            for ite in range(iters):\n",
    "                step = 0\n",
    "                print('iters',ite)\n",
    "                for i in range(len(x)):\n",
    "                    step += 1\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    feed = {self.encoder_inputs: x[i], \n",
    "                            self.targets: y[i],\n",
    "                            self.decoder_inputs : y[i],\n",
    "                            self.keep_prob: self.train_keep_prob}\n",
    "                            #self.initial_state: new_state}\n",
    "                    \n",
    "                    batch_loss, new_state, pred, target = sess.run([self.loss,\n",
    "                                                      self.optimizer,\n",
    "                                                      self.train_prediction,\n",
    "                                                      self.targets],\n",
    "                                                      feed_dict=feed)\n",
    "                    # print result\n",
    "                    #self.print_result(x[i], y[i])\n",
    "                    end = time.time()\n",
    "                    \n",
    "                    # control the print lines\n",
    "                    if step % log_every_n == 0:\n",
    "                        print(\"=======================================================\\n\")\n",
    "                        print('step: {} in iter: {}/{}... '.format(step, ite+1, iters),\n",
    "                              'loss: {:.10f}... '.format(batch_loss),\n",
    "                              '{:.4f} sec/batch'.format((end - start)))\n",
    "\n",
    "                    if (step % save_every_n == 0):\n",
    "                        self.saver.save(sess, './seq2seq_models/model')\n",
    "                        #print(\"Target: \\n\", target)\n",
    "                        #print(\"PRED: \\n\",pred)\n",
    "                # print(tf.shape(self.encoder_state), tf.shape(self.d_initial_state))\n",
    "                # print(np.array(state).shape)\n",
    "                # print(np.array(self.d_initial_state).shape, self.d_initial_state)\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, x, y, variable_name='model_pred'):\n",
    "        with tf.Session() as sess:\n",
    "            loader = tf.train.import_meta_graph('./seq2seq_models/model.meta')\n",
    "            loader.restore(sess, './seq2seq_models/model')\n",
    "            graph = tf.get_default_graph()\n",
    "            \n",
    "            encoder_input = graph.get_tensor_by_name('inputs:0')\n",
    "            decoder_input = graph.get_tensor_by_name('decoder_inputs:0')\n",
    "            target = graph.get_tensor_by_name('targets:0')\n",
    "            keep_prob= graph.get_tensor_by_name('keep_prob:0')\n",
    "            \n",
    "            prediction = sess.graph.get_tensor_by_name('decode_1/model_pred:0')\n",
    "            \n",
    "            self.count = 0\n",
    "            self.total = 0\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                feed = {self.encoder_inputs: x[i], \n",
    "                                self.targets: y[0],\n",
    "                                self.decoder_inputs : y[0],\n",
    "                                self.keep_prob: 1.}\n",
    "                self.answer = sess.run(prediction, feed_dict=feed)\n",
    "                c, t = self.accuracy(self.answer, y[i])\n",
    "                self.count += c\n",
    "                self.total += t\n",
    "        return self.count/self.total\n",
    "            # print(answer)\n",
    "    \n",
    "    def accuracy(self, pred, target):\n",
    "        pred = np.array(pred)\n",
    "        pred = np.array(pred >= 0.5).astype(int)\n",
    "        result = np.abs(pred - target)\n",
    "        \n",
    "        count = np.sum(result)\n",
    "        total = result.size\n",
    "\n",
    "        for i in range(result.shape[0]):\n",
    "            np.savetxt(\"result_\" + str(i) + \".csv\", result[i], delimiter=',')\n",
    "        return count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 5\n",
    "lstm_size=[50., 50., 50.]\n",
    "learning_rate=0.005\n",
    "save_path = './seq2seq_models'\n",
    "\n",
    "iters=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch: 1908 ; Test Batch: 211\n",
      "iters 0\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 1/100...  loss: 0.1366816908...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 1/100...  loss: 0.0297981072...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 1/100...  loss: 0.0122777065...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 1/100...  loss: 0.0210627615...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 1/100...  loss: 0.0094680544...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 1/100...  loss: 0.0004520139...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 1/100...  loss: 0.0170255993...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 1/100...  loss: 0.0012942289...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 1/100...  loss: 0.0015716224...  0.0020 sec/batch\n",
      "iters 1\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 2/100...  loss: 0.0074027870...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 2/100...  loss: 0.0033236174...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 2/100...  loss: 0.0015533912...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 2/100...  loss: 0.0028909447...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 2/100...  loss: 0.0024786105...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 2/100...  loss: 0.0000655257...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 2/100...  loss: 0.0005824257...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 2/100...  loss: 0.0002453746...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 2/100...  loss: 0.0002047154...  0.0030 sec/batch\n",
      "iters 2\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 3/100...  loss: 0.0013676323...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 3/100...  loss: 0.0005733452...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 3/100...  loss: 0.0005741913...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 3/100...  loss: 0.0005665743...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 3/100...  loss: 0.0011782330...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 3/100...  loss: 0.0000184755...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 3/100...  loss: 0.0002024873...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 3/100...  loss: 0.0001023622...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 3/100...  loss: 0.0000511560...  0.0020 sec/batch\n",
      "iters 3\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 4/100...  loss: 0.0004881968...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 4/100...  loss: 0.0002468882...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 4/100...  loss: 0.0001136952...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 4/100...  loss: 0.0002635000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 4/100...  loss: 0.0012156827...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 4/100...  loss: 0.0000061587...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 4/100...  loss: 0.0000590849...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 4/100...  loss: 0.0000327857...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 4/100...  loss: 0.0000183291...  0.0020 sec/batch\n",
      "iters 4\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 5/100...  loss: 0.0003559116...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 5/100...  loss: 0.0002217563...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 5/100...  loss: 0.0001972652...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 5/100...  loss: 0.0002654240...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 5/100...  loss: 0.0017273171...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 5/100...  loss: 0.0000033524...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 5/100...  loss: 0.0001311435...  0.0050 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 5/100...  loss: 0.0000316815...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 5/100...  loss: 0.0000110668...  0.0020 sec/batch\n",
      "iters 5\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 6/100...  loss: 0.0000752235...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 6/100...  loss: 0.0000272057...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 6/100...  loss: 0.0000134087...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 6/100...  loss: 0.0000327884...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 6/100...  loss: 0.0001325252...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 6/100...  loss: 0.0000013934...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 6/100...  loss: 0.0000275053...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 6/100...  loss: 0.0000203960...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 6/100...  loss: 0.0000093816...  0.0020 sec/batch\n",
      "iters 6\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 7/100...  loss: 0.0001724383...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 7/100...  loss: 0.0000424826...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 7/100...  loss: 0.0000084093...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 7/100...  loss: 0.0000257674...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 7/100...  loss: 0.0000849776...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 7/100...  loss: 0.0000006060...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 7/100...  loss: 0.0000076206...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 7/100...  loss: 0.0000077366...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 7/100...  loss: 0.0000162441...  0.0020 sec/batch\n",
      "iters 7\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 8/100...  loss: 0.0000939896...  0.0030 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 8/100...  loss: 0.0000417591...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 8/100...  loss: 0.0000068093...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 8/100...  loss: 0.0000265936...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 8/100...  loss: 0.0000367345...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 8/100...  loss: 0.0000003286...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 8/100...  loss: 0.0000023633...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 8/100...  loss: 0.0000012655...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 8/100...  loss: 0.0000011915...  0.0020 sec/batch\n",
      "iters 8\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 9/100...  loss: 0.0000206312...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 9/100...  loss: 0.0000113484...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 9/100...  loss: 0.0000019902...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 9/100...  loss: 0.0000089112...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 9/100...  loss: 0.0000246884...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 9/100...  loss: 0.0000001083...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 9/100...  loss: 0.0000014705...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 9/100...  loss: 0.0000004615...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 9/100...  loss: 0.0000003562...  0.0020 sec/batch\n",
      "iters 9\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 10/100...  loss: 0.0000100213...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 10/100...  loss: 0.0000482393...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 10/100...  loss: 0.0000097800...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 10/100...  loss: 0.0000785442...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 10/100...  loss: 0.0024303570...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 10/100...  loss: 0.0000011527...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 10/100...  loss: 0.0000025636...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 10/100...  loss: 0.0000010788...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 10/100...  loss: 0.0000010317...  0.0020 sec/batch\n",
      "iters 10\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 11/100...  loss: 0.0000198886...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 11/100...  loss: 0.0000079515...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 11/100...  loss: 0.0000019406...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 11/100...  loss: 0.0000058148...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 11/100...  loss: 0.0000358574...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 11/100...  loss: 0.0000001144...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 11/100...  loss: 0.0000002696...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 11/100...  loss: 0.0000002428...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 11/100...  loss: 0.0000002455...  0.0020 sec/batch\n",
      "iters 11\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 12/100...  loss: 0.0000059674...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 12/100...  loss: 0.0000021833...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 12/100...  loss: 0.0000008074...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 12/100...  loss: 0.0000024010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 12/100...  loss: 0.0000080736...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 12/100...  loss: 0.0000000437...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 12/100...  loss: 0.0000001847...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 12/100...  loss: 0.0000001161...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 12/100...  loss: 0.0000001266...  0.0020 sec/batch\n",
      "iters 12\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 13/100...  loss: 0.0000020562...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 13/100...  loss: 0.0000010048...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 13/100...  loss: 0.0000004070...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 13/100...  loss: 0.0000012633...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 13/100...  loss: 0.0000036664...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 13/100...  loss: 0.0000000221...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 13/100...  loss: 0.0000001415...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 13/100...  loss: 0.0000000701...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 13/100...  loss: 0.0000000525...  0.0020 sec/batch\n",
      "iters 13\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 14/100...  loss: 0.0000013311...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 14/100...  loss: 0.0000004449...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 14/100...  loss: 0.0000003884...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 14/100...  loss: 0.0000007084...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 14/100...  loss: 0.0000053907...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 14/100...  loss: 0.0000000154...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 14/100...  loss: 0.0000001705...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 14/100...  loss: 0.0000000421...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 14/100...  loss: 0.0000000487...  0.0020 sec/batch\n",
      "iters 14\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 15/100...  loss: 0.0000040478...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 15/100...  loss: 0.0004625756...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 15/100...  loss: 0.0000348615...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 15/100...  loss: 0.0000719974...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 15/100...  loss: 0.0008958832...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 15/100...  loss: 0.0000009030...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 15/100...  loss: 0.0000145864...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 15/100...  loss: 0.0000010375...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 15/100...  loss: 0.0000004281...  0.0020 sec/batch\n",
      "iters 15\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 16/100...  loss: 0.0000190558...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 16/100...  loss: 0.0000075682...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 16/100...  loss: 0.0000004848...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 16/100...  loss: 0.0000035303...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 16/100...  loss: 0.0000051928...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 16/100...  loss: 0.0000001152...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 16/100...  loss: 0.0000002735...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 16/100...  loss: 0.0000002126...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 16/100...  loss: 0.0000001594...  0.0020 sec/batch\n",
      "iters 16\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 17/100...  loss: 0.0000039500...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 17/100...  loss: 0.0000019109...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 17/100...  loss: 0.0000001787...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 17/100...  loss: 0.0000011634...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 17/100...  loss: 0.0000019285...  0.0050 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 17/100...  loss: 0.0000000333...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 17/100...  loss: 0.0000001283...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 17/100...  loss: 0.0000001010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 17/100...  loss: 0.0000000696...  0.0030 sec/batch\n",
      "iters 17\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 18/100...  loss: 0.0000019051...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 18/100...  loss: 0.0000008553...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 18/100...  loss: 0.0000001487...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 18/100...  loss: 0.0000006307...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 18/100...  loss: 0.0000007767...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 18/100...  loss: 0.0000000160...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 18/100...  loss: 0.0000000496...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 18/100...  loss: 0.0000000483...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 18/100...  loss: 0.0000000304...  0.0070 sec/batch\n",
      "iters 18\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 19/100...  loss: 0.0000010509...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 19/100...  loss: 0.0000004059...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 19/100...  loss: 0.0000001024...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 19/100...  loss: 0.0000003674...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 19/100...  loss: 0.0000002933...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 19/100...  loss: 0.0000000063...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 19/100...  loss: 0.0000000262...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 19/100...  loss: 0.0000000265...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 19/100...  loss: 0.0000000147...  0.0020 sec/batch\n",
      "iters 19\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 20/100...  loss: 0.0000005625...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 20/100...  loss: 0.0000002162...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 20/100...  loss: 0.0000000648...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 20/100...  loss: 0.0000002314...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 20/100...  loss: 0.0000001588...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 20/100...  loss: 0.0000000027...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 20/100...  loss: 0.0000000174...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 20/100...  loss: 0.0000000155...  0.0060 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 20/100...  loss: 0.0000000076...  0.0020 sec/batch\n",
      "iters 20\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 21/100...  loss: 0.0000002584...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 21/100...  loss: 0.0000001106...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 21/100...  loss: 0.0000000388...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 21/100...  loss: 0.0000001333...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 21/100...  loss: 0.0000001034...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 21/100...  loss: 0.0000000013...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 21/100...  loss: 0.0000000121...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 21/100...  loss: 0.0000000075...  0.0050 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 21/100...  loss: 0.0000000042...  0.0030 sec/batch\n",
      "iters 21\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 22/100...  loss: 0.0000001203...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 22/100...  loss: 0.0000000560...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 22/100...  loss: 0.0000000210...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 22/100...  loss: 0.0000000645...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 22/100...  loss: 0.0000000563...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 22/100...  loss: 0.0000000007...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 22/100...  loss: 0.0000000078...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 22/100...  loss: 0.0000000039...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 22/100...  loss: 0.0000000024...  0.0030 sec/batch\n",
      "iters 22\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 23/100...  loss: 0.0000000594...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 23/100...  loss: 0.0000000333...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 23/100...  loss: 0.0000000110...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 23/100...  loss: 0.0000000353...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 23/100...  loss: 0.0000000356...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 23/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 23/100...  loss: 0.0000000050...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 23/100...  loss: 0.0000000023...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 23/100...  loss: 0.0000000016...  0.0040 sec/batch\n",
      "iters 23\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 24/100...  loss: 0.0000000348...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 24/100...  loss: 0.0000000210...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 24/100...  loss: 0.0000000059...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 24/100...  loss: 0.0000000213...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 24/100...  loss: 0.0000000200...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 24/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 24/100...  loss: 0.0000000031...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 24/100...  loss: 0.0000000014...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 24/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "iters 24\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 25/100...  loss: 0.0000000219...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 25/100...  loss: 0.0000000140...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 25/100...  loss: 0.0000000038...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 25/100...  loss: 0.0000000150...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 25/100...  loss: 0.0000000138...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 25/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 25/100...  loss: 0.0000000021...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 25/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 25/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "iters 25\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 26/100...  loss: 0.0000000156...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 26/100...  loss: 0.0000000105...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 26/100...  loss: 0.0000000028...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 26/100...  loss: 0.0000000116...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 26/100...  loss: 0.0000000105...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 26/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 26/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 26/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 26/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "iters 26\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 27/100...  loss: 0.0000000116...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 27/100...  loss: 0.0000000081...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 27/100...  loss: 0.0000000023...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 27/100...  loss: 0.0000000093...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 27/100...  loss: 0.0000000085...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 27/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 27/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 27/100...  loss: 0.0000000005...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 27/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "iters 27\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 28/100...  loss: 0.0000000095...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 28/100...  loss: 0.0000000068...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 28/100...  loss: 0.0000000019...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 28/100...  loss: 0.0000000080...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 28/100...  loss: 0.0000000072...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 28/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 28/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 28/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 28/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "iters 28\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 29/100...  loss: 0.0000000079...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 29/100...  loss: 0.0000000057...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 29/100...  loss: 0.0000000017...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 29/100...  loss: 0.0000000070...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 29/100...  loss: 0.0000000063...  0.0119 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 29/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 29/100...  loss: 0.0000000009...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 29/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 29/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "iters 29\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 30/100...  loss: 0.0000000070...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 30/100...  loss: 0.0000000051...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 30/100...  loss: 0.0000000015...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 30/100...  loss: 0.0000000063...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 30/100...  loss: 0.0000000056...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 30/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 30/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 30/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 30/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "iters 30\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 31/100...  loss: 0.0000000062...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 31/100...  loss: 0.0000000044...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 31/100...  loss: 0.0000000014...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 31/100...  loss: 0.0000000057...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 31/100...  loss: 0.0000000050...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 31/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 31/100...  loss: 0.0000000007...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 31/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 31/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "iters 31\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 32/100...  loss: 0.0000000057...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 32/100...  loss: 0.0000000040...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 32/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 32/100...  loss: 0.0000000053...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 32/100...  loss: 0.0000000046...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 32/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 32/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 32/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 32/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "iters 32\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 33/100...  loss: 0.0000000052...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 33/100...  loss: 0.0000000036...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 33/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 33/100...  loss: 0.0000000049...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 33/100...  loss: 0.0000000042...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 33/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 33/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 33/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 33/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "iters 33\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 34/100...  loss: 0.0000000048...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 34/100...  loss: 0.0000000034...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 34/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 34/100...  loss: 0.0000000045...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 34/100...  loss: 0.0000000039...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 34/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 34/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 34/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 34/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "iters 34\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 35/100...  loss: 0.0000000045...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 35/100...  loss: 0.0000000031...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 35/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 35/100...  loss: 0.0000000042...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 35/100...  loss: 0.0000000037...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 35/100...  loss: 0.0000000000...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 35/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 35/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 35/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 35\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 36/100...  loss: 0.0000000042...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 36/100...  loss: 0.0000000029...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 36/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 36/100...  loss: 0.0000000040...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 36/100...  loss: 0.0000000035...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 36/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 36/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 36/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 36/100...  loss: 0.0000000001...  0.0040 sec/batch\n",
      "iters 36\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 37/100...  loss: 0.0000000039...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 37/100...  loss: 0.0000000027...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 37/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 37/100...  loss: 0.0000000038...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 37/100...  loss: 0.0000000033...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 37/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 37/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 37/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 37/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 37\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 38/100...  loss: 0.0000000037...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 38/100...  loss: 0.0000000026...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 38/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 38/100...  loss: 0.0000000036...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 38/100...  loss: 0.0000000031...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 38/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 38/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 38/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 38/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 38\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 39/100...  loss: 0.0000000035...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 39/100...  loss: 0.0000000024...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 39/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 39/100...  loss: 0.0000000034...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 39/100...  loss: 0.0000000029...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 39/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 39/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 39/100...  loss: 0.0000000001...  0.0025 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 39/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 39\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 40/100...  loss: 0.0000000033...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 40/100...  loss: 0.0000000023...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 40/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 40/100...  loss: 0.0000000032...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 40/100...  loss: 0.0000000028...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 40/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 40/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 40/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 40/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 40\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 41/100...  loss: 0.0000000032...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 41/100...  loss: 0.0000000022...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 41/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 41/100...  loss: 0.0000000031...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 41/100...  loss: 0.0000000027...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 41/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 41/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 41/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 41/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 41\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 42/100...  loss: 0.0000000030...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 42/100...  loss: 0.0000000021...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 42/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 42/100...  loss: 0.0000000030...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 42/100...  loss: 0.0000000025...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 42/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 42/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 42/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 42/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 42\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 43/100...  loss: 0.0000000029...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 43/100...  loss: 0.0000000020...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 43/100...  loss: 0.0000000006...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 43/100...  loss: 0.0000000028...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 43/100...  loss: 0.0000000024...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 43/100...  loss: 0.0000000000...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 43/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 43/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 43/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 43\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 44/100...  loss: 0.0000000028...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 44/100...  loss: 0.0000000019...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 44/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 44/100...  loss: 0.0000000027...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 44/100...  loss: 0.0000000023...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 44/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 44/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 44/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 44/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 44\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 45/100...  loss: 0.0000000027...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 45/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 45/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 45/100...  loss: 0.0000000026...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 45/100...  loss: 0.0000000022...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 45/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 45/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 45/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 45/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 45\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 46/100...  loss: 0.0000000025...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 46/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 46/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 46/100...  loss: 0.0000000025...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 46/100...  loss: 0.0000000022...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 46/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 46/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 46/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 46/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 46\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 47/100...  loss: 0.0000000025...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 47/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 47/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 47/100...  loss: 0.0000000024...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 47/100...  loss: 0.0000000021...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 47/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 47/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 47/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 47/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 47\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 48/100...  loss: 0.0000000024...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 48/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 48/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 48/100...  loss: 0.0000000024...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 48/100...  loss: 0.0000000020...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 48/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 48/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 48/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 48/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 48\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 49/100...  loss: 0.0000000023...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 49/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 49/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 49/100...  loss: 0.0000000023...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 49/100...  loss: 0.0000000019...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 49/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 49/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 49/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 49/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 49\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 50/100...  loss: 0.0000000022...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 50/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 50/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 50/100...  loss: 0.0000000022...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 50/100...  loss: 0.0000000019...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 50/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 50/100...  loss: 0.0000000002...  0.0030 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 50/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 50/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 50\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 51/100...  loss: 0.0000000021...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 51/100...  loss: 0.0000000015...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 51/100...  loss: 0.0000000005...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 51/100...  loss: 0.0000000021...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 51/100...  loss: 0.0000000018...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 51/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 51/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 51/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 51/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "iters 51\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 52/100...  loss: 0.0000000021...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 52/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 52/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 52/100...  loss: 0.0000000021...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 52/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 52/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 52/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 52/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 52/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 52\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 53/100...  loss: 0.0000000020...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 53/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 53/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 53/100...  loss: 0.0000000020...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 53/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 53/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 53/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 53/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 53/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "iters 53\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 54/100...  loss: 0.0000000019...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 54/100...  loss: 0.0000000013...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 54/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 54/100...  loss: 0.0000000019...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 54/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 54/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 54/100...  loss: 0.0000000002...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 54/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 54/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 54\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 55/100...  loss: 0.0000000019...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 55/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 55/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 55/100...  loss: 0.0000000019...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 55/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 55/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 55/100...  loss: 0.0000000002...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 55/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 55/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 55\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 56/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 56/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 56/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 56/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 56/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 56/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 56/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 56/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 56/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 56\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 57/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 57/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 57/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 57/100...  loss: 0.0000000018...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 57/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 57/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 57/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 57/100...  loss: 0.0000000001...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 57/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 57\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 58/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 58/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 58/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 58/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 58/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 58/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 58/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 58/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 58/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 58\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 59/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 59/100...  loss: 0.0000000012...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 59/100...  loss: 0.0000000004...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 59/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 59/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 59/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 59/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 59/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 59/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 59\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 60/100...  loss: 0.0000000017...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 60/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 60/100...  loss: 0.0000000004...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 60/100...  loss: 0.0000000016...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 60/100...  loss: 0.0000000014...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 60/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 60/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 60/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 60/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 60\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 61/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 61/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 61/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 61/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 61/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 61/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 61/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 61/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 61/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 61\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 62/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 62/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 62/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 62/100...  loss: 0.0000000016...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 62/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 62/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 62/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 62/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 62/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 62\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 63/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 63/100...  loss: 0.0000000011...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 63/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 63/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 63/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 63/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 63/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 63/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 63/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 63\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 64/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 64/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 64/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 64/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 64/100...  loss: 0.0000000013...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 64/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 64/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 64/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 64/100...  loss: 0.0000000000...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters 64\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 65/100...  loss: 0.0000000015...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 65/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 65/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 65/100...  loss: 0.0000000015...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 65/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 65/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 65/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 65/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 65/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 65\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 66/100...  loss: 0.0000000015...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 66/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 66/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 66/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 66/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 66/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 66/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 66/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 66/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 66\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 67/100...  loss: 0.0000000014...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 67/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 67/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 67/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 67/100...  loss: 0.0000000012...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 67/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 67/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 67/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 67/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 67\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 68/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 68/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 68/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 68/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 68/100...  loss: 0.0000000012...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 68/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 68/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 68/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 68/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 68\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 69/100...  loss: 0.0000000014...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 69/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 69/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 69/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 69/100...  loss: 0.0000000012...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 69/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 69/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 69/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 69/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 69\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 70/100...  loss: 0.0000000013...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 70/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 70/100...  loss: 0.0000000003...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 70/100...  loss: 0.0000000013...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 70/100...  loss: 0.0000000012...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 70/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 70/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 70/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 70/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 70\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 71/100...  loss: 0.0000000013...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 71/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 71/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 71/100...  loss: 0.0000000013...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 71/100...  loss: 0.0000000011...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 71/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 71/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 71/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 71/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 71\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 72/100...  loss: 0.0000000013...  0.0030 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 72/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 72/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 72/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 72/100...  loss: 0.0000000011...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 72/100...  loss: 0.0000000000...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 72/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 72/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 72/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 72\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 73/100...  loss: 0.0000000013...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 73/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 73/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 73/100...  loss: 0.0000000012...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 73/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 73/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 73/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 73/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 73/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 73\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 74/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 74/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 74/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 74/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 74/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 74/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 74/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 74/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 74/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 74\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 75/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 75/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 75/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 75/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 75/100...  loss: 0.0000000011...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 75/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 75/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 75/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 75/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 75\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 76/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 76/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 76/100...  loss: 0.0000000003...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 76/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 76/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 76/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 76/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 76/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 76/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 76\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 77/100...  loss: 0.0000000012...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 77/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 77/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 77/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 77/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 77/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 77/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 77/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 77/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 77\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 78/100...  loss: 0.0000000012...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 78/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 78/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 78/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 78/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 78/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 78/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 78/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 78/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 78\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 79/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 79/100...  loss: 0.0000000008...  0.0030 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 79/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 79/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 79/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 79/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 79/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 79/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 79/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 79\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 80/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 80/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 80/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 80/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 80/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 80/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 80/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 80/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 80/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 80\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 81/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 81/100...  loss: 0.0000000008...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 81/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 81/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 81/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 81/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 81/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 81/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 81/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 81\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 82/100...  loss: 0.0000000011...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 82/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 82/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 82/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 82/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 82/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 82/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 82/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 82/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 82\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 83/100...  loss: 0.0000000011...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 83/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 83/100...  loss: 0.0000000002...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 83/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 83/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 83/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 83/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 83/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 83/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 83\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 84/100...  loss: 0.0000000011...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 84/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 84/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 84/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 84/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 84/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 84/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 84/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 84/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 84\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 85/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 85/100...  loss: 0.0000000007...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 85/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 85/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 85/100...  loss: 0.0000000009...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 85/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 85/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 85/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 85/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 85\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 86/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 86/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 86/100...  loss: 0.0000000002...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 86/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 86/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 86/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 86/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 86/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 86/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 86\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 87/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 87/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 87/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 87/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 87/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 87/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 87/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 87/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 87/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 87\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 88/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 88/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 88/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 88/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 88/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 88/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 88/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 88/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 88/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 88\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 89/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 89/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 89/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 89/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 89/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 89/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 89/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 89/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 89/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 89\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 90/100...  loss: 0.0000000010...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 90/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 90/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 90/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 90/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 90/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 90/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 90/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 90/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 90\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 91/100...  loss: 0.0000000010...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 91/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 91/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 91/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 91/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 91/100...  loss: 0.0000000000...  0.0040 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 91/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 91/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 91/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 91\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 92/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 92/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 92/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 92/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 92/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 92/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 92/100...  loss: 0.0000000001...  0.0094 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 92/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 92/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 92\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 93/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 93/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 93/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 93/100...  loss: 0.0000000009...  0.0020 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 93/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 93/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 93/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 93/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 93/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 93\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 94/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 94/100...  loss: 0.0000000007...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 94/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 94/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 94/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 94/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 94/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 94/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 94/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 94\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 95/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 95/100...  loss: 0.0000000007...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 95/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 95/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 95/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 95/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 95/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 95/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 95/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 95\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 96/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 96/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 96/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 96/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 96/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 96/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 96/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 96/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 96/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 96\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 97/100...  loss: 0.0000000009...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 97/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 97/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 97/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 97/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 97/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 97/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 97/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 97/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 97\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 98/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 98/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 98/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 98/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 98/100...  loss: 0.0000000008...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 98/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 98/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 98/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 98/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "iters 98\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 99/100...  loss: 0.0000000009...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 99/100...  loss: 0.0000000006...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 99/100...  loss: 0.0000000002...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 99/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 99/100...  loss: 0.0000000007...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 99/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 99/100...  loss: 0.0000000001...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 99/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 99/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "iters 99\n",
      "=======================================================\n",
      "\n",
      "step: 200 in iter: 100/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 400 in iter: 100/100...  loss: 0.0000000006...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 600 in iter: 100/100...  loss: 0.0000000002...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 800 in iter: 100/100...  loss: 0.0000000008...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1000 in iter: 100/100...  loss: 0.0000000007...  0.0030 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "\n",
      "step: 1200 in iter: 100/100...  loss: 0.0000000000...  0.0030 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1400 in iter: 100/100...  loss: 0.0000000001...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1600 in iter: 100/100...  loss: 0.0000000000...  0.0020 sec/batch\n",
      "=======================================================\n",
      "\n",
      "step: 1800 in iter: 100/100...  loss: 0.0000000000...  0.0020 sec/batch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if os.path.exists(save_path) is False:\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "train_input, train_target, test_input, test_target = batch_generator(x_input.values, \n",
    "                                                              y_label.values, \n",
    "                                                              batch_size=batch_size, \n",
    "                                                              seq_len=seq_len)\n",
    "\n",
    "model = Seq2Seq(batch_size=batch_size, \n",
    "                seq_max_len=seq_len,\n",
    "                lstm_size=lstm_size,\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "model.train(train_input, \n",
    "            train_target,\n",
    "            iters=iters,\n",
    "            save_every_n=1000,\n",
    "            log_every_n =200\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./seq2seq_models/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03830771009131892"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./seq2seq_models/model',graph=tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
